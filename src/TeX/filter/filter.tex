% Examples of filtering and smoothing

% Copyright 2022, 2024 Andrew M. Fraser.
\documentclass[12pt]{article}
\usepackage{graphicx,color}
\usepackage{amsmath, amsfonts}
\usepackage{placeins}


\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\INTEGER}{\field{Z}}
\newcommand{\REAL}{\field{R}}
\newcommand{\COMPLEX}{\field{C}}
\newcommand{\EV}{\field{E}}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\id}{\mathbb{I}}
\newcommand{\variance}[1]{\field{V}\left[ #1 \right]}
\newcommand{\normal}[2]{{\cal N}\left(#1,#2 \right)}
\newcommand{\diff}{\text{d}}

\newcommand{\filterplot}[2]{
\begin{figure}
  \centering
  \resizebox{0.7\textwidth}{!}{\includegraphics{#1.pdf}}
  \caption{#2}
  \label{fig:#1}
\end{figure}
}

\title{Illustrations of Filtering and Smoothing}
\author{Andrew M.\ Fraser}

\begin{document}
\maketitle

\section{Introduction}
\label{sec:introduction}

I have written code for the following tasks:
\begin{itemize}
\item Kalman filtering and smoothing
\item Extended Kalman filtering
\item Particle filtering
\item Simulate stochastic differential equations to exercise the
  filtering code
\end{itemize}
This document started as a collection of figures that illustrate data
generated by that code.  Build this document from the root directory
for hmmds by issuing:
\begin{verbatim}
$ make filter
\end{verbatim}

\section{Build System}

The file src/TeX/filter/Rules.mk defines the dependencies for making
this document.  They are primarily pdfs.  Rules for building the pdfs
are in src/plotscripts/filter/Rules.mk.  And rules for making the data
that the figures need are in src/hmmds/synthetic/filter/Rules.mk.

There are pattern rules for making \%\_filter.pdf or \%\_smooth.pdf from
\%\_data in src/plotscripts/filter/Rules.mk.  And
src/hmmds/synthetic/filter/Rules.mk has the rules for making the
\%\_data files.

\section{Linear Map}
\label{sec:linear_map}

I define a linear Gaussian state space system
\begin{subequations}
  \label{eq:linear_map}
  \begin{align}
    \label{eq:linear_state_map}
    x[t+1] &= A x[t] + B V[t] \\
    y[t] &= C x[t] + D W[t] \\
    A &=
        \begin{bmatrix}
          \cos(\omega dt) & \sin(\omega dt)\\
          -\sin(\omega dt) & \cos(\omega dt)
        \end{bmatrix} \cdot e^{-a dt} \\
    B &=
        \begin{bmatrix}
          b\sqrt{dt} & 0 \\ 0 & b\sqrt{dt}
        \end{bmatrix} \\
    C &=
        \begin{bmatrix}
          c & 0
        \end{bmatrix}\\
    D &=
        \begin{bmatrix}
         d
        \end{bmatrix}
  \end{align}
\end{subequations}
where $V$ and $W$ are unit variance iid Gaussian noise.
Figures~\ref{fig:linear_map_filter} and \ref{fig:linear_map_smooth}
illustrate the behavior of the system with the values
\begin{align*}
  \omega &= 2\pi && \text{frequency} = 1\\
  a &= 0.01 && \text{relaxation time is 100 cyles}\\
  b &= 2 && \text{state noise scale} \\
  c &= 0.5 && \text{observation multiplier} \\
  d &= 25 && \text{observation noise scale}.
\end{align*}
Figure~\ref{fig:linear_map_filter} has the following subplots:
\begin{description}
\item[Upper left:] A phase portrait, $x_1$ vs $x_0$
\item[Center left:] Time series, $x_0$ and $x_1$ vs $t$.  The curves
  are sampled 100 times per cycle and dots represent 20 samples per
  cycle.
  % Rules.mk: FILTER_ARGS = --sample_rate 100 --sample_ratio 5
  The data for filtering and smoothing are sampled at that rate.
\item[Lower left:] Simulated data $y_0$ vs $t$ with dots representing
  the samples.
\item[Upper right:] The sampled observations $y_0$ vs $t$
\item[Center right:] The first component of the state, $x_0$, and the
  estimate of the first component from a forward Kalman filter,
  $\hat x_0$, vs $t$.
\item[Lower right:] The difference, $\hat x_0 - x_0$, and twice the
  square root of the estimated variance, $2\sqrt{\Sigma_{0,0}}$,
  vs $t$.
\end{description}
%
\filterplot{linear_map_filter}{Kalman filter applied to data from a
  stationary linear map.  On the left, top to bottom: True phase
  space; True time series (dots at sample rate); Noisy observation
  time series.  On the right top to bottom: Observation time series;
  True and estimated time series; Actual error and estimated
  deviation.  Note that the data for the right hand column is drawn
  independently from the data in the left hand column.}
%
\pagebreak %
And Fig.~\ref{fig:linear_map_smooth} has the following subplots:
\begin{description}
\item[Upper left:] The estimate of the first component from a forward
  Kalman filter, $\hat x_0$, and the first component of the state,
  $x_0$, vs $t$.
\item[Center left:] The estimate of the first component from a backward
  Kalman filter, $\hat x_0$, vs $t$.
\item[Lower left:] The estimate of the first component from smoothing
  that uses both a forward and a backward pass through the data,
  $\hat x_0$, vs $t$.
\item[Upper right:] The error and estimated standard deviation for
  $x_0$ from a forward pass through the data.
\item[Center right:] The error and estimated standard deviation for
  $x_0$ from a backward pass through the data.
\item[Lower right:] The error and estimated standard deviation for
  $x_0$ from combining a forward and a backward pass through the data.
\end{description}

\filterplot{linear_map_smooth}{A smoothing filter applied to the data
  illustrated in the upper right hand plot of Fig.~\ref{fig:linear_map_filter} }%
\pagebreak

The plots in Figs. \ref{fig:linear_sde_filter} and
\ref{fig:linear_sde_smooth} are like the plots in
Figs.~\ref{fig:linear_map_filter} \ref{fig:linear_map_smooth} except
that the data are generated by simulating a stochastic differential
equation (SDE).  In particular Eqn.~\eqref{eq:linear_state_map} is
replaced by integrating
\begin{equation}
  \label{eq:linear_state_sde}
  \diff x = A x \diff t + \diff \Omega
\end{equation}
where $\Omega$ is a Wiener process\footnote{The code in
  hmm.state\_space.SDE simulates the Wiener process by integrating for
  a time step $\tau$ and adding $\sqrt{\tau}\cdot B$ to the result.}.
The result is a linear discrete time system, but it exercises code for
extended Kalman filtering (EKF) that integrates an SDE and the tangent
to the underlying ODE.

\filterplot{linear_sde_filter}{Extended Kalman filter applied to
  linear stochastic differential equation.  Like
  Fig.~\ref{fig:linear_map_filter}, but state maps come from
  integrating tangents.}

\filterplot{linear_sde_smooth}{Extended smoothing applied to
  linear stochastic differential equation.  Like
  Fig.~\ref{fig:linear_map_smooth}, but state maps come from
  integrating tangents.}\pagebreak

The plots in Fig. \ref{fig:linear_particle_filter} are like the plots
in Figs.~\ref{fig:linear_map_filter} except that the estimates come
from a particle filter.
\filterplot{linear_particle_filter}{Particle filter applied to data
  from a linear map.  Like Fig.~\ref{fig:linear_map_filter}.}\pagebreak

The plots in Figs. \ref{fig:lorenz_filter} and
\ref{fig:lorenz_smooth} are like the plots in
Figs.~\ref{fig:linear_sde_filter} \ref{fig:linear_sde_smooth} except
that the underlying ODE is the Lorenz system.

\filterplot{lorenz_filter}{Extended Kalman filter applied to Lorenz
  system with two dimensional observations.}

\filterplot{lorenz_smooth}{Extended smoothing filter applied to Lorenz
  system with two dimensional observations.} \pagebreak

\filterplot{lorenz_particle_filter}{Particle filter applied to Lorenz
  system.  Like Fig.~\ref{fig:lorenz_filter}
  except that estimates are from a particle filter rather than an EKF.}

\filterplot{log_likelihood}{An illustration of maximum likelihood
  estimation.  Samples, $y[0:1000]$, drawn from foo with a noise scale
  $b=0.01$ appear in the upper plot.  The log likelihoods
  $\log\left(p(y[0:1000]|b)\right)$ of systems with a range of
  different values for $b$ appear in the lower plot.}

% Makefile: _python $< --n_samples 10000 --a 0.05 --b 0.2 $@
\filterplot{distribution}{Test a formula for the variance of states
  generated by a linear SDE using 10,000 samples with $a=0.05$ and
  $b=0.2$.  Only 1,000 samples appear in the upper plot.  Below that
  is a \emph{probability plot} which compares the cumulative
  distribution of the actual data to the cumulative distribution of a
  normal distribution with the variance given by the formula
  $\EV(x^2) = \frac{b^2}{1 - e^{-2*a*dt}}$.}

\clearpage

\section{Boxes for Lorenz System}
\label{sec:boxes}

I hoped to build a filter for coarsely quantized observations of
simulations of the Lorenz system that gets performance close to the
bound given by estimated Lyapunov exponents.  Here is the strategy
from my poster for Dynamics Days 2025:
\begin{itemize}
\item Cover attractor with boxes, ie, particles
\item Assign a uniform probability density in each box
\item Use numerical ODE integration of Lorenz system and its tangent
  to move boxes forward in time
\item When boxes get too big subdivide them
\item When boxes overlap and get too numerous, random resample to
  decimate
\end{itemize}

After working on it for a couple of weeks I got code to run that
doesn't get as close to the bound as HMMs with zillions of states
(11\% off).  To improve the performance, I will consider these
questions:
\begin{enumerate}
\item \label{q:subdivide_criterion} What is an appropriate criterion
  for subdividing boxes?
\item \label{q:subdivide_new_boxes} How should I subdivide boxes?
\item What is an appropriate criterion for resampling?
\item By what fraction should resampling reduce the number of
  particles?
\item How close to a boundary should a particle be to survive an
  update?  I call this distance the \emph{margin}.
\item Should I adjust the weight of marginal particles?
\item Should I subdivide marginal particles?
\item Should I augment box sizes?  Augmentation militates against
  particle exhaustion and the collapse of boxes in the stable
  direction.
\end{enumerate}

\subsection{Subdivision}
\label{sec:subdivision}

\subsubsection{Criterion and Number}
\label{sec:criterion}

Here I will develop an answer to question \ref{q:subdivide_criterion}
in terms of first and second derivatives.  The criterion is that the
size of the quadratic term in a Taylor series should be small compared
to the linear term.  I begin by explaining how I propagate particles
and boxes.

I map particle centers forward a time step by numerically integrating
the Lorenz system for a time interval $\tau = 0.15$
\begin{align}
  x[n+1] &= \Phi(x[n],\tau) \\
  \frac{d \Phi(x,t)}{dt} &\equiv \dot x = f(x) =
                           \begin{bmatrix}
                             \sigma(x_1-x_0)\\
                             x_0(\rho-x_2) - x_1\\
                             x_0x_1 - \beta x_2
                           \end{bmatrix}
\end{align}

Each particle also has a box (parallelepiped) with edges given by the
columns of
\begin{equation*}
  b =
  \begin{bmatrix}
    b_{0,0} & b_{0,1} & b_{0,2} \\
    b_{1,0} & b_{1,1} & b_{1,2} \\
    b_{2,0} & b_{2,1} & b_{2,2} \\
  \end{bmatrix}
\end{equation*}
%
Here is a two term Taylor series for mapping a box edge (an edge is a
column, ie $b_1 \equiv b_{*,1}$ is column number 1) forward one time
step
\begin{equation}
  \label{eq:quadratic_phi}
  b_j[n+1] = \frac{\partial}{\partial x} \Phi(x[n], \tau) b_j[n] + \frac{1}{2} b_j^T[n]
  \frac{\partial^2}{\partial x^2} \Phi(x[n], \tau) b_j[n] + \text{Remainder}
\end{equation}
I calculate the linear term by numerically integrating the space
derivative of the Lorenz system
\begin{align}
  \label{eq:tangent}
  \dot b_L &\equiv \frac{\partial}{\partial x} \frac{d}{dt} \Phi(x,t) b
  \\
  \nonumber 
  &=
    \begin{bmatrix}
      -\sigma & \sigma & 0 \\
      (\rho - x_2) & -1 & -x_0 \\
      x_1 & x_0 & -\beta
    \end{bmatrix} b  \\
  \label{eq:F}
           & \equiv F b \\
  \nonumber
  \dot b_{L;j} &= F b_{L;j}
\end{align}
where $F$ in \eqref{eq:F} denotes the space derivative of $f$.

I subdivide boxes to keep the quadratic term in
\eqref{eq:quadratic_phi} small so that I can use only the linear term
to propagate the boxes.  I avoid numerically integrating to get the
quadratic term in \eqref{eq:quadratic_phi} and simply compare the time
derivatives of the linear and quadratic terms, namely: $\dot b_L$ and
$\dot b_Q$.

The quadratic term for the $j^{\text{th}}$ edge of a box is
\begin{subequations}
  \begin{align}
    \dot b_{Q;j} &= \frac{1}{2} b_j^T \frac{\partial^2}{\partial x^2}
               \frac{d}{dt} \Phi(x, t) b_j \\
             &= \frac{1}{2} b_j^T \frac{\partial^2}{\partial x^2}
               f(x,t) b_j.
  \end{align}
\end{subequations}
The second derivative $\frac{\partial^2}{\partial x^2} f(x,t)$ is
independent of time and position with components
\begin{subequations}
  \begin{align}
    \frac{\partial^2}{\partial x^2}
             f_0(x) &= 
                      \begin{bmatrix}
                        0 & 0 & 0 \\
                        0 & 0 & 0 \\
                        0 & 0 & 0
                      \end{bmatrix} \\
    \frac{\partial^2}{\partial x^2}
             f_1(x) &=
                      \begin{bmatrix}
                        0 & 0 & -1 \\
                        0 & 0 & 0 \\
                        -1 & 0 & 0
                      \end{bmatrix} \\
    \frac{\partial^2}{\partial x^2}
             f_2(x) &=
                      \begin{bmatrix}
                        0 & 1 & 0 \\
                        1 & 0 & 0 \\
                        0 & 0 & 0
                      \end{bmatrix}.
  \end{align}
\end{subequations}
\begin{itemize}
\item Note that $\dot b_{Q;i,j}$ is the $i^{\rm{th}}$ component of the
  quadratic contribution to the velocity of the $j^{\rm{th}}$ column
  of $b$, with
  \begin{equation}
    \label{eq:bdot_ij}
    \dot b_{Q;i,j} = \frac{1}{2} \sum_{g,h} \frac{\partial^2 f_i}{\partial x_g
      \partial x_h} b_{g,j} b_{h,j}.
  \end{equation}
\item Once I have two $3\times 3$ arrays for $\dot b_L$ and
  $\dot b_Q$, I will find the box edge for which the quadratic term is
  largest, ie,
  \begin{equation}
    \label{eq:J}
    J = \argmax_j \dot b_{Q;j}\cdot \dot b_{Q;j}
  \end{equation}
  and then decide whether or not to subdivide the box based on the following
  ratio test
  \begin{equation}
    \label{eq:LQ_ratio}
    R \equiv \frac{\left| \dot b_{Q;J} \right|}{\left| \dot b_{L;J}\right|}
                     ~\overset{\geq}{?}~ R_{\text{threshold}}
  \end{equation}
\item Since $\dot b_Q$ is quadratic in $b$ while $\dot b_L$ is linear,
  subdividing an edge into $N$ children would reduce $R$ by a factor
  of about $N$ and choosing $N(R) = \frac{R}{R_{\text{threshold}}}$
  would leave the children at the test threshold.  I will use a term
  $r$ to reduce the size of the children beyond the threshold with
  \begin{equation*}
    N(R) = \frac{rR}{R_{\text{threshold}}}.
  \end{equation*}
\end{itemize}

\subsubsection{New Boxes}
\label{sec:new_boxes}

Here I answer question number \ref{q:subdivide_new_boxes} is ``How
should I subdivide boxes?''  Centered at each of $N(R)$ uniformly
spaced points along the edge $b_J$ create a new box $n$ with edges
\begin{align*}
  n_J &= \frac{1}{N(R)} b_J \\
  n_i &= b_i - \left( \frac{b_i \cdot b_J}{b_J \cdot b_J} \right) b_J
        \quad \forall i \neq J
\end{align*}
which preserves the volume of the original box, and has the new
undivided edges, $n_i$ perpendicular to the divided edges, $n_J$, ie,
$n_J \cdot n_i = 0$.

\subsection{Dynamics Days 2025}
\label{sec:particle_result}

Text copied from my poster for Dynamics Days 2025:

To find something better than an HMM with zillions of states:
\begin{itemize}
\item Cover attractor with boxes, ie, particles
\item Assign a uniform probability density in each box
\item Use numerical ODE integration of Lorenz system and its tangent
  to move boxes forward in time
\item When boxes get too big subdivide them
\item When boxes overlap and get too numerous, random resample to
  decimate
\end{itemize}
\begin{center}
  \resizebox{0.9\textwidth}{!}{\includegraphics{no_divide.pdf}}\\
  \resizebox{0.9\textwidth}{!}{\includegraphics{with_divide.pdf}}\\
  \resizebox{0.9\textwidth}{!}{\includegraphics{entropy_filter.pdf}}
\end{center}

\subsection{Shrinking the Gap}
\label{sec:particle_search}

In March of 2025 I improved on the particle filtering code that I had
used for my poster at Dynamics Days in January.  I wrote Cython code
for integrating the tangent equations in parallel.  The new code is
much faster than the old code.

While I wrote the Cython code for speed so that I could more quickly
invetigate the effects of different parameter setting, I found an
error in the old code as I worked on the Cython code.  In particular I
was transposing the arrays that define the boxes at every time step.

This section is a log of my exploration of parameters I use for
particle filtering using the parallel code.

First, I varied the the parameter r\_threshold against which the ratio
of the quadratic and linear terms of a Taylor series of the Lorenz
vector field is compared.  I did that comparison for several values of
the resample parameters.  Here are the parameters values that I didn't
vary:
\begin{verbatim}
atol: 1e-08
edge_max: 0.2
margin: 0.01
n_initialize: 15000
n_quantized: 4
n_y: 1000
r_extra: 2.0
random_seed: 7
s_augment: 0.0005
t_relax: 50.0
time_step: 0.15
\end{verbatim}

\begin{tabular*}{1.0\linewidth}{rrrrr}
  r\_threshold& Resample$_{\text{max}}$ & Resample$_{\text{target}}$ &min\_time:N\_min &
                                                                    $\hat
                                                                    h$ \\
                                                                    \hline
  *  & 10,000 & 1,000 & \multicolumn{2}{c}{Particle exhaustion} \\
                        \hline
  1e-2  & 20,000 & 2,000 & 584: & 0.950 \\
  others  & 20,000 & 2,000 & \multicolumn{2}{c}{Particle exhaustion} \\
                        \hline 
  1e-2 & 20,000 & 5,000 & 584:96 & 0.942   \\
  3e-3 & 20,000 & 5,000 & 584:51 & 0.952   \\
  1e-3 & 20,000 & 5,000 & 396:0 &   \\
  3e-4 & 20,000 & 5,000 & 570:0 &   \\
  1e-4 & 20,000 & 5,000 & 584:41 & 0.946  \\ \hline
                        \hline 
  1e-2 & 50,000 & 5,000 & 584:5 & 0.962 \\
  3e-3 & 50,000 & 5,000 & 584:169 & 0.953 \\
  1e-3 & 50,000 & 5,000 & 584:63 & 0.949  \\
  3e-4 & 50,000 & 5,000 & 584:212 & \textbf{0.925}  \\
  1e-4 & 50,000 & 5,000 & 584:45 & 0.953  \\ \hline
                        \hline
  1e-2 & 50,000 & 10,000 & 584:17  & 0.958  \\
  3e-3 & 50,000 & 10,000 & 584:392 & 0.940  \\
  1e-3 & 50,000 & 10,000 & 584:176 & \textbf{0.932}  \\
  3e-4 & 50,000 & 10,000 & 396:0   &        \\
  1e-4 & 50,000 & 10,000 & 584:31  & 0.952  \\ \hline
  %
  1e-2 & 100,000 & 10,000 & 584:62  & 0.954          \\
  3e-3 & 100,000 & 10,000 & 584:373 & 0.948          \\
  1e-3 & 100,000 & 10,000 & 584:101 & \textbf{0.939} \\
  3e-4 & 100,000 & 10,000 & 147:118 & 0.945          \\
  1e-4 & 100,000 & 10,000 & 584:152 & 0.948          \\ \hline
  %
  1e-2 & 200,000 & 20,000 && 0.943          \\
  3e-3 & 200,000 & 20,000 && 0.943          \\
  1e-3 & 200,000 & 20,000 & 584:1349& \textbf{0.929} \\
  3e-4 & 200,000 & 20,000 && 0.931          \\
  1e-4 & 200,000 & 20,000 && 0.940          \\ \hline
  %
  1e-2 & 2,000,000 & 200,000 && 0.942          \\
  3e-3 & 2,000,000 & 200,000 && 0.944          \\
  1e-3 & 2,000,000 & 200,000 && 0.936          \\
  3e-4 & 2,000,000 & 200,000 & 584:994 & \textbf{0.927} \\
  1e-4 & 2,000,000 & 200,000 && 0.942          \\ \hline
\end{tabular*}
Cython RK4 parameter h\_max set to $1e-5$ for table above.

2025-04-04 Found that decreasing atol from 1e-8 to 1e-10 caused
more particle exhaustion.  I was using scipy integrate to make the
data and my own Cython RK4 method for filtering.  I switched to using
Cython RK4 for both the data and filtering.

The runtime for filtering depends on where the data starts, which
depends on the details of how the code relaxes to the attractor.  The
time varies by more than a factor of 2.  Simply changing the RK4
parameter h\_max for relaxing to the attractor (and leaving
h\_max=1.0e-5 for making the data and filtering) yields:\\
\begin{tabular*}{1.0\linewidth}{rrrrr}
  h\_max & $\hat h_{500}$ & real      & user        & minimum N\\ \hline
  1.5e-5 & 0.944         & 3m30.034s & 63m52.943s  & [102]=566 \\
  1.0e-5 & 0.911         & 7m16.065s & 125m19.944s & [109]=242
\end{tabular*}

For studying other parameters, I'll use $h_{\text{max}}=1.5e-5$,
$n_y=5,000$, $r_{\text{threshold}} = 3e-4$, resample
$50,000 \rightarrow 5,000$ and $n_y = 500$.  Thoughts about other
parameters:
\begin{description}
\item[h\_max] Cython Runge-Kutta parameter used to generate data and
  for filtering.  The effect on execution time only starts being
  significant at 3e-05, and it's at small values that the parallel
  code is most effective.  Choose 0.0001 because coarser values
  don't save time and I believe that finer values are more accurate.\\
  \input{h_max.tex}
\item[edge\_max] Divide edges bigger than this.  I don't have a theory
  why some values lead to particle exhaustion.  Picking 0.2 seems safe.\\
  \input{edge_max.tex}
\item[margin] Keep particles this close to boundaries\\
  \input{margin.tex}  
\item[r\_extra] When dividing boxes multiply the number required by
  the ratio of quadratic/linear by r\_extra.\\
  \input{r_extra.tex}
\item[s\_augment] With h\_max = 0.0003\\
  \input{s_augment.tex}
\end{description}

April 10: redo study of $r_{\text{threshold}}$ with h\_max = 0.0001,
edge\_max = 0.2, margin = 0.01, r\_extra = 3.0, s\_augment = 0.001, and
resample = $50,000 \rightarrow 5,000$.\\
  \input{r_threshold.tex}
\end{document}

%%% Local Variables:
%%% mode:latex
%%% End:
