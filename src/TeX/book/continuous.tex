\chapter{Continuous States and Observations and Kalman Filtering}
\label{chap:continuous}

We think of \index{state space model}state space systems with continuously distributed
states and observations in terms of equations like
\begin{subequations}
  \label{eq:contnoise}
  \begin{align}
    \ti{x}{t} &= F(\ti{x}{t-1},t) + \ti{\eta}{t}\\
    \ti{y}{t}   &= G(\ti{x}{t},t) + \ti{\epsilon}{t},
  \end{align}
\end{subequations}
where $X\in\REAL^n$ is the state variable, $Y\in\REAL^m$ is the
observation, and $\ti{\eta}{t}$ and $\ti{\epsilon}{t}$ are noise
terms.  Equations~\eqref{eq:contnoise} define the conditional
probability densities
\begin{equation}
  \label{eq:Cstatetran}
  P_{\ti{X}{t+1}\given \ti{X}{t}}
\end{equation}
and
\begin{equation}
  \label{eq:Cobs}
  P_{\ti{Y}{t}\given \ti{X}{t}}.
\end{equation}
Having each of the noise terms $\ti{\eta}{t}$ and $\ti{\epsilon}{t}$
in Eqns.~\ref{eq:contnoise} be independent of all other noise terms is
sufficient to ensure that the following assumptions hold:
\begin{enumerate}
\item The dynamics of the state variable $X$ are Markov.
\item Given the state at time $t$, the observation $\ti{Y}{t}$ is
  independent of everything else.
\end{enumerate}
These are the same as the assumptions of
Eqns.~\eqref{eq:assume_markov} and \eqref{eq:assume_output} which
characterize HMMs with discrete observations.  In this chapter, we
write forward and backward algorithms by replacing sums of finite
probabilities with integrals over probability densities.  If the
functions $F$ and $G$ are linear in $X$ and the noise terms
$\ti{\eta}{t}$ and $\ti{\epsilon}{t}$ are independent and Gaussian,
then the forward algorithm is called \emph{Kalman Filtering}.

In this chapter we go over the forward and backward algorithms for
continuous states and observations three times.  First in
Section~\ref{sec:integrals} we emphasize the parallel to
Chapter~\ref{chap:algorithms} by simply replacing sums in the
development of that chapter with integrals.  By themselves, the
results are not immediately useful because one must specify parametric
forms for the probability densities and \emph{do} the integrals to
implement the algorithms.  Next, in Section~\ref{sec:LinearGaussian},
we concisely present the algorithms one obtains when the functions $F$
and $G$ in Eqns.~\eqref{eq:contnoise} are linear and the noise terms
$\ti{\eta}{t}$ and $\ti{\epsilon}{t}$ are Gaussian.  We hope this
concise presentation will be useful for readers who want to implement
the algorithms.  Finally, for completeness, in
Section~\ref{sec:KDerive} we demonstrate that in fact the integrals of
Section~\ref{sec:integrals} do yield the formulas of
Section~\ref{sec:LinearGaussian}.

\section{Algorithms with Integrals}
\label{sec:integrals}

Here we write out the forward and backward algorithms for models with
continuously distributed states and observations by simply taking the
descriptions in Chapter \ref{chap:algorithms} and replacing sums with
integrals.

\subsection{Forward Algorithm}
\index{forward algorithm!for continuous states}

Like the forward algorithm for a simple HMM (see Equations
\eqref{eq:ForwardDefinitions}) the forward algorithm for continuous
variables uses each successive observation and calculates the incremental
likelihood
\begin{equation*}
  \ti{\gamma}{t} \equiv \gammax
\end{equation*}
and the three distributions
\begin{align*}
  \alpha(t,x) &\equiv \alphax{X}{t}{t+1}{x} && \text{updated} \\
  a(t,x) &\equiv \StateForecast{X}{x}{t} && \text{forecast} \\
  \tilde a(t,x) &\equiv \JointForecast{X}{x}{t} && \text{joint forecast}.
\end{align*}

Using the distributions $P_{\ti{X}{0}}$ and
$P_{\ti{Y}{0}\given \ti{X}{0}}$ which are parts of the model, we start
by initializing in step~\ref{step:initialize} and then we loop over
the remaining steps for the subsequent observations:
\begin{enumerate}
\item \textbf{Initialize} \label{step:initialize} The calculations
\begin{align}
  \label{eq:ContInitial}
  P_{\ti{X}{0},\ti{Y}{0}} \left(x,\ti{y}{0} \right) &=
  P_{\ti{Y}{0}\given \ti{X}{0}} \left(\ti{y}{0}\given x \right)P_{\ti{X}{0}}
  \left(x \right) \\
                                %
  \ti{\gamma}{0} = P\left(\ti{y}{0} \right) & = \int
  P_{\ti{X}{0},\ti{Y}{0}}
  \left(x,\ti{y}{0} \right) dx \\
                                %
  \alpha(0,x) \equiv \alphax{X}{0}{1}{x} &=
  \frac{P_{\ti{X}{0},\ti{Y}{0}} \left(x,\ti{y}{0}
    \right)}{P\left(\ti{y}{0} \right)}
\end{align}
specify $\ti{\gamma}{0}$, the probability of the first
observation and $\alpha(0,x)$, the conditional distribution of the
first state given the first observation.
\item \textbf{Forecast the state distribution} \index{forecast} Find
  the conditional distribution of the state at the present time given
  the past observations.
\begin{align}
  \label{eq:t274}
  P\left(\ti{x}{t},\ti{x}{t-1}\given \ts{y}{0}{t} \right) &=
  P\left(\ti{x}{t}\given \ti{x}{t-1},\ts{y}{0}{t} \right)
  P\left(\ti{x}{t-1}\given \ts{y}{0}{t} \right) \\
  \label{eq:t275}
  &= P\left(\ti{x}{t}\given \ti{x}{t-1} \right)
  P\left(\ti{x}{t-1}\given \ts{y}{0}{t} \right) \\
  &= P\left(\ti{x}{t}\given \ti{x}{t-1} \right)
  \alpha(t-1,\ti{x}{t-1})\\
                                %
  \label{eq:t277}
  a(t,x) \equiv \StateForecast{X}{x}{t} &= \int
  P\left(\ti{x}{t},\ti{x}{t-1}\given \ts{y}{0}{t} \right) d\ti{x}{t-1}\\
  \label{eq:FIForecast}
  &= \int P_{\ti{X}{1} \given \ti{X}{0}} \left(x|x' \right)
    \alpha(t-1,x') dx'
\end{align}
Here we justify \eqref{eq:t274} by Bayes rule, \eqref{eq:t275} by
the model assumptions, and \eqref{eq:t277} by the definition of a
marginal distribution.
\item \textbf{Calculate the joint forecast} Leaving the state at the
  present time as a free parameter, calculate the joint conditional
  distribution of the state and this observation given past
  observations.
  \begin{align}
    \nonumber
  \tilde a(t,x) & \equiv \JointForecast{X}{x}{t} \\
  \label{eq:t279}
                &= P\left(\ti{y}{t}\given \ti{x}{t},\ts{y}{0}{t} \right)
  \StateForecast{X}{x}{t} \\
  \label{eq:FIUpdate}
  &=P\left(\ti{y}{t}\given \ti{x}{t} \right) a(t,x)
\end{align}
Here we justify \eqref{eq:t279} by Bayes rule and \eqref{eq:FIUpdate} by
the model assumptions.
\item \textbf{Calculate the incremental likelihood}
  Integrate out $\ti{x}{t}$ to get the conditional probability of
  this observation given previous observations
  \begin{align}
    \nonumber
    \ti{\gamma}{t} &\equiv \gammax = \int
  \JointForecast{X}{x}{t} d\ti{x}{t} \\
    \label{eq:Igamma}
    &= \int \tilde a(t,x) dx
\end{align}
\item \textbf{Update the conditional state distribution} \index{update} Use
  Bayes rule to combine \eqref{eq:FIUpdate} and \eqref{eq:Igamma} and get
  the conditional distribution of the present state given all past
  observations and the present observation.
\begin{align}
  \alpha(t,x) &\equiv \alphax{X}{t}{t+1}{x} \\
  &=  \frac{ \JointForecast{X}{x}{t}}{\gammax}\\
  \label{eq:IUpdate}
  &= \frac{\tilde a(t,x)}{\ti{\gamma}{t}}.
\end{align}
\end{enumerate}
Note that aside from normalization, the forward algorithm alternates
between multiplying by the observation likelihood in
\eqref{eq:FIUpdate} and integrating with the state transition
probability in \eqref{eq:FIForecast}.

\subsection{Backward Algorithm}
\index{backward algorithm!for continuous states}

Similarly, the backward algorithm finds a function called the
\index*{backwards forecast},
\begin{equation}
  \label{eq:contbeta}
  \beta(t,x) \equiv \frac{P_{\ts{Y}{t+1}{T}\given \ti{X}{t}}
  \left(\ts{y}{t+1}{T}\given x \right)}{P\left(\ts{y}{t+1}{T}\given \ts{y}{0}{t+1}
               \right)},
\end{equation}
for each time $t$ by starting with $\beta(T-1,x) = 1$ and following with
the recursion
\begin{equation}
  \label{eq:contback}
  \beta(t-1,x) = \int 
  \frac{\beta(t,x') P_{\ti{Y}{t}\given \ti{X}{t}}\left(\ti{y}{t}\given x' \right)
  P_{\ti{X}{t}\given \ti{X}{t-1}}\left(x'\given x \right)}
  {P\left(\ti{y}{t}\given \ts{y}{0}{t} \right)} dx'.
\end{equation}
Note that by replacing the sum over discrete states $s$ in
\eqref{eq:back4} with an integral over continuous states $x'$ one
obtains \eqref{eq:contback}, and that as with the discrete case we
have chosen to define $\beta(t,x)$ so that the conditional
distribution of the state at time $t$ given all of the observations is
\begin{equation}
  \label{eq:contalphabeta}
  \alpha(t,x) \beta(t,x) = P_{\ti{X}{t}\given \ts{Y}{0}{T}}
  \left(x\given \ts{y}{0}{T} \right).
\end{equation}
Defining and evaluating a \emph{\index*{backwards update}} function
\begin{equation}
  \label{eq:BIUpdate}
  b(t,x) \equiv \frac{\beta(t,x)
    P_{\ti{Y}{t}\given \ti{X}{t}}\left(\ti{y}{t}\given x
    \right)} {P\left(\ti{y}{t}\given \ts{y}{0}{t} \right)}
\end{equation}
lets one write Eqn.~\eqref{eq:contback} as the \emph{backwards forecast}
\begin{equation}
  \label{eq:BIForecast}
  \beta(t-1,x) = \int b(t,x') P_{\ti{X}{t}\given \ti{X}{t-1}}\left(x'\given x
  \right) dx'
\end{equation}
which may make evaluating the integral easier and emphasizes the
alternation between multiplying by the observation likelihood in
\eqref{eq:BIUpdate} and integrating with the transition probability
\eqref{eq:BIForecast}.

\section{Linear Gaussian Systems}
\label{sec:LinearGaussian}

If the functions $F$ and $G$ in Eqn.~\eqref{eq:contnoise} are linear
in $x$, the noise terms $\ti{\eta}{t}$ and $\ti{\epsilon}{t}$ are \iid
and Gaussian\footnote{We assume \emph{identical} distributions only to
  simplify the notation.  The procedures generalize easily to time
  dependent noise terms.  The notation $X\sim\Normal(\mu,\Sigma)$
  means, ``The random variable $X$ has a Gaussian distribution with
  mean $\mu$ and covariance $\Sigma$.} with $\ti{\eta}{t} \sim
\Normal(0,\Sigma_\eta)$ and $\ti{\epsilon}{t} \sim
\Normal(0,\Sigma_\epsilon)$, and the distribution of the initial state
$\ti{X}{0}$ is also Gaussian, then we can write
\begin{subequations}
  \label{eq:LinearG}
  \begin{align}
  \ti{X}{0} & \sim \Normal\left(\mu_{\ti{X}{0}},\Sigma_{\ti{X}{0}}
  \right)\\
                                %
  \ti{x}{t} &= \ti{F}{t} \cdot \ti{x}{t-1} + \ti{\eta}{t} &
                                                            \ti{\eta}{t} &\sim \Normal\left( 0, \Sigma_\eta \right) \\
    P(\ti{x}{t}\given \ti{x}{t-1}) &=
                                    \NormalE{F\ti{x}{t-1}}{\Sigma_\eta}{\ti{x}{t}} \\
  \ti{y}{t} &= \ti{G}{t} \cdot \ti{x}{t} + \ti{\epsilon}{t} &
  \ti{\epsilon}{t} &\sim \Normal\left( 0, \Sigma_\epsilon \right) \\
    P(\ti{y}{t}\given \ti{x}{t}) &=
                                    \NormalE{G\ti{x}{t}}{\Sigma_\epsilon}{\ti{y}{t}},
  \end{align}
\end{subequations}
where $\ti{F}{t}$ and $\ti{G}{t}$ are matrices.  We use the notation
$\Normal\left( \mu, \Sigma \right)$ for a Gaussian distribution with
mean $\mu$ and covariance $\Sigma$, and we denote the value of a
Gaussian probability density at $v$ by $\NormalE{\mu}{\Sigma}{v}$ \ie
if $V$ is an $n$-dimensional random variable $V \sim \Normal\left( \mu,
  \Sigma \right)$ then $ P\left(v \right) = \NormalE{\mu}{\Sigma}{v}
\equiv \frac{1}{\sqrt{(2\pi)^n \left|\Sigma\right|}} e^{-\frac{1}{2}
  (v-\mu)\transpose \Sigma^{-1} (v-\mu)}$.

We describe the forward and backward algorithms for linear Gaussian
systems in terms of the quantities listed below.  Our notation for
these quantities emphasizes the similarity to the calculations for
discrete processes in Chapter~\ref{chap:algorithms}.  In particular
the Greek subscripts $\alpha$ and $\beta$ denote the forward updated
distribution and the backwards forecast distribution respectively while
the Roman subscripts $a$ and $b$ denote the forward forecast
distribution and the backwards updated distributions respectively.
The assumptions of Eqns.~\eqref{eq:LinearG} imply that the
distributions described by these parameters are also Gaussian.
\begin{description}
\item[$\bm{\ti{\mu_\alpha}{t}}$ and $\bm{\ti{\Sigma_\alpha}{t}}$]
  (Note \emph{Greek} subscript.) are the parameters of the
  \emph{updated} state distribution\footnote{For the quantities that
    we call $\ti{\mu_\alpha}{t}$ and $\ti{\Sigma_\alpha}{t}$,
    Maybeck\cite{Maybeck82} uses the notation $\hat x(t^+_i)$ and
    $P(t^+_i)$ and Kailath et al.\cite{KSH00} use $\hat x_{i|i}$ and
    $P_{i|i}$ respectively.}, \ie,
  \begin{equation*}
    P\left(\ti{x}{t}\given \ts{y}{0}{t+1} \right) =
    \NormalE{\ti{\mu_\alpha}{t}}{\ti{\Sigma_\alpha}{t}}{\ti{x}{t}}.
  \end{equation*}
\item[$\bm{\ti{\mu_a}{t}}$ and $\bm{\ti{\Sigma_a}{t}}$] (Note
  \emph{Roman} subscript.) are the parameters of the one step
  \emph{forecast} of the state distribution\footnote{For the
    quantities that we call $\ti{\mu_a}{t}$ and $\ti{\Sigma_a}{t}$,
    Maybeck\cite{Maybeck82} uses the notation $\hat x(t^-_i)$ and
    $P(t^-_i)$ and Kailath et al.\cite{KSH00} use $\hat x_{i+1}$ and
    $P_{i+1}$ respectively.}, \ie,
  \begin{equation*}
    P \left(\ti{x}{t}\given \ts{y}{0}{t} \right) =
    \NormalE{\ti{\mu_a}{t}}{\ti{\Sigma_a}{t}}{\ti{x}{t}}.
  \end{equation*}
\item[$\bm{\ti{\mu_\gamma}{t}}$ and $\bm{\ti{\Sigma_\gamma}{t}}$] are
  the parameters of the conditional probability of the observation at
  time $t$ given all previous observations, \ie
  \begin{equation*}
    P\left(\ti{y}{t}\given \ts{y}{0}{t} \right) =
    \NormalE{\ti{\mu_\gamma}{t}}{\ti{\Sigma_\gamma}{t}}{\ti{y}{t}}
    \equiv \ti{\gamma}{t}.
  \end{equation*}
  Neither the forward nor the backwards Kalman filter uses the $\gamma$
  terms, but they are useful for calculating the likelihood for model
  parameters.
\item[$\bm{\ti{N_\beta}{t},\ti{\mu_\beta}{t}}$ and
  $\bm{\ti{\Sigma_\beta}{t}}$] are the parameters\footnote{On page
    342, Kailath et al.\cite{KSH00} use $\hat x_i^b$ to denote the
    quantity that we call $\ti{\mu_\beta}{t}$.} of the
  backwards forecast function $\beta(t,x)$, which as a ratio of
  Gaussian functions is itself an unnormalized Gaussian.  We define
  $\ti{N_\beta}{t}$ by
  \begin{equation*}
    \frac{\beta(t,x)}{\ti{N_\beta}{t}} =
    \NormalE{\ti{\mu_\beta}{t}}{\ti{\Sigma_\beta}{t}}{x}.
  \end{equation*}
\item[$\bm{\ti{\mu_b}{t}}$ and $\bm{\ti{\Sigma_b}{t}}$] are the
  mean\footnote{Kailath et al.\cite{KSH00} use $\hat x_{i|i}^b$ to
    denote the quantity that we call $\ti{\mu_b}{t}$.} and covariance
  of the backwards update function $b(t,x)$ (see Eqn.~\eqref{eq:BUpdate})
  which is an intermediate term in the backward algorithm.  Notice
  that the parameters of the forward forecast have Roman subscripts
  while the parameters of the backward forecast have Greek subscripts.
\item[$\bm{\ti{\mu_{\alpha\beta}}{t}}$ and
  $\bm{\ti{\Sigma_{\alpha\beta}}{t}}$] are the mean and covariance
  of the best estimate of the state at time $t$ given all of the
  observations, \ie $P_{\ti{X}{t}\given \ts{Y}{0}{T}} \left(x\given \ts{y}{0}{T}
  \right) =
  \NormalE{\ti{\mu_{\alpha\beta}}{t}}{\ti{\Sigma_{\alpha\beta}}{t}}{x}$.
\end{description}


\subsection{Kalman Filter: The Forward Algorithm}
\index{Kalman filter}

The following two step recursion is called Kalman
filtering\footnote{There are many more detailed presentations of
  Kalman filters, \eg, Maybeck\cite{Maybeck82}, Kailath et
  al.\cite{KSH00}, Jacobs\cite{Jacobs93}, and Brown and
  Hwang\cite{Brown97}.} and it implements the forward algorithm: %
\newcommand{\G}{ \ti{G}{t} } \newcommand{\GT}{\left( \G
  \right)\transpose} \newcommand{\SX}{ \ti{\Sigma_a}{t} }
\begin{description}
\item[Calculate the forecast of the distribution of the state]
  \begin{subequations}
    \label{eq:KFore}
    \begin{align}
      \label{eq:KForeMu}
      \ti{\mu_a}{t} &= \ti{F}{t} \cdot \ti{\mu_\alpha}{t-1}\\
      \label{eq:KForeSigma}
      \ti{\Sigma_a}{t} &= \ti{F}{t} \cdot \ti{\Sigma_\alpha}{t-1}
      \cdot \left(\ti{F}{t}\right)\transpose + \Sigma_\eta
    \end{align}
  \end{subequations}
\item[Update the distribution of the current state using
  $\bm{\ti{y}{t}}$]
                           %
  \begin{subequations}
    \label{eq:KUpdate}
    \begin{align}
      \label{eq:KUpdateSigma}
      \left( \ti{\Sigma_\alpha}{t} \right)^{-1} &= \left(
        \ti{\Sigma_a}{t} \right)^{-1} + \GT \Sigma_\epsilon^{-1} \G \\
      \ti{\mu_\alpha}{t} &= \ti{\mu_a}{t} +
      \ti{\Sigma_{\alpha}}{t} \left( \ti{G}{t} \right)\transpose
      \Sigma_\epsilon^{-1} \big[\ti{y}{t} - \ti{G}{t}
      \ti{\mu_a}{t}\big]
    \end{align}
  \end{subequations}
\end{description}
Note:
\begin{itemize}
\item Equations~\eqref{eq:KUpdate} are usually presented in the
  equivalent but computationally more efficient form
  \begin{subequations}
    \label{eq:KalmanGain}
  \begin{align}
    \ti{\mu_\alpha}{t} &= \ti{\mu_a}{t} + \ti{K}{t} \left( \ti{y}{t} -
    \ti{G}{t} \ti{\mu_a}{t} \right) \\
    \ti{\Sigma_\alpha}{t} &= \left( \id - \ti{K}{t} \G \right) \SX 
  \end{align}
  where
  \begin{equation}
    \ti{K}{t} \equiv \SX \GT \left( \G \SX \GT + \Sigma_\epsilon \right)^{-1}
  \end{equation}
  \end{subequations}
  is called \emph{the \index*{Kalman gain matrix}}\footnote{This
    computationally more efficient form was Kalman's principle
    contribution.}  \index{matrix!Kalman gain}%
  (See Eqn.~\eqref{eq:KalmanGain}.).
\item One can calculate the log likelihood of a model by summing the
  increments
  \begin{equation*}
    \log\left( P\left(\ts{y}{0}{T} \right)\right) = \sum_{t=0}^{T-1}
    \log\left(P \left(\ti{y}{t}\given \ts{y}{0}{t} \right) \right)
  \end{equation*}
  and calculating each increment as
  \begin{equation*}
    P \left(\ti{y}{t}\given \ts{y}{0}{t} \right) =
    \NormalE{\ti{\mu_\gamma}{t}}{\ti{\Sigma_\gamma}{t}}{\ti{y}{t}}
  \end{equation*}
  where
  \begin{align*}
    \ti{\mu_\gamma}{t} &= \ti{G}{t} \ti{\mu_a}{t}\\
    \ti{\Sigma_\gamma}{t} &= \ti{G}{t} \ti{\Sigma_a}{t} \left(
    \ti{G}{t} \right)\transpose + \Sigma_\epsilon\\
    \log\left( P \left(\ti{y}{t}\given \ts{y}{0}{t} \right) \right) &= -
    \frac{1}{2} \Big( n \log(2\pi) + \log \left( \left|
    \ti{\Sigma_\gamma}{t} \right| \right) \\ & \quad \quad \quad
    + \big( \ti{y}{t} - \ti{\mu_\gamma}{t} \big)\transpose
    \left( \ti{\Sigma_\gamma}{t} \right)^{-1}
    \big( \ti{y}{t} - \ti{\mu_\gamma}{t} \big)
    \Big)
  \end{align*}
\end{itemize}

\subsection{The Backward Algorithm}

We calculate $\ti{\mu_\beta}{t}$ and $\ti{\Sigma_\beta}{t}$ as defined
in Eqn.~\eqref{eq:contbeta} with the following recursion that goes
through the observations in reverse order.

\begin{description}
\item[Update the distribution of the current state using $\ti{y}{t}$]
  \begin{subequations}
    \label{eq:BUpdate}
    \begin{align}
    \left(\ti{\Sigma_b}{t} \right)^{-1} &= \left(\ti{\Sigma_\beta}{t}
    \right)^{-1} + \left( \ti{G}{t} \right)\transpose
    \left(\Sigma_\epsilon
    \right)^{-1} \ti{G}{t} \\
        \ti{\mu_b}{t} &= \ti{\mu_\beta}{t} + \ti{\Sigma_{b}}{t}
        \left( \ti{G}{t} \right)\transpose \Sigma_\epsilon^{-1}
        \big[\ti{y}{t} - \ti{G}{t} \ti{\mu_\beta}{t}\big],
  \end{align}
  \end{subequations}
\item[Forecast of the distribution of the state backward in time]
  \begin{subequations}
    \label{eq:BFore}
    \begin{align}
      \ti{\mu_\beta}{t-1} &= \left( \ti{F}{t} \right)^{-1}
      \ti{\mu_b}{t} \\
      \label{eq:SigmaBeta}
      \ti{\Sigma_\beta}{t-1} &= \left( \ti{F}{t} \right)^{-1} \left(
        \Sigma_\eta + \ti{\Sigma_b}{t} \right) \left( \left( \ti{F}{t}
        \right)^{-1} \right)\transpose
    \end{align}
  \end{subequations}
\end{description}
Note:
\begin{itemize}
\item As for the forward recursion, the update formulas are usually
  presented in a computationally more efficient form using a gain
  matrix (See Eqn.~\eqref{eq:KalmanGainBack}).
\item Ideally one would initialize the backward algorithm with
  \begin{align*}
    \left( \ti{\Sigma_\beta}{T-1} \right)^{-1} &= 0\\
    \ti{\mu_\beta}{T-1} &= 0
  \end{align*}
  but that would make $\left( \ti{\Sigma_b}{T-1} \right)^{-1}$
  uninvertible and preclude using Eqn.~\eqref{eq:SigmaBeta} to
  evaluate $\ti{\Sigma_\beta}{T-1}$.  One can address the problem by
  initializing $\ti{\Sigma_\beta^{-1}}{T-1}$ with small values, or by using
  the \emph{\index*{inverse covariance form}} of the algorithm (see
  Section~\ref{sec:DetailInverse}.).
\end{itemize}

\subsection{Smoothing}
\index{smoothing}

The conditional distribution of the state at time $t$ given all of the
data is Gaussian and therefore specified by its covariance and mean, \ie,
\begin{equation*}
   P \left(\ti{x}{t}\given \ts{y}{0}{T} \right) = \NormalE{\ti{\mu_{\alpha
   \beta}}{t}}{\ti{\Sigma_{\alpha \beta}}{t}}{\ti{x}{t}},
\end{equation*}
where
\begin{subequations}
  \label{eq:smoothing}
  \begin{align}
    \left( \ti{\Sigma_{\alpha \beta}}{t} \right)^{-1} &= \left(
      \ti{\Sigma_{\alpha}}{t} \right)^{-1} + \left(
      \ti{\Sigma_{\beta}}{t} \right)^{-1} ~\text{ and} \\
    \ti{\mu_{\alpha \beta}}{t} &=
    \ti{\Sigma_{\alpha \beta}}{t} \left( \left(
        \ti{\Sigma_{\alpha}}{t} \right)^{-1} \ti{\mu_{\alpha}}{t} +
      \left( \ti{\Sigma_{\beta}}{t} \right)^{-1} \ti{\mu_{\beta}}{t}
    \right)
\end{align}
\end{subequations}
are combinations of the \emph{forward update} parameters and the
\emph{backward prediction} parameters.  Such use of all of the
observations to estimate the state sequence is called
\emph{smoothing}.  Combining forward update parameters and backward
update parameters, \ie, $\alpha$ and $b$, for smoothing is an error.

\section{Algorithm Derivations and Details}
\label{sec:KDerive}

Here we connect the integrals that describe the forward and backward
algorithms (Eqns.~\eqref{eq:ContInitial}-\eqref{eq:BUpdate}) to the
formulas (Eqns.~\eqref{eq:KFore}-\eqref{eq:smoothing}).  In this
context each distribution is Gaussian.  So we can characterize each
distribution by its mean and covariance and ignore normalization.
Given two $d$-dimensional Gaussian density functions
\begin{align*}
  P_1(x) &\equiv \frac{1}{\sqrt{(2\pi)^d\left| \Sigma_1 \right|}}\exp \left(-\frac{1}{2}
    (x-\mu_1)\transpose \Sigma_1^{-1}(x-\mu_1) \right) \equiv
           \NormalE{\mu_1}{\Sigma_1}{x} &&\text{and} \\
  P_2(x) &\equiv \frac{1}{\sqrt{(2\pi)^d\left| \Sigma_2 \right|}}\exp \left(-\frac{1}{2}
    (x-\mu_2)\transpose \Sigma_2^{-1}(x-\mu_2)  \right) \equiv
           \NormalE{\mu_2}{\Sigma_2}{x},
\end{align*}
we can characterize their product or ratio by respectively adding or
subtracting their exponents (see Equation~\eqref{eq:GaussianProduct}
on page \pageref{eq:GaussianProduct}).

\subsection{Forward Kalman Filter}
\label{sec:DetailForward}

Recall that the forward algorithm for a simple HMM (see
Eqn.~\eqref{eq:2LineForward} on page \pageref{eq:2LineForward})
alternates between multiplying a state distribution by a likelihood
and multiplying the result by the state transition probability matrix.
In the forward Kalman filter the state transition matrix is a Gaussian
and the sum is replaced by an integral.

The basic loop consists of steps \ref{PXforecast} through
\ref{PXupdate} below.  In the first iteration, we use the model
parameters that describe $P\left(\ti{x}{0} \right)$ and proceed
directly to step~\ref{PYforecast}.
\begin{enumerate}
\item \label{PX1} \textbf{Initialize with
    $\bm{\ti{\mu_a}{0}}$ and $\bm{\ti{\Sigma_a}{0}}$.}  We
  initialize the recursion using the model parameters $\ti{\mu_a}{0}$
  and $\ti{\Sigma_a}{0}$ of $P(\ti{x}{0})$ and entering the loop at
  step~\ref{PYforecast} to calculate $\ti{\mu_\gamma}{0}$ and
  $\ti{\Sigma_\gamma}{0}$ by setting $t=0$.
\item \label{PXforecast} \textbf{Calculate the state forecast,
    $\bm{P\left(\ti{x}{t}\given \ts{y}{0}{t} \right)}$.}  From
  Eqn.~\eqref{eq:FIForecast}
  \begin{equation}
    \label{eq:ForecastKIntegral}
    a(t,x) = \int \NormalE{Fx'}{\Sigma_\eta}{x} \alpha((t-1), x') dx'
  \end{equation}
  Rather than evaluating the integral to find the distribution, we can
  specify it completely by calculating its first two moments.  Since
  \begin{equation*}
    \ti{x}{t} = \ti{F}{t} \ti{x}{t-1} + \ti{\eta}{t}.
  \end{equation*}
  the mean is
  \begin{align}
    \ti{\mu_a}{t} &= \EV_{
      \ti{x}{t-1},\ti{\eta}{t}\given \ts{y}{0}{t}} \left[
      \ti{F}{t}\ti{X}{t-1} + \ti{\eta}{t} \right] \nonumber \\
    &= \EV_{\ti{x}{t-1},\ti{\eta}{t}\given \ts{y}{0}{t}}
      \ti{F}{t}\ti{X}{t-1} +
      \EV_{\ti{x}{t-1},\ti{\eta}{t}\given \ts{y}{0}{t}} \ti{\eta}{t} \nonumber \\
    \label{eq:etaIndependent}
    &= \EV_{ \ti{x}{t-1}\given \ts{y}{0}{t}}
    \ti{F}{t}\ti{X}{t-1}  + \EV_{\eta} \ti{\eta}{t} \\
                                 %
     &= \ti{F}{t}\ti{\mu_\alpha}{t-1}. \nonumber
   \end{align}
   The key step in the above sequence is
   Eqn.~\eqref{eq:etaIndependent} which we justify by observing that
   the distribution of the noise $\ti{\eta}{t}$ is independent of time
   and independent of $\ti{x}{\tau}$, and $\ti{y}{\tau}$ for all
   earlier times $\tau$.  Similarly we calculate the
   variance by
   \begin{align}
     \ti{\Sigma_a}{t} &= \EV_{
       \ti{x}{t-1},\ti{\eta}{t}\given \ts{y}{0}{t}} \big[
     \left( \ti{F}{t}\ti{X}{t-1} + \ti{\eta}{t} - \ti{\mu_a}{t-1}
     \right) \nonumber\\
     & \quad \times \left( \ti{F}{t}\ti{X}{t-1} + \ti{\eta}{t} -
       \ti{\mu_a}{t-1} \right)\transpose \big] \\
                                %
    &= \ti{F}{t}\ti{\Sigma_\alpha}{t-1}\ti{F}{t}\transpose +
    \Sigma_\eta .
  \end{align}
  Thus Eqn.~\eqref{eq:KFore} implements the integral of
  Eqn.~\eqref{eq:FIForecast}.
\item \label{PYforecast} \textbf{Calculate
    $\bm{P\left(\ti{y}{t}\given \ts{y}{0}{t} \right)}$.}  Using
  \begin{equation*}
    \ti{y}{t} = \ti{G}{t}\ti{x}{t} + \ti{\epsilon}{t}
  \end{equation*}
  we calculate the mean and covariance of the distribution of the
  forecast observation as follows
  \begin{align}
    \ti{\mu_\gamma}{t} &= \EV_{
      \ti{x}{t},\ti{\epsilon}{t}\given \ts{y}{0}{t}}
    \ti{G}{t}\ti{X}{t} + \ti{\epsilon}{t} \nonumber \\
                                %
    \label{eq:mugamma}
    &= \ti{G}{t}\ti{\mu_a}{t}\\
                                %
    \ti{\Sigma_\gamma}{t} &= \EV_{
      \ti{x}{t},\ti{\epsilon}{t}\given \ts{y}{0}{t}}
    \left( \ti{G}{t}\ti{X}{t} + \ti{\epsilon}{t} -
      \ti{\mu_\gamma}{t} \right) \nonumber \\
    &\quad\times \left( \ti{G}{t}\ti{X}{t} +
      \ti{\epsilon}{t} - \ti{\mu_\gamma}{t}
    \right)\transpose \nonumber \\
                                %
    \label{eq:Sigmagamma}
    &= \ti{G}{t}\ti{\Sigma_a}{t}\ti{G}{t}\transpose +
    \Sigma_\epsilon
  \end{align}
\item \label{PZforecast} \textbf{Calculate $\bm{P\left(\ti{x}{t},
        \ti{y}{t}\given \ts{y}{0}{t} \right)}$.}  The forecast
  distribution of the joint variable
  \begin{equation*}
    \ti{z}{t} =
    \begin{bmatrix}
      \ti{x}{t}\\
      \ti{y}{t}
    \end{bmatrix}
  \end{equation*}
  is characterized by
  \begin{equation*}
    \mu_z =
    \begin{bmatrix}
      \ti{\mu_a}{t}\\
      \ti{\mu_\gamma}{t}      
    \end{bmatrix}
  \end{equation*}
  and
  \begin{equation}
    \label{eq:cont-temp}
    \Sigma_z  =
    \begin{bmatrix}
      \ti{\Sigma_a}{t} & \ti{\Sigma_a}{t} (\ti{G}{t})\transpose 
      \\ \ti{G}{t} \ti{\Sigma_a}{t}&\ti{\Sigma_\gamma}{t} 
    \end{bmatrix}\equiv
    \begin{bmatrix} A & C \\ C\transpose & B \end{bmatrix}.
  \end{equation}
  We derive the off diagonal terms of $\Sigma_z$ in
  Eqn.~\eqref{eq:cont-temp} as follows
  \begin{align}
    C &= \EV_{\ti{x}{t},\ti{\epsilon}{t}\given \ts{y}{0}{t}}
    \big( \ti{x}{t} - \ti{\mu_a}{t} \big) \big( \ti{y}{t}
      - \ti{\mu_\gamma}{t} \big)\transpose \nonumber \\
    &=  \EV_{\ti{x}{t}\given \ts{y}{0}{t}}
    \big( \ti{x}{t} - \ti{\mu_a}{t} \big)
    \big( \ti{x}{t} - \ti{\mu_a}{t} \big)\transpose
    \left(\ti{G}{t} \right)\transpose \nonumber \\
    & \quad +
    \EV_{\ti{x}{t},\ti{\epsilon}{t}\given \ts{y}{0}{t}}
    \big( \ti{x}{t} - \ti{\mu_a}{t} \big) \big( \ti{\epsilon}{t}
    \big) \nonumber \\
    \label{eq:cont:C}
      &= \ti{\Sigma_{a}}{t} \big(\ti{G}{t} \big)\transpose .
  \end{align}
  We use the terms $A$, $B$ and $C$ in the right block matrix of
  \eqref{eq:cont-temp} to match \eqref{eq:MI:ABCDEF} on page
  \pageref{eq:MI:ABCDEF} of the appendix where we derive expressions
  for $D$, $E$ and $F$ in 
    \begin{equation*}
      \begin{bmatrix} A & C \\ C\transpose & B \end{bmatrix}^{-1} \equiv
      \begin{bmatrix} D & F \\ F\transpose & E \end{bmatrix}.
    \end{equation*}
    we will use those expressions when we calculate the conditional
    distribution of $\ti{x}{t}$ given $\ti{y}{t}$ in
    step~\ref{PXupdate}.

    Note that the calculation in this step is equivalent to completing
    the square in the sum of the exponents we would get by multiplying
    $P(\ti{y}{t} \given \ti{x}{t})$ and $a(t,x)$ in
    \eqref{eq:FIUpdate}, \ie,
    \begin{align}
      \nonumber
      \NormalE{\mu_{\tilde a}}{\Sigma_{\tilde a}}{x,\ti{y}{t}}
      &\equiv \JointForecast{X}{x}{t} \\
      \label{eq:NormalJointForecast}
      &= \NormalE{Gx}{\Sigma_\epsilon}{\ti{y}{t}} \NormalE{\mu_a}{\Sigma_a}{x}
    \end{align}
  \item \label{PXupdate} \textbf{Calculate the state update,
      $\bm{P\left(\ti{x}{t}\given \ts{y}{0}{t+1} \right)}$.}  With the
    actual value of $\ti{y}{t}$ and the joint distribution of
    $\ti{x}{t}$ and $\ti{y}{t}$ given $\ts{y}{0}{t}$ from step
    \ref{PZforecast}, we use Eqn.~\eqref{eq:Gauss-Conditional} from
    page \pageref{eq:Gauss-Conditional} in the appendix to write the
    parameters of the conditional
    $P\left(\ti{x}{t}\given \ts{y}{0}{t+1} \right)$ as
  \begin{subequations}
    \label{eq:UpdateRaw}
    \begin{align}
      \ti{\Sigma_\alpha}{t} &= D^{-1} \\
      \ti{\mu_\alpha}{t} &= \ti{\mu_a}{t} + CB^{-1} \left(
        \ti{y}{t} - \ti{\mu_\gamma}{t}\right).
    \end{align}
  \end{subequations}
  Note the following equations and justifications:
  \begin{align*}
    E^{-1} &= B - C\transpose A^{-1}C && \text{See \eqref{eq:MI:E}}\\
    &= \ti{\Sigma_\gamma}{t} - \ti{G}{t}\ti{\Sigma_a}{t} \left(
    \ti{G}{t}\right)\transpose && \text{See \eqref{eq:cont-temp}}\\
    &= \Sigma_\epsilon && \text{See \eqref{eq:Sigmagamma}}\\
    CB^{-1} &= D^{-1}A^{-1}CE && \text{See \eqref{eq:MI:F}} \\
    &= \ti{\Sigma_\alpha}{t} \left( \ti{G}{t}
    \right)\transpose E && \text{See \eqref{eq:cont:C}}\\
    &= \ti{\Sigma_\alpha}{t} \left( \ti{G}{t}
    \right)\transpose (\Sigma_\epsilon)^{-1}\\
    D &= A^{-1} + A^{-1} CEC\transpose A^{-1} && \text{See \eqref{eq:MI:D}}.
  \end{align*}
  Thus
  \begin{subequations}
    \label{eq:FUpdateAgain}
    \begin{align}
      \left( \ti{\Sigma_\alpha}{t} \right)^{-1} &= \left(
        \ti{\Sigma_a}{t} \right)^{-1} + \left( \ti{G}{t}
        \right)\transpose \Sigma_\epsilon^{-1} \ti{G}{t} \\
      \ti{\mu_\alpha}{t} &= \ti{\mu_a}{t} +
      \ti{\Sigma_{\alpha}}{t} \left( \ti{G}{t} \right)\transpose
      \Sigma_\epsilon^{-1} \big[\ti{y}{t} - \ti{G}{t}
      \ti{\mu_a}{t}\big]
    \end{align}
  \end{subequations}
  which are the update equations in \eqref{eq:KUpdate}.
\end{enumerate}

As presented in Eqns.~\eqref{eq:KFore} and \eqref{eq:KUpdate}, the
forward algorithm requires two matrix inversions per iteration.  First
one must invert $\left( \ti{\Sigma_\alpha}{t-1}\right)^{-1}$ for
Eqn.~\eqref{eq:KForeSigma}, then one must invert $\ti{\Sigma_a}{t-1}$
for Eqn.~\eqref{eq:KUpdateSigma}.  Each of these is an $n\times n$
matrix where $n$ is the dimension of the state $x$.  One can avoid
these inversions either by keeping track of state space covariances or
by keeping track of \emph{inverse} state space covariances.  Either
choice improves the numerical speed and accuracy of the algorithm.
Kalman's form keeps track of state space covariances and uses the
\emph{\index*{Kalman gain matrix}} %
\index{matrix!Kalman gain}%
which in the notation of Eqn.~\eqref{eq:cont-temp} is $K=CB^{-1}$.  To
get Eqn.~\eqref{eq:UpdateRaw} into Kalman's form, note that by
Eqn.~\eqref{eq:MI:D} on page \pageref{eq:MI:D},
$D^{-1} = A -CB^{-1} C\transpose$, and thus
\begin{subequations}
  \label{eq:KalmanGain}
  \begin{align}
    \ti{\Sigma_\alpha}{t} &= \big(\id - \ti{K}{t} \ti{G}{t}
    \big) \ti{\Sigma_a}{t} \\
    \ti{\mu_\alpha}{t} &= \ti{\mu_a}{t} + \ti{K}{t} \left(
      \ti{y}{t} - \ti{\mu_\gamma}{t}\right).
  \end{align}
\end{subequations}
Using Eqns.~\eqref{eq:Sigmagamma}, \eqref{eq:cont-temp} and
\eqref{eq:cont:C}, we find the Kalman gain matrix in terms of known
quantities to be
\begin{align*}
  CB^{-1} &\equiv \ti{K}{t}\\
  &= \ti{\Sigma_{a}}{t} \big(\ti{G}{t} \big)\transpose \big(
  \ti{\Sigma_\gamma}{t}\big)^{-1}\\
  &= \ti{\Sigma_{a}}{t} \big(\ti{G}{t} \big)\transpose \big(\ti{G}{t}\ti{\Sigma_a}{t}\ti{G}{t}\transpose +
    \Sigma_\epsilon \big)^{-1}.
\end{align*}
The formula requires inversion of an $m\times m$ matrix where $m$, the
dimension of the observation $y$, is usually less than the dimension of
the state $x$.

\subsection{Backward Recursion}
\label{sec:DetailBack}
\index{backward algorithm!for continuous states}

On page \pageref{eq:BIUpdate} we described the backwards recursion as
alternating between multiplying a prior by a likelihood in
\eqref{eq:BIUpdate} and integrating the product of a state probability
and a state transition probability in \eqref{eq:BIForecast}.

We should initialize the backward recursion with a uniform
distribution $\beta(T-1,x) = 1$ or $\Sigma^{-1}_{\beta(T-1)} = 0$.  We
will ignore that for now and focus on the two alternating steps:
\begin{enumerate}
\item \textbf{Backwards Update} ignoring normalization, given the
  backwards forecast $\beta(t,x)$ the update formula is
  \begin{align}
    \nonumber
    b(t,x) &= \beta(t,x) P(y[t] \given x) \\
    \label{eq:NormalJointBackcast}
           &= \NormalE{\mu_{\beta(t,x)}}{\Sigma_{\beta(t,x)}}{x} \NormalE{G[t]x}{\epsilon}{\ti{y}{t}}. 
  \end{align}
  Notice that the form of \eqref{eq:NormalJointBackcast} matches the
  form of \eqref{eq:NormalJointForecast} on page
  \pageref{eq:NormalJointForecast} in the forward recursion.  After
  taking the conditional given the actual value of $\ti{y}{t}$ we copy
  the result from \eqref{eq:FUpdateAgain} and obtain
    \begin{align*}
      \left( \ti{\Sigma_b}{t} \right)^{-1} &= \left(
        \ti{\Sigma_\beta}{t} \right)^{-1} + \left( \ti{G}{t}
        \right)\transpose \Sigma_\epsilon^{-1} \ti{G}{t} \\
      \ti{\mu_b}{t} &= \ti{\mu_\beta}{t} +
      \ti{\Sigma_{b}}{t} \left( \ti{G}{t} \right)\transpose
      \Sigma_\epsilon^{-1} \big[\ti{y}{t} - \ti{G}{t}
      \ti{\mu_\beta}{t}\big]
    \end{align*}
  \item \textbf{Backwards Forecast} compare
    \eqref{eq:ForecastKIntegral} use \eqref{eq:BIForecast}
    \begin{align}
      \label{eq:BackwardKIntrgral}
      \beta(t-1,x) &= \int b(t,x')\NormalE{Fx}{\Sigma_\eta}{x'} dx' 
    \end{align}
    Want:
  \begin{subequations}
    \begin{align}
      \ti{\mu_\beta}{t-1} &= \left( \ti{F}{t} \right)^{-1}
      \ti{\mu_b}{t} \\
      \ti{\Sigma_\beta}{t-1} &= \left( \ti{F}{t} \right)^{-1} \left(
        \Sigma_\eta + \ti{\Sigma_b}{t} \right) \left( \left( \ti{F}{t}
        \right)^{-1} \right)\transpose
    \end{align}
  \end{subequations}
\end{enumerate}

So
\begin{align*}
  \ti{\Sigma_\beta}{t-1} &= (\ti{F}{t})^{-1} ( \Sigma_\eta +
  \ti{\Sigma_b}{t} ) \left( \left( \ti{F}{t} \right)^{-1}
  \right)\transpose
  \\
  \ti{\mu_\beta}{t-1} &= (\ti{F}{t})^{-1}\ti{\mu_b}{t}.
\end{align*}

\subsection{Smoothing}
\label{sec:DetailSmoothing}
\index{smoothing}

We have defined $\alpha(t,x)$ and $\beta(t,x)$ so that
\begin{equation*}
   P_{\ti{X}{t}\given \ts{Y}{0}{T}} \left(x\given \ts{y}{0}{T} \right) =
   \alpha(t,x) \beta(t,x).
\end{equation*}
(See Eqn.~\eqref{eq:contalphabeta}.)  In fact
$P_{\ti{X}{t}\given \ts{Y}{0}{T}}$ is Gaussian, and we denote its parameters
$\ti{\mu_{\alpha \beta}}{t}$ and $\ti{\Sigma_{\alpha \beta}}{t}$.
Examining the exponential terms in $\alpha(t,x) \beta(t,x)$ we find
(suppressing the time indices)
\begin{align*}
  &\left( x - \mu_\alpha \right)\transpose \Sigma_\alpha^{-1} \left( x
    - \mu_\alpha \right) + \left( x - \mu_\beta \right)\transpose
  \Sigma_\beta^{-1} \left( x - \mu_\beta \right)\\
  & = x\transpose \left( \left( \ti{\Sigma_{\alpha}}{t} \right)^{-1} + \left(
      \ti{\Sigma_{\beta}}{t} \right)^{-1} \right) x - 2x\transpose
  \left( \left( \ti{\Sigma_{\alpha}}{t} \right)^{-1}
  \ti{\mu_{\alpha}}{t} + \left( \ti{\Sigma_{\beta}}{t} \right)^{-1}
  \ti{\mu_{\beta}}{t} \right) \\
& + \mu_\alpha\transpose  \left(
  \ti{\Sigma_{\alpha}}{t} \right)^{-1} \mu_\alpha +
  \mu_\beta\transpose  \left( \ti{\Sigma_{\beta}}{t} \right)^{-1}
  \mu_\beta ,
\end{align*}
which implies
\begin{subequations}
  \begin{align}
    \left( \ti{\Sigma_{\alpha \beta}}{t} \right)^{-1} &= \left(
      \ti{\Sigma_{\alpha}}{t} \right)^{-1} + \left(
      \ti{\Sigma_{\beta}}{t} \right)^{-1} ~\text{ and} \\
    \ti{\mu_{\alpha \beta}}{t} &=
    \ti{\Sigma_{\alpha \beta}}{t} \left( \left(
        \ti{\Sigma_{\alpha}}{t} \right)^{-1} \ti{\mu_{\alpha}}{t} +
      \left( \ti{\Sigma_{\beta}}{t} \right)^{-1} \ti{\mu_{\beta}}{t}
    \right).
\end{align}
\end{subequations}

\subsection{Inverse Covariance Form}
\label{sec:DetailInverse}
 \index{inverse covariance form}

 If the inverse covariance of the state distribution is singular, one
 must propagate inverse covariances rather than covariances (see page
 239 of Maybeck\cite{Maybeck79}).  Kailath et al.\ call this \emph{The
   Information Form} (see page 332 of \cite{KSH00}).
 \index{information form} The procedure is useful when one makes the
 backwards pass through the data for smoothing because the initial
 inverse covariance is zero.

\subsection{Extended Kalman Filter}
\label{sec:EKF}
\index{extended Kalman filter|textbf}

Recall Eqn.~\eqref{eq:contnoise} from the beginning of the chapter
\begin{align*}
  \ti{x}{t+1} &= F(\ti{x}{t},t) + \ti{\eta}{t}\\
  \ti{y}{t}   &= G(\ti{x}{t},t) + \ti{\epsilon}{t},
\end{align*}
and that if the functions $F$ and $G$ are linear and the noise terms
$\ti{\eta}{t}$ and $\ti{\epsilon}{t}$ are independent and Gaussian
that the Kalman filter implements the forward algorithm.  If on the
other hand, the functions $F$ and $G$ are nonlinear but the errors of
first order approximations to them are small compared to the size of
the state covariance, then one can reasonably apply the same algorithm to the
approximations.  The resulting procedure is called an \emph{extended
  Kalman filter}.  While, as we noted in Section~\ref{sec:related}
there are more robust alternatives, the simplicity of extended Kalman
filters explains their frequent use.  In Section~\ref{sec:laser} we
applied an extended Kalman filter to laser measurements for the
following purposes:
\begin{itemize}
\item Estimate model parameters
\item Estimate state space trajectory
\item Forecast measurements
\end{itemize}
And in the next chapter we will compare the likelihood of a model
implemented as an extended Kalman filter to a performance bound
obtained from Lyapunov exponent estimates.

%%% Local Variables:
%%% TeX-master: "main"
%%% eval: (load-file "hmmkeys.el")
%%% mode: LaTeX
%%% End:
