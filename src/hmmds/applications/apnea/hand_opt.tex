
% Notes on modeling heart rate

\documentclass[12pt]{article}
\usepackage{graphicx,color}
\usepackage{amsmath, amsfonts}
\usepackage{placeins}
\usepackage{verbatim}
\usepackage{showlabels}

\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\INTEGER}{\field{Z}}
\newcommand{\REAL}{\field{R}}
\newcommand{\COMPLEX}{\field{C}}
\newcommand{\id}{\mathbb{I}}
\newcommand{\variance}[1]{\field{V}\left[ #1 \right]}
\newcommand{\normal}[2]{{\cal N}\left(#1,#2 \right)}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\BestModel}{\emph{two\_ar5\_masked}}

\title{Hand Optimization}
\author{Andrew M.\ Fraser}

\begin{document}
\maketitle

\newcommand{\StudyCaption}[2]{
  \caption{Performance vs #1 on the \emph{a} records combined with and
    \emph{b} and \emph{c} records that are close to the pass-1
    boundary.  The models have
    #2.}
}

\newcommand{\StudyFigs}[2]{

\begin{figure}
  \centering
  \resizebox{0.8\textwidth}{!}{\includegraphics{#1_threshold.pdf}}
  \StudyCaption{detection threshold}{#2}
  \label{fig:#1_threshold}
\end{figure}

\begin{figure}
  \centering
    \resizebox{0.8\textwidth}{!}{\includegraphics{#1_errors_vs_ar.pdf}}
    \StudyCaption{autoregressive order}{#2}
  \label{fig:#1_ar_order_study}
\end{figure}

\begin{figure}
  \centering
    \resizebox{0.8\textwidth}{!}{\includegraphics{#1_errors_vs_fs.pdf}}
    \StudyCaption{heart rate sample frequency}{#2}
  \label{fig:#1_sample_frequency_study}
\end{figure}

\begin{figure}
  \centering
    \resizebox{0.8\textwidth}{!}{\includegraphics{#1_errors_vs_lpp.pdf}}
    \StudyCaption{cutoff period in seconds of low pass filter for heart rate}{#2}
  \label{fig:#1_lpp_study}
\end{figure}

\begin{figure}
  \centering
    \resizebox{0.8\textwidth}{!}{\includegraphics{#1_errors_vs_rc.pdf}}
    \StudyCaption{center frequency in cpm for extracting respiration signal}{#2}
  \label{fig:#1_rc_study}
\end{figure}

\begin{figure}
  \centering
    \resizebox{0.8\textwidth}{!}{\includegraphics{#1_errors_vs_rw.pdf}}
    \StudyCaption{width in cpm of filter for extracting respiration signal}{#2}
  \label{fig:#1_rw_study}
\end{figure}

\begin{figure}
  \centering
    \resizebox{0.8\textwidth}{!}{\includegraphics{#1_errors_vs_rs.pdf}}
    \StudyCaption{cutoff frequency in cpm for smoothing the
      respiration signal}{#2}
  \label{fig:#1_rs_study}
\end{figure}

\begin{table*}
  \centering
  \input{#1_score.tex}
  \caption[Performance]{Performance of a model that has #2.}
  \label{tab:#1_score}
\end{table*}}

\section{Combining Respiration and Heart Rate}
\label{sec:combination}

Here I combine a vector heart rate and respiration signal with a four
state state structure.  The parameters to choose
include:
\begin{description}
\item[VARG parameters:] for the (Vector Autoregressive Gaussian) model
  of the 2-d vectors with components respiration and low-pass filtered
  heart rate.  The parameters include:
  \begin{description}
  \item[AR order] 5 % ar
  \item[sample rate] 4 % fs
  \item[low pass period] 70 seconds % lpp
  \item[respiration pass center] 16.5 per minute % rc
  \item[respiration pass width] 3.5 per minute % rw
  \item[envelope smooth] .49 per minute % rs
  \item[$\psi$ and $\nu$] Priors for each state
  \end{description}
\item[Detector threshold] 0.5
\end{description}

In the foregoing list, I chose the values of the VARG parameters to
get the best performance when the threshold for each record was set to
maximize performance.  Then I chose the overall detector threshold to
maximize overall performance.  In later sections I will consider
methods of setting custom thresholds for each record that don't use
the expert classification data.

In the following figures I've plotted the number of classification
errors in a set of records that I call \emph{a-plus} against each of
those parameters.  The a-plus records are the \emph{a} records and the
\emph{b} and \emph{c} records near the boundary of my pass-1
classification step\footnote{Specifically the records \emph{b01, b02,
    b03, b04, c08} and \emph{c10}}.

\StudyFigs{v4s}{four states and the observation models are vector
  autoregressive models for heart rate and respiration}

\clearpage % flush floats
\section{Varying the Detector Threshold}
\label{sec:threshold}

Notice that in Table~\ref{tab:v4s_score} the records a02 a09 a18 have
39\% of the classification errors.  Figures
\ref{fig:v4s_threshold_a02} to\ref{fig:v4s_threshold_c10} show the
dependence of the number of errors on the detector threshold for
selected records.  While the best overall threshold is about 0.5 there
is a best threshold for each record and that varies over a factor of
$10^5$ depending on the record.  In the next section,
\ref{sec:custom_threshold}, I describe a technique for customizing the
detector threshold for each record.

\newcommand{\ThresholdStudy}[2]{
  \begin{figure}
    \centering
    \resizebox{0.8\textwidth}{!}{\includegraphics{v4s_threshold_#1.pdf}}
    \caption{The number of classification errors as a function
      detector threshold for record #1.  The
      best threshold for record #1 is about #2.}
    \label{fig:v4s_threshold_#1}
  \end{figure}
}

\ThresholdStudy{a02}{0.01}
\ThresholdStudy{a09}{0.0006}
\ThresholdStudy{c10}{700}

\clearpage
\subsection{Custom Thresholds}
\label{sec:custom_threshold}

Supposing that I can find a function from heart rate time series to
thresholds, I seek parameter values that minimize detection errors
when I use the best threshold for each record in the a-plus set of
records.  Figure~\ref{fig:cheat} illustrates that search.  I was
surprised to see that the optimal parameter values were close to those
I found using a fixed threshold.

\begin{figure}
  \centering
  \resizebox{0.4\textwidth}{!}{\includegraphics{cheat_ar.pdf}}
  \resizebox{0.4\textwidth}{!}{\includegraphics{cheat_fs.pdf}}\\
  \resizebox{0.4\textwidth}{!}{\includegraphics{cheat_lpp.pdf}}
  \resizebox{0.4\textwidth}{!}{\includegraphics{cheat_rc.pdf}}\\
  \resizebox{0.4\textwidth}{!}{\includegraphics{cheat_rw.pdf}}
  \resizebox{0.4\textwidth}{!}{\includegraphics{cheat_rs.pdf}}
  \caption[Parameter sensitivity with variable thresholds.]{Survey of
    6 parameters.  The code considers 10 threshold values for each
    parameter value and uses the threshold value that minimizes the
    number of classification errors.}
  \label{fig:cheat}
\end{figure}


I found Fourier Power Spectral Density estimates (PSDs) useful for
classifying whole records for Pass1.  I've used PSDs again for
customizing detector thresholds.  My PSD estimates are vectors with
2,149 components.  I use \marginpar{Sort of.} the following 1-d
statistic to set thresholds:
\begin{equation}
  \label{eq:z_sum}
  z_{\text{sum}}(\text{record}) \equiv \sum_{i=0}^{2048}
  \frac{\text{PSD}_i(\text{record}) - \mu_i}{\sigma_i}
\end{equation}
Figure~\ref{fig:shift_threshold} illustrates a four parameter function
that maps PSDs to thresholds, and classification results using that
function appear in Table~\ref{tab:abcd_score}.

\begin{figure}
  \centering
  \resizebox{0.5\textwidth}{!}{\includegraphics{shift_threshold.pdf}}
  \caption[A function of PSDs for varying detector thresholds.]{The
    axes of the upper plot are the function of a PSD defined in
    \eqref{eq:z_sum} and the detector threshold.  The markers for each
    record are placed at the threshold that minimizes the number of
    classification errors for that record.  The piecewise affine line
    is a four parameter function that maps
    $z_{\text{sum}}: \mapsto \text{threshold}$.  The parameters have
    been optimized to minimize the classification errors over all of a
    set of records.  The four lower plots illustrate the dependence of
    the total number of errors on each of the four parameters.  }
  \label{fig:shift_threshold}
\end{figure}

\begin{table*}
  \centering
  \input{abcd_score.tex}
  \caption[Performance]{Classification performance when thresholds are
  functions of PSDs}
  \label{tab:abcd_score}
\end{table*}

\clearpage

\subsection{Further Optimization}
\label{sec:further}

The function plotted in Figure~\ref{fig:shift_threshold} improves
performance from 2790 errors, 17\% (Table~\ref{tab:v4s_score}) to 2162
errors, 13\% (Table~\ref{tab:abcd_score}).  However it is not as good
as 1952 errors\footnote{That performance use a bogus class decoding
  idea.} that the models I describe in the first edition of the book
obtained.

% Perhaps I can get some more improvement by revisiting parameter
% choices using threshold function \ref{fig:shift_threshold}, but when I
% used the threshold function, the optimal parameter values stayed the
% same.  See Fig.~\ref{fig:abcd}

% \begin{figure}
%   \centering
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_ip.pdf}}
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_pt.pdf}}\\
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_ar.pdf}}
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_fs.pdf}}\\
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_lpp.pdf}}
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_rc.pdf}}\\
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_rw.pdf}}
%   \resizebox{0.4\textwidth}{!}{\includegraphics{abcd_rs.pdf}}
%   \caption[Parameter sensitivity with variable thresholds.]{Survey of
%     8 parameters.}
%   \label{fig:abcd}
% \end{figure}

Here are some ideas for further improvements:
\begin{description}
\item[Better Thresholds] Perhaps a better function for setting per
  record thresholds would help.  Since cheating to use the best
  threshold for each record yields 1410 errors (See
  Table~\ref{tab:cheat_score}), I think I need more discriminating
  models.
\item[More States] I will try using more states.
\end{description}


\begin{table*}
  \centering
  \input{cheat_score.tex}
  \caption[Performance]{Classification performance with best threshold
  for each record by cheating.}
  \label{tab:cheat_score}
\end{table*}

\subsection{More States}
\label{sec:more_states}

\begin{figure}
  \centering
  \resizebox{0.4\textwidth}{!}{\includegraphics{multi_cheat_ar.pdf}}
  \resizebox{0.4\textwidth}{!}{\includegraphics{multi_cheat_fs.pdf}}\\
  \resizebox{0.4\textwidth}{!}{\includegraphics{multi_cheat_lpp.pdf}}
  \resizebox{0.4\textwidth}{!}{\includegraphics{multi_cheat_rc.pdf}}\\
  \resizebox{0.4\textwidth}{!}{\includegraphics{multi_cheat_rw.pdf}}
  \resizebox{0.4\textwidth}{!}{\includegraphics{multi_cheat_rs.pdf}}
  \caption[Parameter sensitivity with variable thresholds.]{Survey of
    6 parameters.  The code considers 10 threshold values for each
    parameter value and uses the threshold value that minimizes the
    number of classification errors.}
  \label{fig:multi_cheat}
\end{figure}

\begin{figure}
  \centering
  \resizebox{0.9\textwidth}{!}{\includegraphics{fit2threshold.pdf}}
  \caption[Functions from record statistics to threshold.]{The best
  threshold for each training record is plotted against a naive fit
  $x=\text{log\_fit}$ in the top plot.  The line in the top
  plot is the function $f(x) = m\cdot x +b$ for thresholds that
  minimizes error on the training set.  Error counts versus parameters
  $m$ and $b$ appear in the lower plots}
  \label{fig:fit2threshold}
\end{figure}

\begin{table*}
  \centering
  \input{multi_score.tex}
  \caption[Performance]{Classification performance of multi-state
    model with best threshold for each record by cheating.}
  \label{tab:multi_score}
\end{table*}

\begin{table*}
  \centering
  \input{fit_mb_score.tex}
  \caption[Performance]{Classification performance of multi-state
    model with thresholds set by function of three statistics: PSD
    and log likelihoods of two HMMs.}
  \label{tab:mb_score}
\end{table*}

\end{document}

In the book, I got to error rate of .1176 on the training data (1952
errors) and .1305 (2253 errors) on the test data Cheating by peaking
at the expert data to set thresholds I got 1410 errors with the v4s
models.

Performance of multi models with cheating:

       A->N   N->A  N_error
       3A 2N  787   705   1492
       3A 3N  651   638   1289  (changed psi & nu)

Performance without cheating

2024-03-17: 3 normal states, 3 apnea states, threshold based on Pass1,
log_likelihoods of 6 state model with classes trained on APLUSNAMES
and c_model.  2094 errors on all training data.

2024-03-18: Improve on yesterday by using models low_classless and
high_classless instead of c_model and \$(MULTI_BEST) for threshold
calculations.  1940 errors on all training data.

2024-03-20: Finished attempt to use one model for each training
record.  I'd hoped to use likelihood's to define nearest neighbors and
then use the neighbor's model to classify a record's data.  That would
have generalized to the x-files.  It didn't work well at all.

2024-03-21: Focus on parameter of models \$(MODELS)/high_classless and
\$(MODELS)/low_classless that give statistics for the threshold
function.  1805 errors on all training data.  N_minutes = 6457 + 10155
= 16612.  Error fraction is 1805/16612 = 0.109.

2024-03-23: Found deadline for submission to SciPy-24 was Feb 27 and
that meeting will be in Tacoma.  I won't go.  I'm ready to move beyond
tinkering with models for the apnea data.  I wrote to PhysioNet asking
how to score classification of testing data.

2024-04-29 Changed training set from: APLUSNAMES =
$(ANAMES) b01 b02 b03 b04 c08 c10 to: APLUSNAMES = $(ANAMES) b01 b02
c02 c09 c10 because the derived heart rates for c08, b03, and b04 have
unsatisfactory spikes.  After modifying the training set performance
in Table 4 (multi state with cheat threshold) dropped to 1424, 0.09,
and the values in Table 5 (uses the best m and b values) were 2337
0.14.  The optimum parameter values stayed the same

Plan:

1. Review x-files and consider modifying QRS code to address failures.

2. View x-files and estimate best threshold for each.

3. Create submission file based on thresholds from code.

4. Create submission file based on thresholds from viewing data.

5. If possible score test data using cheat best threshold for each
file.

6. Combine heart_rate.tex and hand_opt.tex into document that reports
on interesting or valuable lessons from my work on the apnea data.

7. Rewrite last chapter of the book.

8. Revise software including build of book.

9. Start asking for help.

Here are notes on the apnea data:

x-files with untrimmed beginnings: 01, 04, 06, 18, 22, 24, 26, 28, 29,
35

Guesses about which x-files are ``Normal'' (like c-files) based on:

Pass1   Visual 64   128 1024 2048 4096
                    x03            x03
x04     x04    x04  x04  x04  x04  x04
x06     x06
x11     x11              x11  x11  x11
                                   x15
x17     x17              x17
                    x18  x18  x18
x22     x22    x22  x22  x22  x22  x22
x24     x24              x24  x24  x24
x29     x29    x29       x29  x29  x29
x33     x33    x33  x33  x33  x33  x33
x34     x34    x34  x34  x34  x34  x34
x35     x35    x35  x35  x35  x35  x35

x11 has atypical beats, but my QRS code tracks and provides OK heart
rate

x29 has alternans.  I think it's a ``Normal'' record

x26 Has atypical beats and my QRS code occasionally also fails for
normal beats.  I think that the atypical beats queers the training and
leads to the failures on normal beats.

Here are the thresholds to use for the x-files (first column from
python printfit.py default threshold_statistics.pkl ):

Record  Fit    Visual  QRS OK?
x01     0.42    -1.7   yes
x02     2.19     1.0   yes
x03     1.15     1.1   yes
x04     2.81     3.4   extra beats
x05     0.55     0.0   yes
x06     0.94     2.8   yes
x07    -1.64    -1.0   yes
x08     0.92    -0.4   yes
x09    -2.00     0.3   yes
x10    -0.26     0.0   yes    
x11    -1.39           Arrhythmia ?PVC distorts resp
x12     1.12     0.4   yes
x13    -1.66    -0.3   Arrhythmia, negative ecg spikes
x14    -1.92    -0.7   yes
x15     0.49    -0.6   yes
x16    -0.06     0.2   yes
x17     1.48           yes  c?
x18     0.95    -2.3   yes
x19     3.73     0.4   yes Some arrhythmia, but ok
x20     0.19    -0.7   yes
x21     0.10           yes
x22     0.22           yes
x23    -1.48           yes
x24     3.75           yes
x25     0.04           yes
x26    -1.46     0.0   arrhythmia and extra beats
x27    -0.68           yes
x28    -0.86           yes
x29    10.66           yes But serious arrhythima
x30    -0.58     0.8   yes
x31     5.00           yes
x32     2.08           yes
x33     0.19           yes
x34     0.22           yes
x35     0.08           yes

X33 and x34 are shifted measurements of the same event, as are c05 and
c06.

x04 OK after about t=88

x11 QRS-HMM is OK.  Easy to see PVC peaks in ECG.  At coarse time
scale, I can't separate PVC peaks from low frequency excursions.
Solution: Mask positive peaks 3\%, low likelihood 1\%, and long
inter-beat periods (hr=55bpm)

x13 QRS-HMM is OK.  Easy to see PVC valleys in ECG.  Solution: Mask on
negative peaks 5\% and low likelihood 1\%.

x19 QRS-HMM is OK, but Arrhythmia may cause high fit threshold that
throws off classification.  Solution: Mask on low likelihood 10\% and
set threshold to 1.2

x26 QRS-HMM inserts extra beats.  Arrhythmia missing R.  Solution:
Custom alpha-beta variance prior.  Mask on negative peaks 3\%, low
likelihood 3\%, and long inter-beat periods (48 bpm).

x29 QRS-HMM is OK.  Episodes of arrhythmia with frequent premature
beats.  Sometimes every 5th beat is premature.  Solution: Mark this
record as normal and don't fix the derived signals.


python fit2threshold.py ../../../../build/derived_data/apnea/models/multi_ar12fs4lpp65rc13rw3.0rs.455_masked threshold_statistics.pkl --records a01 a02 a03 a04 a05 a06 a07 a08 a09 a10 a11 a12 a13 a14 a15 a16 a17 a18 a19 a20 b01 b02 b03 b04 c08 c10 --mb 0.927 0.0305 --fig_path fit2threshold.pdf
errors=1841
a01 -0.00  0.82 -0.82
a02 -1.80 -1.05 -0.75
a03  2.40  2.73 -0.34
a04 -0.60 -0.67  0.06
a05 -0.60 -1.09  0.49
a06 -1.20 -0.63 -0.57
a07  1.20  0.57  0.63
a08  1.20  0.03  1.17
a09 -2.40 -1.58 -0.82
a10 -0.00 -0.75  0.75
a11 -2.40 -0.61 -1.79
a12 -1.20 -1.23  0.03
a13 -0.00 -0.02  0.02
a14 -0.00  1.72 -1.72
a15 -0.60 -0.73  0.13
a16  0.60  0.26  0.34
a17 -0.00 -0.83  0.83
a18 -2.40 -0.61 -1.79
a19 -0.00  0.35 -0.35
a20 -1.20 -0.79 -0.41
b01  2.40  0.18  2.22
b02  1.80  0.08  1.72
b03  1.20  0.81  0.39
b04  2.40  3.26 -0.86
c08  2.40  3.17 -0.77
c10  2.40  0.34  2.06
     best  fit   difference

2024-06-15 Start on HMM called ``threshold'' for estimating thresholds
delta threshold = .12 n_states = 42

errors=1294
a01 -1.00 -0.31 -0.69
a02 -2.33 -2.72  0.39 [...]

2024-06-21 But with 42 degrees of freedom, one can fit 26 thresholds
exactly.

Changes: (1) Limit rank of SVD to 8; (2) VARG covariance the same for
all states except noise;  (3) Use 100 steps between -3 and +3 for
calculating the best thresholds.

Makefile says --power_dict hr_respiration .25 threshold 4

Rank = 8, delta mu = .2, variance = .49 n_states = 26
errors=1926
    best  fit   difference  in qxfit2threshold
a01 -0.03 -0.62  0.59
a02 -2.21 -1.45 -0.76 [...]

Why is minimum of fit thresholds -1.45?

delta mu = .2, variance = 0.04, n_states = 26
***Training failed***

delta mu = .2, variance = 0.09, n_states = 26
errors=2120
    best  fit   difference  in qxfit2threshold
a01 -0.03  0.19 -0.22
a02 -2.21  0.11 -2.32

delta mu = .1, variance = 0.09, n_states = 50
***Training failed***

delta mu = .1, variance = 0.25, n_states = 50, rank = 8
errors=2038
    best  fit   difference  in qxfit2threshold
a01 -0.03 -0.83  0.80
a02 -2.21 -0.33 -1.89

delta mu = .1, variance = 1.0, n_states = 50, rank = 8
errors=2136
    best  fit   difference  in qxfit2threshold
a01 -0.03 -0.69  0.66
a02 -2.21 -1.08 -1.13
minimum of fit is -1.08 occurs for 8 records

delta mu = .05, variance = 1.0, n_states = 98, rank = 9
errors=2047
    best  fit   difference  in qxfit2threshold
a01 -0.03 -0.03 -0.00
a02 -2.21 -1.45 -0.76
minimum of fit is -1.45 occurs for 7 records

2024-07-23 Errors on test data: 3704 21\%.  Not satisfactory given the
complexity of the effort.  Next, I will try to get close to 80\% with
a simple approach.
