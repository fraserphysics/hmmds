% \documentclass[twocolumn]{article}
\RequirePackage{rotating}
\documentclass[]{article}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{xspace}
%\usepackage{showlabels}
%\usepackage[pdftex]{graphicx,color} % For including pdfs

\usepackage{graphicx}
\usepackage[most]{tcolorbox}
\usepackage{figlatex}

% Commands from Hmmdsbook/hmmdsbook.cls
\usepackage{afterpage}
\usepackage[norefeq,refpage,nocfg,intoc,noprefix]{nomencl}
\newcommand{\parameters}{\theta}
\newcommand{\ts}[3]{#1_{#2}^{#3}}                    % Time Sequence
\newcommand{\argmin}{\operatorname*{argmin}}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\ti}[2]{{#1}{(#2)}}                  % Time Index
\newcommand{\states}{{\cal{S}}}
\newcommand{\ie}{i.e.\xspace}
\newcommand{\eg}{e.g.\xspace}
\newcommand{\etal}{et al.\xspace}
\newcommand{\iid}{i.~i.~d.\xspace}
\newcommand{\plotsize}{%
  \fontsize{9}{9}%
  \selectfont}
\newenvironment{symbdescription}{%
  \list{}{%
    \labelwidth\nomlabelwidth
    \leftmargin\labelwidth
    \advance\leftmargin\labelsep
    \itemsep\nomitemsep
    \let\makelabel\nomlabel}}%
{\endlist}
\renewcommand{\comment}[1]{}

\newcommand{\sbest}{s_{\text{best}}}
\newcommand{\cbest}{c_{\text{best}}}
\newcommand{\is}{\texttt{=}}

% Commands for figures

\newcommand*{\inputfig}[2]{\input{#1/#2.pdf_t}}
\newcommand*{\InputIntroductionFig}[1]{\inputfig{../figs/introduction}{#1}}
\newcommand*{\InputBasicAlgorithmsFig}[1]{\inputfig{../figs/basic_algorithms}{#1}}

\newcommand{\IncludeApneaFig}[1]{\includegraphics[scale=0.7]{../figs/apnea/#1.pdf}}

\title{Estimating Membership in Classes of HMM States: Notes for
  Friends\footnote{Diane Vaughan}}

\author{Andrew Fraser}

\begin{document}

\maketitle

\section{Introduction}\label{sec:introduction}

In 2008, SIAM published my book \emph{Hidden Markov Models and
  Dynamical Systems.}  In the final chapter, I used HMMs to classify
each minute of EKG records as either normal or as apnea.  The key to
that effort was building HMMs with many states \eg 14 in which the
states were partitioned into \emph{classes}.  Half of the states could
belong to the apnea class with the other half belonging to the normal
class.  A few years after SIAM published the book, I began rewriting
the software with the intention of illustrating exemplary software
practices.  One such practice is \emph{unit testing}.  Unit testing
revealed a conceptual error in my treatment of classes.  Since then
I've made a few starts at fixing the code and the book.  I've learned
more about good software practices, but I haven't set aside enough
time to finish the project.

I am returning to the project now that I have retired from LANL.\@
After rewriting the basic HMM code, I turned to the problem of
classes.  I have at least 3 different ways of handling them.  I'm
writing this document to clarify my own thoughts and to ask for help.

Since even in this brief introduction I've used some jargon that I
should explain before asking for help, I will review Hidden Markov
Models, \emph{HMMs}, before describing how I treat classes.  I've
drawn some of the following text and figures from the book.

\section{Hidden Markov Models with States and Observations Drawn from
  Discrete Sets}\label{sec:hmms}

In this section I describe the simplest HMMs: those that are
discrete in time, state, and observation.  I begin with a couple of
definitions.  Three random variables $\ti{X}{1}$, $\ti{X}{2}$, and
$\ti{X}{3}$ constitute a \emph{\index*{Markov chain}} if their
probability distributions obey
\begin{equation}
  \label{eq:MarkovChain}
  P_{\ti{X}{3}|\ti{X}{1},\ti{X}{2}} = P_{\ti{X}{3}|\ti{X}{2}},
\end{equation}
which is equivalent to $\ti{X}{1}$ and $\ti{X}{3}$ being conditionally
independent given $\ti{X}{2}$, \ie,
\begin{equation*}
  P_{\ti{X}{3},\ti{X}{1}|\ti{X}{2}} = P_{\ti{X}{3}|\ti{X}{2}}   P_{\ti{X}{1}|\ti{X}{2}}.
\end{equation*}
An indexed sequence of random variables $\ts{X}{1}{T}$ is a
\emph{Markov process}\index{Markov process} if for any $t: 1 < t < T$
the variables before and after $t$ are conditionally independent given
$\ti{X}{t}$, \ie,
\begin{equation}
  \label{eq:MarkovProcess}
  P_{\ts{X}{1}{t-1},\ts{X}{t+1}{T}|\ti{X}{t}} =
  P_{\ts{X}{1}{t-1}|\ti{X}{t}} P_{\ts{X}{t+1}{T}|\ti{X}{t}}.
\end{equation}
I will restrict my attention to time invariant models, \ie, those
for which the transition probabilities are constant over time.
Begin by considering the ordinary (\emph{unhidden})
Markov model or process sketched in Fig.~\ref{fig:mm}.  The set of
states $\states = \left\{u,v,w\right\}$, the probability distribution
for the initial state
\begin{equation}
  \label{eq:InitialProbabilites}
P_{\ti{S}{1}} =
\begin{bmatrix}
  \frac{1}{3}, & \frac{1}{3}, & \frac{1}{3}
\end{bmatrix},
\end{equation}
and the~\index*{transition matrix}\index{matrix!transition}%
\begin{equation}
  \label{eq:TransitionMatrix}
\begin{array}{rr|ccc}
  && \multicolumn{3}{c}{\ti{S}{t+1}} \\
  \multicolumn{2}{c|}{P(\ti{s}{t+1}|\ti{s}{t})} & u & v & w \\ \hline
  & u & 0 & 1 & 0 \\  && \vspace{-1 em} \\
  \ti{S}{t} & v & 0 & \frac{1}{2} & \frac{1}{2} \\  && \vspace{-0.98 em} \\
  & w & \frac{1}{2} & \frac{1}{2} & 0
\end{array}
\end{equation}
define the model, and the model determines the probability of any
sequence of states $\ts{s}{1}{T}$, which I write\footnote{I use
  upper case letters to denote random variables and $P$ to denote
  probability distribution functions.  A random variable used as
  subscript on $P$ specifies that I mean the distribution of that
  random variable.  I can give $P$ an argument to specify the value
  of the distribution function at that value, \eg $P_X(3)$ is the
  probability that the random variable $X$ has the value 3 and
  $P_X(x)$ is the probability that the random variable $X$ has the
  value $x$.  I usually drop subscripts on $P$ when the context or
  argument resolves ambiguity as to which probability function I
  mean.} as $P_{\ts{S}{1}{T}}\left( \ts{s}{1}{T} \right)$.  For
example I calculate the probability that a sequence of 4 states has
the values $\ts{s}{1}{4} = (u,v,w,v)$, (\ie, $\ti{s}{1} = u$,
$\ti{s}{2} = v$, $\ti{s}{3} = w$, and $\ti{s}{4} = v$) as follows:


\begin{align}
  \label{eq:intro_hmm1}
  P(\ts{s}{1}{4}) &= P(\ti{s}{1}) \prod_{\tau=2}^4 %
                     P(\ti{s}{\tau}|\ts{s}{1}{\tau-1})\\
  \label{eq:intro_hmm2}
                  &= P(\ti{s}{1}) \prod_{\tau=2}^4 %
                     P(\ti{s}{\tau}|\ti{s}{\tau-1}) \\
  \label{eq:intro_hmm3}
  P(u,v,w,v)      &= P(v|u,v,w) \cdot P(w|u,v) \cdot  P(v|u) \cdot P(u)\\
  \label{eq:intro_hmm4}
        &= P(v|w) \cdot P(w|v) \cdot  P(v|u) \cdot P(u)\\
  \label{eq:intro_hmm5}
        &= \frac{1}{2} \cdot \frac{1}{2} \cdot 1 %
                     \cdot \frac{1}{3} = \frac{1}{12}.
\end{align}

Applying~\index*{Bayes rule} $\left( P_{A|B} P_B = P_{A,B} \right)$
recursively, yields Eqn.~\eqref{eq:intro_hmm1} and the special case,
Eqn.~\eqref{eq:intro_hmm3}.  Equations~\eqref{eq:intro_hmm2}
and~\eqref{eq:intro_hmm4} follow from Eqns.~\eqref{eq:intro_hmm1}
and~\eqref{eq:intro_hmm3} respectively by the %
\emph{\index*{Markov assumption}}, Eqn.~\eqref{eq:MarkovProcess}.
which says that in determining the probability of the $t^\text{th}$
state given any sequence of previous states only the
${(t-1)}^{\text{th}}$ state is relevant. %
%%%

A common exercise is to find a \emph{\index*{stationary}} probability
distribution, \ie, given a transition matrix $T$ find the probability
vector $V$ (non-negative entries that sum to one) that satisfies
\begin{equation}
  \label{eq:statCond}
  VT = V.
\end{equation}
If~\eqref{eq:statCond} holds, then
\begin{equation*}
  P_{\ti{S}{2}}  = P_{\ti{S}{1}}T = P_{\ti{S}{1}} = P_{\ti{S}{t}}
  \forall t,
\end{equation*}
and in fact all probabilities are independent of shifts in time, \ie,
\begin{equation*}
  P_{\ts{S}{1}{t}} = P_{\ts{S}{1+\tau}{t+\tau}} \forall (t,\tau),
\end{equation*}
which is the definition of a stationary process.  Quick calculations
verify that the initial probability and transition matrix
in~\eqref{eq:InitialProbabilites} and~\eqref{eq:TransitionMatrix} do
not satisfy~\eqref{eq:statCond} but that the distribution $V =
\begin{bmatrix} \frac{1}{7}, & \frac{4}{7}, & \frac{2}{7}
\end{bmatrix}$ does.  Although the example is not a stationary
stochastic process, it relaxes towards such a process in the sense
that
\begin{equation*}
  \lim_{t \rightarrow \infty} P_{\ti{S}{t}} =  \lim_{t \rightarrow
    \infty} P_{\ti{S}{1}} T^t = \begin{bmatrix} \frac{1}{7}, & \frac{4}{7}, & \frac{2}{7}
\end{bmatrix}.
\end{equation*}

\begin{figure}[htbp]
  \centering{\plotsize%
    \InputIntroductionFig{Markov_mm}
  }
  \caption[\comment{fig:Markov }A Markov model.]{A Markov model}\label{fig:mm}
\end{figure}

The important points about a Markov model also apply to hidden
Markov models, namely that:
\begin{itemize}
\item The model determines the probability of arbitrary sequences of
  observations,
\item and the assumptions about independence and time invariance
  permit specification of the model by a small number of parameters.
\end{itemize}

% karlheg does not like the "," after the display-math array.  The
% punctuation here is not in any style manual, but karlheg thinks it
% seems right:
%
Now suppose, as sketched in Fig.~\ref{fig:dhmm}, that when the system
arrives in a state that rather than observing the state directly, one
observes a random variable that depends on the state.  The matrix that
specifies the random map from states to observations, \ie%
:
\begin{equation*}
  \begin{array}{cr|ccc}
      &      &\multicolumn{3}{c}{Y} \\
      \multicolumn{2}{r|}{P(y|s)} & d & e           & f \\ %
      \hline%
      & u      & 1 & 0           & 0 \\
      &        & \vspace{-1 em} \\
    S & v      & 0 & \frac{1}{3} & \frac{2}{3} \\
      &        & \vspace{-1 em} \\
      & w      & 0 & \frac{2}{3} & \frac{1}{3}
  \end{array}%,
\end{equation*}
combined with the distribution of initial
states~\eqref{eq:InitialProbabilites} and transition
matrix~\eqref{eq:TransitionMatrix} specifies this \emph{hidden} Markov
model.  The notion is that the underlying Markov process chugs along
unaware of the observations, and that when the process arrives at each
successive state $\ti{s}{t}$, an observation $\ti{y}{t}$ is produced
in a fashion that depends only on the state $\ti{s}{t}$.

\begin{figure}[htbp]
  \centering{\plotsize%
    \InputIntroductionFig{Markov_dhmm}
  }
  \caption[\comment{fig:Markov_dhmm }A hidden Markov model.]{A hidden
    Markov model}\label{fig:dhmm}
\end{figure}

Let me calculate the probability that a sequence of four observations
from this process would have the values $\ts{y}{1}{4} = (d,e,f,e)$.
As an intermediate step I calculate $P(\ts{y}{1}{4},\ts{s}{1}{4})$
for the given observation sequence and all possible state sequences.
Then I add to obtain
\begin{equation}
  \label{eq:dhmm_sum}
  \sum_{\ts{s}{1}{4}} P(\ts{y}{1}{4},\ts{s}{1}{4}) = P(\ts{y}{1}{4}).
\end{equation}
It is convenient that the only state sequences that could have
produced the observation sequence are $(u,v,v,v)$, $(u,v,v,w)$, and
$(u,v,w,v)$.  For any other state sequence
$P(\ts{y}{1}{4},\ts{s}{1}{4}) = 0$.

\begin{subequations}\label{eq:pcalc}
 \begin{align}
  \ts{s}{1}{4} & & P(\ts{s}{1}{4}) %
                & & P(\ts{y}{1}{4}|\ts{s}{1}{4}) %
                 & & P(\ts{y}{1}{4},\ts{s}{1}{4})\nonumber\\[1ex]
  \hline\nonumber\\[-2ex]
  uvvv         & & \frac{1}{3} \cdot 1 \cdot \frac{1}{2} \cdot \frac{1}{2} %
                & & 1 \cdot \frac{1}{3} \cdot \frac{2}{3} \cdot \frac{1}{3} %
                 & & \frac{2}{324}\\[1ex]
%%%
  uvvw         & & \frac{1}{3} \cdot 1 \cdot \frac{1}{2} \cdot \frac{1}{2} %
                & & 1 \cdot \frac{1}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} %
                 & & \frac{4}{324}\\[1ex]
%%%
  uvwv         & & \frac{1}{3} \cdot 1 \cdot \frac{1}{2} \cdot \frac{1}{2} %
                & & 1 \cdot \frac{1}{3} \cdot \frac{1}{3} \cdot \frac{1}{3} %
                 & & \frac{1}{324}
 \end{align}
\end{subequations}

Adding the fractions in the right hand column yields %
\begin{equation*}
  P(d,e,f,e) = \frac{7}{324}.
\end{equation*}

Now examine this calculation more carefully beginning with a statement
of the model assumptions.
\begin{description}
\item[The state process is Markov:] Given the current state, the
  probability of the next state is independent of earlier states and
  observations, \ie,
  \begin{equation}
    \label{eq:assume_markov}
    P_{\ti{S}{t+1}|\ts{S}{1}{t},\ts{Y}{1}{t}} = %
        P_{\ti{S}{t+1}|\ti{S}{t}}.
  \end{equation}
\item[The observations are conditionally independent given the states:]
  Given the current state, the probability of the current observation is
  independent of states and observations at all earlier times, \ie,
  \begin{equation}
    \label{eq:assume_output}
    P_{\ti{Y}{t}|\ts{S}{1}{t},\ts{Y}{1}{t-1}} = %
        P_{\ti{Y}{t}|\ti{S}{t}}.
  \end{equation}
\end{description}
Though the assumptions appear asymmetric in time, they are
not\footnote{I often use the following facts about independence
  relations:
  \begin{align}
    P(A|B,C) = P(A|B)   &\iff     P(A,C|B) = P(A|B) \cdot P(C|B)\nonumber\\
    \label{eq:markov-symmetry}%
                        &\iff     P(C|A,B) = P(C|B)\\
    P(A|B,C,D) = P(A|B) &\iff     P(A,C,D|B) = P(A|B) \cdot P(C,D|B)\nonumber\\
                        &\implies P(A,C|B) = P(A|B) \cdot P(C|B)\nonumber\\
    \label{eq:independence-groups}%
                        &\iff     P(A|B,C) = P(A|B).
  \end{align}
  The first chain of implications,~\eqref{eq:markov-symmetry}, says
  that if a process is Markov with time going forward, then it is also
  Markov with time going backwards.  The second
  chain,~\eqref{eq:independence-groups}, says that if $A$ is
  conditionally independent of $C$ and $D$ given $B$, then $A$ is
  conditionally independent of $C$ alone given $B$.  By symmetry, $A$
  is also conditionally independent of $D$ given $B$.}.  From the
assumptions, one can derive that
\begin{description}
\item[The joint process is Markov:]
  \begin{equation*}
    P_{\ts{Y}{t+1}{T},\ts{S}{t+1}{T}|\ts{Y}{1}{t},\ts{S}{1}{t}}
      = P_{\ts{Y}{t+1}{T},\ts{S}{t+1}{T}|\ti{Y}{t},\ti{S}{t}}
  \end{equation*}
\item[Given $\bm{\ti{S}{t}}$, $\bm{\ti{Y}{t}}$ is conditionally independent of everything else:]
  \begin{equation*}
    P_{\ti{Y}{t} |\ts{Y}{1}{t-1},\ts{Y}{t+1}{T}, \ts{S}{1}{T}} = P_{\ti{Y}{t} |\ti{S}{t}}
  \end{equation*}
\end{description}
Equations~\eqref{eq:assume_markov} and~\eqref{eq:assume_output} are
assumptions about \emph{conditional independence} relations.
Figure~\ref{fig:dhmm_net} represents these relations as a %
\emph{\index*{Bayes net}}.

\begin{figure}[htbp]
  \centering{\plotsize%
    \InputIntroductionFig{Markov_dhmm_net}
  }
  \caption[\comment{fig:dhmm-net }Bayes net schematic for a hidden Markov model.]%
  {Bayes net schematic for a hidden Markov model.  The drawn edges
    indicate the dependence and independence relations: Given
    $\ti{S}{t}$, $\ti{Y}{t}$ is conditionally independent of
    everything else.  Also, given $\ti{S}{t}$ all earlier values of
    state and observation are conditionally independent of all later
    values of state and observation.}\label{fig:dhmm_net}
\end{figure}

Bayes rule and the assumptions justify
\begin{align}
  P(\ts{Y}{1}{T},\ts{S}{1}{T}) &= P(\ts{S}{1}{T}) \, %
                                   P(\ts{Y}{1}{T}|\ts{S}{1}{T}),\notag\\
  \label{eq:sseqprob}%
  P(\ts{S}{1}{T})              &= P(\ti{S}{1}) %
                                   \prod_{t=2}^T P(\ti{S}{t}|\ti{S}{t-1})\\
  \label{eq:condyseqprob}%
  P(\ts{Y}{1}{T}|\ts{S}{1}{T}) &= \prod_{t=1}^T P(\ti{Y}{t}|\ti{S}{t})\\
  \intertext{and I conclude}
  P(\ts{Y}{1}{T},\ts{S}{1}{T}) &= P(\ti{S}{1}) %
                                   \prod_{t=2}^T P(\ti{S}{t}|\ti{S}{t-1})\, %
                                   \prod_{t=1}^T P(\ti{Y}{t}|\ti{S}{t}).\notag
\end{align}

Since the state $u$ produces the observation $d$ exclusively and no
other state can produce $d$, the observation sequence $(d,f,e,f)$ is
only possible if the state sequence begins with $u$ and does not
return to $u$.  That constraint reduces the number of possible state
sequences to eight.  The impossibility of state $w$ following itself,
further constrains the possible state sequences to the three listed in
the calculations of Eqn.~\eqref{eq:pcalc}.  One can verify the values
for $P(\ts{s}{1}{T})$ and $P(\ts{y}{1}{T}|\ts{s}{1}{T})$ in those
calculations by applying Eqns.~\eqref{eq:sseqprob}
and~\eqref{eq:condyseqprob}.

The calculation of $P(\ts{y}{1}{4})$ in Eqn.~\eqref{eq:pcalc} is easy
because, of the $3^4 = 81$ conceivable state sequences, only three are
consistent with the observations and model structure.  In general
however, if there are $N_S$ states and an observation sequence with
length $T$, then implementing
\begin{equation*}
  P(\ts{y}{1}{T}) = \sum_{\ts{s}{1}{T}} P\left(\ts{s}{1}{T}
    ,\ts{y}{1}{T} \right)
\end{equation*}
naively requires order ${\left(N_S\right)}^T$ calculations.  If $N_S$
and $T$ are as large as one hundred, ${\left(N_S\right)}^T$ is too
many calculations for any conceivable computer.

There is a family of algorithms whose complexities are linear in the
length $T$ that make it possible to use HMMs with interestingly long
time series.  I will provide details of three of those algorithms in
subsequent sections.  Here I only list their names and objectives.  In
these descriptions, I denote by $\parameters$ the vector of
parameters that define an HMM, namely the state transition
probabilities, the initial state probabilities, and the conditional
observation probabilities,
\begin{equation*}
   \parameters \equiv \left\{
     \begin{aligned}
       &\left\{\; P_{\ti{S}{t+1}|\ti{S}{t}} \left(s'|s
       \right)~\forall s',s \;\right\},\\
       & \left\{\; P_{\ti{S}{1}} \left(s \right)~\forall s
       \;\right\},\\
       &  \left\{\; P_{\ti{Y}{t}|\ti{S}{t}} \left(y_i|s' \right)
       ~ \forall y_i,s' \;\right\}
     \end{aligned}
   \right\}.
\end{equation*}
\begin{description}
\item[The Viterbi Algorithm:]\index{Viterbi algorithm} Given a model
  $\parameters$ and a sequence of observations $\ts{y}{1}{T}$, the
  Viterbi algorithm finds the most probable state sequence
  $\ts{\hat{s}}{1}{T}$, \ie,
  \begin{equation}
    \label{eq:intro-viterbi}
    \ts{\hat s}{1}{T} = \argmax_{\ts{s}{1}{T}} P
    \left(\ts{s}{1}{T}|\ts{y}{1}{T},\parameters\right).
  \end{equation}
  %
\item[The Forward Algorithm:] For each time step $t$ and each state
  $s$, the~\index*{forward algorithm} calculates the conditional
  probability of being in state $s$ at time $t$ given all of the
  observations up to that time, \ie,
  $P_{\ti{S}{t}|\ts{Y}{1}{t},\parameters} \left(s|\ts{y}{1}{t},
    \parameters \right)$. It also calculates
  $P\left(\ti{y}{t}|\ts{y}{1}{t-1}, \parameters \right)$, the
  conditional probability of each observation given previous
  observations.  Using these terms it calculates the probability of
  the entire data sequence given the model,
  \begin{equation*}
    P \left(\ts{y}{1}{T}|\parameters \right) =  P \left(\ti{y}{1}
      |\parameters \right) \cdot  \prod_{t=2}^T P
    \left(\ti{y}{t}|\ts{y}{1}{t-1}, \parameters \right).
  \end{equation*}
  %
\item[The Backward Algorithm] The backward algorithm\index{backward
    algorithm} calculates the influence of later observations on the
  conditional distribution of states at each time.  After running both
  the forward algorithm and the backward algorithm, one can calculate
  $P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)$, the
  conditional probability of being in any state $s \in \states$ at any
  time $t: 1\leq t \leq T$ given the entire sequence of observations.
\end{description}

\subsection{The Model Parameters}\label{sec:parameters}

Before describing the algorithms, I review the notation for the model
parameters.  \setlength{\nomlabelwidth}{2.7cm}%
\begin{symbdescription}
\item[$\bm{P_{\ti{S}{t+1}|\ti{S}{t}}(s'|s)}$] The probability that
  at time $t+1$ the system will be in state $s'$ given that at time
  $t$ it was in state $s$.  Notice that the parameter is independent
  of time $t$.
\item[$\bm{P_{\ti{S}{1}}(s)}$] The probability that the system will
  start in state $s$ at time 1.
\item[$\bm{P_{\ti{Y}{t}|\ti{S}{t}}(y_k|s)}$] The probability that
  the observation value is $y_k$ given that the system is in state $s$.
\item[$\bm{\parameters}$] The entire collection of parameters.
\end{symbdescription}

\subsection{The Forward Algorithm}\label{sec:forward}\index{forward
  algorithm|textbf} \marginpar{Diane, I only include the
  section to be complete.  There is no discrete optimization here.
  Ignore it unless you are curious.}

Given $\parameters$, the forward algorithm calculates
$P(\ts{y}{1}{T}|\parameters)$, and several useful intermediate terms.
Figure~\ref{fig:forward} sketches the structure of the recursion.
Since I am considering only one set of parameters, I will drop the
dependence of probabilities on $\parameters$ from the notation for the
remainder of this section.  In the example of Eqn.~\eqref{eq:pcalc} I
found that I could calculate the right hand terms of
\begin{equation*}
   P\left( \ts{y}{1}{T} \right) = \sum_{\ts{s}{1}{T}}
   P\left( \ts{y}{1}{T},\ts{s}{1}{T} \right)
\end{equation*}
easily from the model assumptions.  Unfortunately, the number of
possible sequences $\ts{s}{1}{T}$ is exponential in $T$, and it is
impossible to do the sum for even modest lengths $T$.

\begin{sidewaysfigure}[htbp]
  %% 0.75\textheight is approx 5.7 in.  The .eps is exactly that size.
  %% The widths for the minipages below are taken by measuring the
  %% ovals inside of XFig.
  \centering{\plotsize%
    %% Column a
    \def\colaa{$\alpha(s_1,t-1)$}%
    \def\colab{$\alpha(s_2,t-1)$}%
    \def\colac{$\alpha(s_3,t-1)$}%
    %% Column b
    \def\colba{$P \left(s_1|\ts{y}{1}{t-1} \right)$}%
    \def\colbb{$P \left(s_2|\ts{y}{1}{t-1} \right)$}%
    \def\colbc{$P \left(s_3|\ts{y}{1}{t-1} \right)$}%
    \def\sumeqforwardAthree{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        \underline{Forecast} from\\%
        prior $\alpha$'s,\\%
        Eqn.~\eqref{eq:forwardA3}
      \end{minipage}}%
    %% Column c
    \def\colca{$P \left(s_1,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\colcb{$P \left(s_2,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\colcc{$P \left(s_3,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\prdeqforwardBtwo{%
      \begin{minipage}[t]{2.3in}
        \raggedright%
        \underline{Update} by\\%
        incorporating\\%
        observation $\ti{y}{t}$,\\%
        Eqn.~\eqref{eq:forwardB2}
      \end{minipage}}%
    %% Column d
    \def\coldb{$P(\ti{y}{t}|\ts{y}{1}{t-1})$}%
    \def\prdeqforwardC{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        \underline{Sum} to get $\gamma(t)$\\%
        $\equiv P \left(\ti{y}{t}|\ts{y}{1}{t-1} \right)$,\\%
        Eqn.~\eqref{eq:forwardC}
      \end{minipage}}%
    %% Column e
    \def\colea{$\alpha(s_1,t)$}%
    \def\coleb{$\alpha(s_2,t)$}%
    \def\colec{$\alpha(s_3,t)$}%
    \def\quoteqforwardD{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        \underline{Normalize}\\%
        new $\alpha$'s,\\%
        Eqn.~\eqref{eq:forwardD}
      \end{minipage}}%
    \InputBasicAlgorithmsFig{forward}
  }
  \vspace{5 em}
  \caption[\comment{fig:forward }Dependency relations in the forward
  algorithm.]%
  {Dependency relations in the forward algorithm (See
    Eqns.~\eqref{eq:forwardA}-\eqref{eq:forwardD} in the
    text).}\label{fig:forward}
\end{sidewaysfigure}
\afterpage{\clearpage}%% Print this right here please.


The forward algorithm regroups the terms and produces the desired
result using order $T$ calculations.  For each time $t:\, 1 < t \leq
T$ I calculate $P(\ti{y}{t}|\ts{y}{1}{t-1})$, and in principle I can
write
\begin{equation*}
  P(\ts{y}{1}{T}) = P(\ti{y}{1}) \prod_{t=2}^T P(\ti{y}{t}|\ts{y}{1}{t-1}).
\end{equation*}
However the values of $P(\ti{y}{t}|\ts{y}{1}{t-1})$ are typically
small compared to 1, and the product of many such terms is too small
to be represented even in double precision.  Working with logarithms
avoids underflow:

\begin{equation}
  \label{eq:logP}
  \log\left( P(\ts{y}{1}{T}) \right) = \log\left( P(\ti{y}{1})
 \right) + \sum_{t=2}^T \log\left( P(\ti{y}{t}|\ts{y}{1}{t-1})\right).
\end{equation}

% Perhaps use \usepackage[most]{tcolorbox} for these boxes
\definecolor{MyGreen}{rgb}{0,.7,0.2}%
\definecolor{MyBlue}{rgb}{0.5,.2,1}%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% #1 = time #2 = state
\newcommand{\alphax}[2]{%
  \tcboxmath[colback=white,colframe=cyan]{%  Todo double box
    P_{S(#1)|\ts{Y}{1}{#1}}\left(#2 |\ts{y}{1}{#1} \right)% chktex 36
  }%
}%
%%%
%%%
\newcommand{\prealpha}{%
  \tcboxmath[colback=white,colframe=MyGreen]{%
    P_{\ti{S}{t}|\ts{Y}{1}{t-1}} \left(s | \ts{y}{1}{t-1} \right)%
  }%
}%
%%%
\newcommand{\gammax}{%
  \tcboxmath[colback=white,colframe=MyBlue]{%
    P(\ti{y}{t}|\ts{y}{1}{t-1})% chktex 36
  }%
}%
%%%
%%%
\newcommand{\pregamma}{%
  \tcboxmath[colback=white,colframe=red]{%
    P_{\ti{S}{t},\ti{Y}{t}|\ts{Y}{1}{t-1}} \left(s,\ti{y}{t}|\ts{y}{1}{t-1}\right)%
  }%
}%
%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For each time step I do the four calculations specified in
equations~\ref{eq:forwardA}-\ref{eq:forwardD} below.  In these
equations I use boxes to emphasize repeated instances of the same
quantity.  The algorithm saves the intermediate results
%
\nomenclature[ga]{$\alpha(s,t)$}{The conditional probability that at time
  $t$ the system is in state $s$ given the observations up to the
  present,
  \begin{equation*}
    \alpha(s,t) \equiv  P_{S(t)"|\ts{Y}{1}{t}}\left(s "|\ts{y}{1}{t}
    \right).
  \end{equation*}
  Also called the forward updated distribution in the Kalman filter
  literature.}
%
\nomenclature[gc]{$\gamma(t)$}{The probability of the present observation
  given the history.}%, $P(y(t)|y_1^{t-1}$.}
\begin{align}
  \label{eq:alpha}
  \alpha(s,t) &\equiv \alphax{t}{s}\\
  \label{eq:gamma}
  \ti{\gamma}{t} &\equiv \gammax .
\end{align}
In words, $\alpha(s,t)$ is the
conditional probability of being in state $s$ at time $t$ given all
of the observations up to time $t$, and $\ti{\gamma}{t}$ is the
conditional probability of the observation at time $t$ given all of
the previous observations.  To initialize the algorithm, one assigns
\begin{equation*}
\alpha(s,1) = P_{\ti{S}{1}|\ti{Y}{1}}(s|\ti{y}{1}) =
\frac{P_{\ti{S}{1}}(s)P_{\ti{Y}{t}|\ti{S}{t}}(\ti{y}{1}|s)}
{\sum_{{\tilde s}}P_{\ti{S}{1}}({\tilde s})P_{\ti{Y}{t}|\ti{S}{t}}(\ti{y}{1}|{\tilde s})}
~\forall s \in \states
\end{equation*}
where the distributions $P_{\ti{S}{1}}$ and $P_{\ti{Y}{t}|\ti{S}{t}}$
are model parameters.  Then, for each later time $t$ one does the
calculations \emph{forecast, update, sum} and \emph{normalize} defined
as follows:
\begin{description}
\item[\underline{Forecast} the Distribution of States] Find for time $t$ and each
  possible state $s$, the conditional probability, given the
  previous observations, of the state being $s$ at time $t$:
  \begin{subequations}\label{eq:forwardA}
    \begin{align}
      \label{eq:forwardA1}
      &\prealpha = \sum_{{\tilde s}\in\states}
      P_{\ti{S}{t},\ti{S}{t-1}|\ts{Y}{1}{t-1}} \left( s, {\tilde s}
      |\ts{y}{1}{t-1} \right)\\
      \label{eq:forwardA2}
      & = \sum_{{\tilde s}\in\states}
        P_{\ti{S}{t}|\ti{S}{t-1},\ts{Y}{1}{t-1}}
        \left( s|{\tilde s},\ts{y}{1}{t-1} \right) \times
       \alphax{t-1}{{\tilde s}} \\
      \label{eq:forwardA3}
      & = \sum_{{\tilde s}\in\states} P_{\ti{S}{t}|\ti{S}{t-1}} \left( s|{\tilde s} \right)
      \cdot \alpha({\tilde s},t-1) .
    \end{align}
  \end{subequations}
  I justify the operations as follows:
  \begin{description}
  \item[\eqref{eq:forwardA1}] $P(a) = \sum_b P(a,b)$
  \item[\eqref{eq:forwardA2}] $P(a|b)\cdot P(b) = P(a,b)$
  \item[\eqref{eq:forwardA3}] Assumption of
    Eqn.~\eqref{eq:assume_markov}: The state process is Markov
  \end{description}
\item[\underline{Update} the Joint Probability of States and the Current
  Observation] Find for time $t$ and each possible state $s$, the
  conditional probability, given the previous observations, of the
  state being $s$ and the observation being $\ti{y}{t}$ (the observation
  actually observed):
  \begin{subequations}\label{eq:forwardB}
    \begin{align}
      & \pregamma = \nonumber \\
      \label{eq:forwardB1}
      &\quad \quad P_{\ti{Y}{t} |
        \ti{S}{t},\ts{Y}{1}{t-1}}\left(\ti{y}{t} |s, \ts{y}{1}{t-1}
      \right) \times \prealpha\\
      \label{eq:forwardB2}
      & \quad = P_{\ti{Y}{t} | \ti{S}{t}}\left(\ti{y}{t} |s \right) \times
      \prealpha .
    \end{align}
  \end{subequations}
I justify the equations as follows:
\begin{description}
\item[\eqref{eq:forwardB1}]  $P(a|b)\cdot P(b) = P(a,b)$
\item[\eqref{eq:forwardB2}] Assumption of
  Eqn.~\eqref{eq:assume_output}: The observations are conditionally
  independent given the states
\end{description}
\item[\underline{Sum} to Get the Conditional Probability of the Current Observation]
  Find for time $t$ the conditional probability, given the previous
  observations, of the observation being $\ti{y}{t}$ (the observation actually
  observed):
  \begin{align}
    \label{eq:forwardC}
    \gammax &= \sum_{s \in \states} \pregamma .
  \end{align}
Equation~\eqref{eq:forwardC} is an application of $P(a) = \sum_b P(a,b)$.
\item[\underline{Normalize} the Updated Distribution of States] For each possible
  state $s$, find the conditional probability of being in that state
  at time $t$ given all of the observations up to time $t$.  Note that
  this differs from the first calculation in that the
  conditioning event includes $\ti{y}{t}$:%
  \begin{subequations}\label{eq:forwardD}
    \begin{align}
      \label{eq:forwardD1}
      \alpha(s,t) &\equiv
      \alphax{t}{s} \\
      \label{eq:forwardD2}
      &= \pregamma \div \gammax
    \end{align}
  \end{subequations}
  Equation~\eqref{eq:forwardD2} is an application of Bayes rule, \ie,
  $P(a|b)\cdot P(b) = P(a,b)$.
\end{description}

\subsection{The Viterbi Algorithm}\label{sec:viterbi}
\marginpar{Diane, this is \emph{dynamic programming}.}

For some applications, one must estimate the sequence of states based
on a sequence of observations.  The Viterbi algorithm\index{Viterbi
  algorithm|textbf} finds the \emph{best} sequence $\ts{\hat s}{1}{T}$
in the sense of maximizing the probability
$P\left( \ts{s}{1}{T}|\ts{y}{1}{T} \right)$.  That is equivalent to
maximizing
$\log \left( P\left( \ts{y}{1}{T},\ts{s}{1}{T} \right) \right)$
because $P \left( \ts{y}{1}{T} \right)$ is simply a constant, and the
$\log$ is monotonic, ie,
\begin{align*}
  \ts{\hat s}{1}{T} &\equiv \argmax_{\ts{s}{1}{T}}
  P(\ts{s}{1}{T}|\ts{y}{1}{T})\\
  &= \argmax_{\ts{s}{1}{T}} \left( P(\ts{s}{1}{T}|\ts{y}{1}{T}) \cdot
    P(\ts{y}{1}{T}) \right)\\
  &= \argmax_{\ts{s}{1}{T}} \log \left( P(\ts{y}{1}{T},\ts{s}{1}{T})
  \right).
\end{align*}
As in the implementation of the forward algorithm, I use logs to
avoid numerical underflow.  If I define $\log \left( P\left(
    \ts{y}{1}{t}, \ts{s}{1}{t} \right) \right)$ as the
\emph{utility} (negative cost) of the state sequence $\ts{s}{1}{t}$
given the observation sequence $\ts{y}{1}{t}$, then the Viterbi
algorithm finds the maximum utility state sequence.

Initially one calculates $\log\left(P_{\ti{Y}{1},\ti{S}{1}}
  \left(\ti{y}{1}, s \right) \right)$ for each state $s \in
\states$.  Then for each successive time step $t: 1 < t \leq T$ one
considers each state and determines the best predecessor for that
state and the utility of the best state sequence ending in that state.
The Viterbi algorithm and the forward algorithm have similar
structures (see Fig.~\ref{fig:forward} and Fig.~\ref{fig:viterbiB}).
Roughly, the forward algorithm does a sum over predecessor states,
while the Viterbi algorithm finds a maximum. I use the following
notation and equations to describe and justify the algorithm.

\subsubsection*{Notation:}
\begin{description}
\item[$\bm{{\hat s}_1^t(s)}$ The best sequence ending in $\bm{s}$]
  Of all length $t$ state sequences ending in $s$, I define
  $\ts{\hat s}{1}{t}(s)$ to be the sequence with the highest joint
  probability with the data, \ie,
  \begin{equation*}
    \ts{\hat s}{1}{t}(s) = \argmax_{ \ts{s}{1}{t}:\ti{s}{t}=s}
    P\left(\ts{y}{1}{t}, \ts{s}{1}{t} \right).
  \end{equation*}
\item[$\bm{\nu(t,s)}$ The \emph{utility} of the best sequence ending
  in $\bm{s}$] %
  This is simply the log of the joint
  probability of the data with the best state sequence defined above,
  \ie
  \begin{equation*}
    \nu(t,s) = \log\left( P\left(\ts{y}{1}{t}, \ts{\hat s}{1}{t}(s)
      \right) \right)
  \end{equation*}
\item[$\bm{\sbest(s,t)}$ The best predecessor of state $\bm{s}$] This is
  the state at time $t-1$ in the best sequence that ends at state $s$
  at time $t$, \ie
  \begin{equation*}
    \sbest(s,t) = \argmax_{\tilde s} \left( \nu(t-1,\tilde s) + \log(
      P(s|\tilde s)) \right).
  \end{equation*}
\end{description}
\subsubsection*{Equations:}
Equations~\eqref{eq:cat} and~\eqref{eq:nuprop} summarize the Viterbi
algorithm.  When finally deciphered, one finds Eqn.~\eqref{eq:cat} is
the obvious statement that the best state sequence ending in $s$ at
time $t+1$ consists of $s$ concatenated with the best sequence ending
in $\sbest$ at time $t$, where $\sbest$ is the best predecessor of $s$.
\begin{equation}
  \label{eq:cat}
  \ts{\hat s}{1}{t+1} (s) = \left( \left[\ts{\hat s}{1}{t}
      (\sbest(s,t+1))\right],s \right)
\end{equation}
Equation~\eqref{eq:nuprop} says that the total utility of the best
path to state $s$ at time $t+1$ is the utility of the best
predecessor plus two terms, one that accounts for the transition from
the predecessor to $s$ and one that accounts for the probability of
state $s$ producing the observation $\ti{y}{t+1}$.  The equation
follows from taking logs of
\begin{align*}
  P\left(\ti{y}{t+1},\ts{y}{1}{t},\ti{s}{t+1},\ts{s}{1}{t} \right) &=
  P\left(\ts{y}{1}{t}, \ts{s}{1}{t} \right) \times \\
  & \quad ~ P \left(\ti{s}{t+1}|\ti{s}{t} \right) \times
  P\left(\ti{y}{t+1}|\ti{s}{t+1} \right)
\end{align*}
which in turn follows from the model assumptions
(Eqn.~\eqref{eq:assume_markov} and Eqn.~\eqref{eq:assume_output}).
\begin{equation}
  \label{eq:nuprop}
  \begin{split}
    \nu (t+1,s) = \nu(t,\sbest(s,t+1)) +
    \log\left(P_{\ti{S}{t+1}|\ti{S}{t}} \left(s|\sbest(s,t+1) \right)\right)\\
    \quad + \log \left( P_{\ti{Y}{t+1}|\ti{S}{t+1}}
      \left(\ti{y}{t+1}|s\right)\right)
  \end{split}
\end{equation}

\subsubsection*{Algorithm:}
Following the steps in Fig.~\ref{fig:viterbi}, note that the algorithm
starts by assigning a utility for each state using the first
observation and then iterates forward through time.  For each time
step $t$ and each possible next state $s_\text{next}$ at time $t+1$,
the algorithm finds and records the best predecessor state $s_\text{best}$
at time $t$.  Then the algorithm calculates the utility of
$s_\text{next}$ at time $t+1$ on the basis of the utility of the best
predecessor, the conditional transition probability, and the
conditional observation probability.  At the final time $T$ the
algorithm selects the highest utility endpoint, \ie,
\begin{equation*}
  \hat {\ti{s}{T}} = \argmax_s \nu(T,s),
\end{equation*}
and then backtracks through the optimal predecessor links to produce
the entire highest utility path.
%%%
%%% fig:viterbi
%%%
%%% FixMe: \addcontentsline{loa}{section}{Pseudocode for the Viterbi Algorithm}
%%% FixMe: Is this a "figure" or an "algorithm"?
\begin{figure}[htbp]
  \begin{center}
    \def\tnext{_{\text{next}}}%
    \def\told{_{\text{old}}}%
    \def\tbest{_{\text{best}}}%
    \fbox{
      \begin{minipage}{0.90\textwidth}
        \begin{tabbing}
          XX\=XX\=XX\=XX\=XX\=XX\=XX\=XX\= \kill
          Initialize: \> \+ \\
          for each $s$\\ \> \+
          $\nu\tnext (s) = \log \left( P_{\ti{Y}{1},\ti{S}{1}}
            \left(\ti{y}{1},s \right)\right)$ \\ \\ \< \- \< \-
          Iterate: \> \+ \\
          for $t$ from 1 to $T$\\ \> \+
          Swap $\nu\tnext \leftrightarrow \nu\told$\\
          for each $s\tnext$\\ \> \+
          \\ \# \underline{Maximize} to find best predecessor\\
          $s\tbest = \argmax_{s\told}\left( \nu\told(s\told) + \log\left(
              P_{\ti{S}{t}|\ti{S}{t-1}} \left(s\tnext|s\told \right) \right)\right)$ \\
          \\ \# \underline{Update} $\nu$\\
          $\nu\tnext(s\tnext) =\,$ \= $\nu\told(s\tbest)$ \\ \> \+
          $+ \log\left( P_{\ti{S}{t}|\ti{S}{t-1}} \left(s\tnext|s\tbest
            \right) \right)$ \\
          $ + \log\left( P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s\tnext \right)
          \right)  $ \\ \> \-
          \\ \# Update predecessor array\\
          Predecessor[$s\tnext,t$] = $s\tbest$\\ \\
          \< \- \< \- \< \- %This stuff is for tabs \< \-
          Backtrack: \> \+ \\
          $s_1^T = \hat s_1^T(\bar s)$, where $\bar s =
          \argmax_s \nu\tnext(s)$ at $t=T$
        \end{tabbing}
      \end{minipage}
    }
    \caption[Pseudocode for the Viterbi Algorithm.]%
    {Pseudocode for the Viterbi Algorithm}\label{fig:viterbi}
  \end{center}
\end{figure}
%%%
%%% fig:viterbiB
%%%
\begin{sidewaysfigure}[htbp]
  %% 0.75\textheight is approx 5.7 in.  The .eps is exactly that size.
  %% The widths for the minipages below are taken by measuring the
  %% ovals inside of XFig.
  \centering{\plotsize%
    %% Column a
    \def\colaa{$\nu(s_1,t-1)$}%
    \def\colab{$\nu(s_2,t-1)$}%
    \def\colac{$\nu(s_3,t-1)$}%
    %% Column b
    \def\colba{$ \begin{matrix} \sbest(s_1,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_1|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\colbb{$ \begin{matrix} \sbest(s_2,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_2|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\colbc{$ \begin{matrix} \sbest(s_3,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_3|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\bestpred{%
      \begin{minipage}[t]{3.9in}
        \raggedright%
        For each state $s$ find\\%
        the best predecessor\\%
        $\sbest(s,t)$, \ie, \underline{maximize}\\%
        $\log\left(P(s|s'(s,t)) \right) + \nu(s'(s,t),t-1)$.\\%
        The bolder lines indicate\\%
        best predecessors.
      \end{minipage}}%
    %% Column c
    \def\colca{$\nu(s_1,t)$}%
    \def\colcb{$\nu(s_2,t)$}%
    \def\colcc{$\nu(s_3,t)$}%
    \def\newnu{%
      \begin{minipage}[t]{2.7in}
        \raggedright%
        For each state $s$\\%
        \underline{update} $\nu(s,t)$\\%
        by including the\\%
        conditional probability\\%
        of the observation $\ti{y}{t}$.
      \end{minipage}}
    %%
    \InputBasicAlgorithmsFig{viterbiB}
  }
  \vspace{7em}
  \caption[Dependency relations in the Viterbi algorithm.]%
  {Dependency relations in the Viterbi algorithm.}\label{fig:viterbiB}
\end{sidewaysfigure}

\subsection{The Backward Algorithm}\label{sec:backward}
\marginpar{Diane, I've only included this to be complete.  It's not
  directly related to discrete optimization.}

The backward algorithm\index{backward algorithm} is similar to the
forward algorithm in structure and complexity, but the terms are not
as easy to interpret.  The principal goal of the algorithm is to
calculate terms that can be combined with results from the forward
algorithm to calculate
$P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)$, the
conditional probability of being in any state $s \in \states$ at any
time $t: 1\leq t \leq T$ given the entire sequence of observations.
The forward algorithm provides the terms
$\alpha(s,t) \equiv P_{\ti{S}{t}|\ts{Y}{1}{t}} \left(s|\ts{y}{1}{t}
\right)\, \forall (s,t)$.  Thus the backward algorithm must provide
terms, call them $\beta(s,t)$, with the values
\begin{equation}
  \label{eq:bw1} \beta(s,t) =
  \frac{P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)}
  {\alpha(s,t)} = \frac{P_{\ti{S}{t}|\ts{Y}{1}{T}}
    \left(s|\ts{y}{1}{T} \right)}
  {P_{\ti{S}{t}|\ts{Y}{1}{t}} \left(s|\ts{y}{1}{t} \right)}.
\end{equation}
\nomenclature[gb]{$\beta(s,t)$}{An intermediate quantity calculated in the
  backwards algorithm which is used somewhat like $\alpha$ in the
  forward algorithm.  One may use either of the following two
  equations to define $\beta$
  \begin{align*}
    \beta(s,t) &= \frac{P_{\ts{Y}{t+1}{T}"|\ti{S}{t}}
      \left(\ts{y}{t+1}{T}"|s
      \right)} {P \left(\ts{y}{t+1}{T}"|\ts{y}{1}{t} \right)}\\
    &= \frac{P_{\ti{S}{t}"|\ts{Y}{1}{T}} \left(s"|\ts{y}{1}{T} \right)}
    {\alpha(s,t)} = \frac{P_{\ti{S}{t}"|\ts{Y}{1}{T}}
      \left(s"|\ts{y}{1}{T} \right)} {P_{\ti{S}{t}"|\ts{Y}{1}{t}}
      \left(s"|\ts{y}{1}{t} \right)}.
  \end{align*}
  The interpretation of $\beta$ is less intuitive than the
  interpretation of $\alpha$.  It is also called the backward forecast
  distribution in the Kalman filter literature.}% end nomenclature
Invoking Bayes rule and the model assumptions I find
\begin{align}
  \label{eq:bw2} \beta(s,t) &= \frac{P_{\ts{Y}{1}{T},\ti{S}{t}}
    \left(\ts{y}{1}{T},s \right)\cdot P \left(\ts{y}{1}{t} \right)}
  {P_{\ts{Y}{1}{t},\ti{S}{t}}
    \left(\ts{y}{1}{t},s \right)\cdot P \left(\ts{y}{1}{T} \right)}\\
  \label{eq:bw3} &= \frac{P_{\ts{Y}{t+1}{T}|\ts{Y}{1}{t},\ti{S}{t}}
    \left(\ts{y}{t+1}{T}|\ts{y}{1}{t},s \right)} {P
    \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)}\\
  \label{eq:bw4}
  & = \frac{P_{\ts{Y}{t+1}{T}|\ti{S}{t}} \left(\ts{y}{t+1}{T}|s
    \right)} {P \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)}.
\end{align}
(Note that if $\alpha(s,t)=0$, Eqn.~\eqref{eq:bw1} is undefined, but
I can nonetheless implement Eqn.~\eqref{eq:bw4}.)

The algorithm starts at the final time $T$ with $\beta$ set to
one\footnote{From the premises that $\alpha(s,t) \beta(s,t) =
  P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)$ and
  $\alpha(s,T) \equiv P_{S(T)|\ts{Y}{1}{T}}\left(s |\ts{y}{1}{T}
  \right)$, I conclude that $\beta(s,T) = 1 ~\forall s$.} %
for each state, $\beta(s,T) = 1,~\forall s \in \states$, and solves
for $\beta$ at earlier times with the following recursion that goes
\emph{backwards} through time:
\begin{equation}
  \label{eq:backformula}
  \beta({\tilde s},t-1) = \sum_{s\in\states} \beta(s,t)
  \frac{ P_{\ti{Y}{t}|\ti{S}{t}}
    \left(\ti{y}{t}|s \right) \cdot P_{\ti{S}{t}|\ti{S}{t-1}}
    \left(s|{\tilde s} \right)} {\ti{\gamma}{t}}
\end{equation}
Note that ${\ti{\gamma}{t} \equiv P \left( \ti{y}{t} |
    \ts{y}{1}{t-1}\right)}$ is calculated by the forward algorithm and
that the terms in the numerator are model parameters.  I justify
Eqn.~\eqref{eq:backformula} by using Eqn.~\eqref{eq:bw4}
\begin{align}
  \beta({\tilde s},t-1) & \equiv \frac{P_{\ts{Y}{t}{T}|\ti{S}{t-1}}
    \left(\ts{y}{t}{T}|{\tilde s} \right)}
  {P \left(\ts{y}{t}{T}|\ts{y}{1}{t-1} \right)} \\
  \label{eq:back2}
  &= \frac{\sum_{s\in\states} P_{\ts{Y}{t}{T},\ti{S}{t}|\ti{S}{t-1}}
    \left(\ts{y}{t}{T},s|{\tilde s} \right)} {P
    \left(\ts{y}{t}{T}|\ts{y}{1}{t-1} \right)}.
\end{align}
Next, factor each term in the numerator of Eqn.~\eqref{eq:back2} using
Bayes rule twice then apply the model assumptions and the expression
for $\beta(s,t)$ from Eqn.~\eqref{eq:bw4}:
\begin{align*}
  & P_{\ts{Y}{t}{T},\ti{S}{t}|\ti{S}{t-1}}\left( \ts{y}{t}{T},s|{\tilde s} \right)\\
  \begin{split}
    &\quad= P_{\ts{Y}{t+1}{T}|\ti{Y}{t},\ti{S}{t},\ti{S}{t-1}}
       \left(\ts{y}{t+1}{T}|\ti{y}{t},s,{\tilde s} \right)\\
    &\quad\qquad \cdot P_{\ti{Y}{t}|\ti{S}{t},\ti{S}{t-1}} \left(\ti{y}{t}|s,{\tilde s}
       \right)\cdot P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)
  \end{split}\\
  &\quad= P_{\ts{Y}{t+1}{T}|\ti{S}{t}} \left(\ts{y}{t+1}{T}|s\right)
           \cdot P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
            P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right) \\
  &\quad= \beta(s,t) \cdot P \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)
           \cdot P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
            P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)
\end{align*}
Similarly, factor the denominator of Eqn.~\eqref{eq:back2} using
Bayes rule:
\begin{equation*}
  P \left(\ts{y}{t}{T}|\ts{y}{1}{t-1} \right) = P
  \left(\ts{y}{t+1}{T}|\ts{y}{1}{t}  \right) \cdot {P \left(
  \ti{y}{t}|\ts{y}{1}{t-1}\right)}
\end{equation*}
Finally by substituting these values into the fraction
of~\eqref{eq:back2}, I verify the recursion~\eqref{eq:backformula}
\begin{align}
  \label{eq:back3} \beta({\tilde s},t-1) &= \frac{\sum_{s\in\states}
    \beta(s,t) \cdot P \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)
    \cdot P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
    P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)} {P
    \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right) \cdot {P \left(
        \ti{y}{t}|\ts{y}{1}{t-1}\right)}} \\
  \label{eq:back4} &= \sum_{s\in\states} \beta(s,t) \frac{
    P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
    P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)} {\ti{\gamma}{t}}.
\end{align}

\section{Apnea}\label{sec:Apnea}
\marginpar{Diane, this is the motivating example.}

In my book \emph{Hidden Markov Models and Dynamical Systems} the only
conceivably useful application was the analysis of EKG data in Chapter
6, \emph{Obstructive Sleep Apnea}.  I wrote code to estimate sequences
of classifications for that application.  As I said in the
introduction to this document, the ideas behind that code are flawed,
and I am writing this document as part of my effort to address those
errors.  Rather than immediately discussing the flawed ideas, in this
section I will pull some of the text about the application from the
book to give a concrete example.

The challenge for the \emph{Computers in Cardiology}\index{Computers
  in Cardiology 2000 (CINC2000)} meeting in 2000
(CINC2000)\index{CINC2000 (Computers in Cardiology 2000)} was to
identify \emph{obstructive sleep apnea} on the basis of
electrocardiograms alone.  With my colleague James~\index*{McNames} at
Portland State University, I won the prize for the best minute by
minute analysis of data.  I prepared our first entry using HMMs, and
James prepared the subsequent (and winning) entries by hand using
spectrograms\footnote{A spectrogram is display of power in Fourier
  spectral bands as a function of time.  The x-axis is time, the
  y-axis is frequency, and the image intensity at point $(t,f)$ is the
  power in that frequency estimated in a window centered at that
  time.}\index{spectrogram} to visualize the data. In preparing the
first entry, I discovered that using a sequence of states from the
Viterbi algorithm to deduce a sequence of classifications produced
obvious errors.  After some thought, I realized that a variant of the
Viterbi algorithm that directly decoded sequences of
\emph{classifications} rather than sequences of \emph{states} would
yield better classification results.  Although I did not implement
such an algorithm in 2000, I have\footnote{I did write code in
  2007--2008.  However the algorithm is flawed.} in preparing this
book.

While the more appropriate algorithm does not perform as well as
James' eye, it does perform well enough to place among the top scores
that appear on the~\index*{PhysioNet}
website.  Here, I will describe the algorithm for decoding
sequences of classification and narrate in a less formal style of
presentation my attempt at using it to \emph{re-win} the contest.

\subsection{The  Challenge and the Data}\label{sec:challenge}

The PhysioNet website announced the challenge and described the data
as follows\footnote{When I looked at the data in 2000, I saw that the
  worst patients were not getting real rest all night long and that
  they were not aware of what they were doing.  About fifteen years
  later I saw data from the night Marguerite spent in a sleep lab.  In
  addition to the kind of data described here, she had EEG
  measurements taken.  The combination provided unambiguous evidence.
  I would not substitute the analysis here for such data.  Also, for
  screening at home, I think SpO$_2$ data from a pulse oximiter would
  be better than the ECG data suggested by the contest.}:

{\it % italic to signify quote
  {\rm \textbf{Introduction:}}
  %
  Obstructive sleep apnea (intermittent cessation of breathing) is a
  common problem with major health implications, ranging from
  excessive daytime drowsiness to serious cardiac arrhythmias.
  Obstructive sleep apnea is associated with increased risks of high
  blood pressure, myocardial infarction, and stroke, and with
  increased mortality rates. Standard methods for detecting and
  quantifying sleep apnea are based on respiration monitoring, which
  often disturbs or interferes with sleep and is generally expensive.
  A number of studies during the past 15 years have hinted at the
  possibility of detecting sleep apnea using features of the
  electrocardiogram. Such approaches are minimally intrusive,
  inexpensive, and may be particularly well-suited for screening. The
  major obstacle to use of such methods is that careful quantitative
  comparisons of their accuracy against that of conventional
  techniques for apnea detection have not been published.

  We therefore offer a challenge to the biomedical research community:
  demonstrate the efficacy of ECG-based methods for apnea detection
  using a large, well-characterized, and representative set of data.
  The goal of the contest is to stimulate effort and advance the state
  of the art in this clinically significant problem, and to foster
  both friendly competition and wide-ranging collaborations. We will
  award prizes of US\$500 to the most successful entrant in each of two
  events.

  {\rm \textbf{Data for development and evaluation:}}
  %
  Data for this contest have kindly been provided by Dr.\ Thomas
  Penzel\index{Penzel, Dr.\ Thomas}  of Philipps-University, Marburg,
  Germany [available on the website].

  The data to be used in the contest are divided into a learning set
  and a test set of equal size. Each set consists of 35 recordings,
  containing a single ECG signal digitized at 100 Hz with 12-bit
  resolution, continuously for approximately 8 hours (individual
  recordings vary in length from slightly less than 7 hours to nearly
  10 hours). Each recording includes a set of reference annotations,
  one for each minute of the recording, that indicate the presence or
  absence of apnea during that minute. These reference annotations
  were made by human experts on the basis of simultaneously recorded
  respiration signals. Note that the reference annotations for the
  test set will not be made available until the conclusion of the
  contest. Eight of the recordings in the learning set include three
  respiration signals (oronasal airflow measured using nasal
  thermistors, and chest and abdominal respiratory effort measured
  using inductive plethysmography) each digitized at 20 Hz, and an
  oxygen saturation signal digitized at 1 Hz. These additional signals
  can be used as reference material to understand how the apnea
  annotations were made, and to study the relationships between the
  respiration and ECG signals. [\ldots]

  {\rm \textbf{Data classes:}}
  %
  For the purposes of this challenge, based on these varied criteria,
  we have defined three classes of recordings:
  \begin{description}
  \item[Class A (Apnea):] These meet all criteria. Recordings in class
    A contain at least one hour with an apnea index of 10 or more, and
    at least 100 minutes with apnea during the recording. The learning
    and test sets each contain 20 class A recordings.
  \item[Class B (Borderline):] These meet some but not all of the
    criteria. Recordings in class B contain at least one hour with an
    apnea index of 5 or more, and between 5 and 99 minutes with apnea
    during the recording. The learning and test sets each contain 5
    class B recordings.
  \item[Class C (Control):] These meet none of the criteria, and may
    be considered normal. Recordings in class C contain fewer than 5
    minutes with apnea during the recording. The learning and test
    sets each contain 10 class C recordings.
  \end{description}

  {\rm \textbf{Events and scoring:}}
  %
  Each entrant may compete in one or both of the following events:
  \begin{description}
  \item[1. Apnea screening:] In this event, your task is to design
    software that can classify the 35 test set recordings into class A
    (apnea) and class C (control or normal) groups, using the ECG
    signal to determine if significant sleep apnea is present.  [\ldots]
  \item[2. Quantitative assessment of apnea:] In this event, your
    software must generate a minute--by--minute annotation file for
    each recording, in the same format as those provided with the
    learning set, using the ECG signal to determine when sleep apnea
    occurs.  Your annotations will be compared with a set of reference
    annotations to determine your score. Each annotation that matches
    a reference annotation earns one point; thus the highest possible
    score for this event will be approximately 16800 (480 annotations
    in each of 35 records). It is important to understand that scores
    approaching the maximum are very unlikely, since apnea assessment
    can be very difficult even for human experts. Nevertheless, the
    scores can be expected to provide a reasonable ranking of the
    ability of the respective algorithms to mimic the decisions made
    by human experts.
  \end{description}
}%% end \it for quote

\subsection{The Data}\label{sec:data}
%%% FixMe: In runs using CM fonts, I see too much space under
%%% FixMe: fig:a03erA.  It and fig:a03erN get put on facing pages.
%%% FixMe: The following text breaks right after "45 seconds and",
%%% FixMe: and there is several inches of empty vertical whitespace
%%% FixMe:  between the figure and the text.

Briefly, one can fetch the following records from PhysioNet:
\begin{description}
\item[a01-a20:] The \emph{a records} from individuals that display
  \emph{apnea}
\item[b01-b05:] The \emph{b records}\footnote{The amplitude of the
    \emph{b05} record varies dramatically over different segments of
    time.  I found it unusable and discarded it entirely.} from
  individuals diagnosed as \emph{borderline}
\item[c01-c10:] The \emph{c records} from \emph{control} or normal
  individuals
\item[a01er-a04er and b01er and c01er:] Identical to \emph{a01-a04}
  and \emph{b01} and \emph{c01} except augmented with respiration and
  $SpO_2$ (percent of arterial hemoglobin saturated with oxygen)
  \nomenclature[rSpO]{$SpO_2$}{Percent of arterial hemoglobin
    saturated with oxygen.} signals
\item[summary\_of\_training:] Expert classifications of each minute in
  the $a$, $b$, and $c$ records
\item[x01-x35:] The test set\footnote{The records \emph{x33} and
    \emph{x34} are so similar that I suspect they are simultaneous
    recordings from different ECG leads.  I did not explicitly exploit
  the similarity in my analysis.}; records without classification
\end{description}

In 2000, using both the data and software to view it from PhysioNet, I
saw striking oscillations in the apnea time series.  The patients stop
breathing for tens of seconds, gasp a few breaths, and stop again.
Each cycle takes about 45 seconds and can go on for most of the night.
I've plotted two periods of such an oscillation from record \emph{a03}
in Fig.~\ref{fig:a03erA}.  The reference or \emph{expert}
classifications provided with the data indicate these are the last
oscillations in the first apnea episode of the night.  Over the entire
night's record of 8 hours and 39 minutes, the patient had apnea for a
total of 4 hours and five minutes in 11 separate episodes.  In that
time, more than once a minute, he was waking up enough to start
breathing.  Ten and a half minutes after the end of the first apnea
episode, the record, as plotted in Fig.~\ref{fig:a03erN}, looks
normal.

\begin{figure}
  \centering{\plotsize%
    \def\SpO{$SpO_2$}%
    \def\ONR{\emph{ONR}}%
    \def\ECG{\emph{ECG}}%
    \IncludeApneaFig{a03erA}}
  \caption[\comment{fig:a03erA }A segment of record a03]%
  {A segment of record a03.  Two cycles of a large apnea
    induced oscillation in $SpO_2$ are drawn in the lower plot.  The
    middle plot is the oronasal airflow signal, and the upper plot is
    the ECG (units of both ONR and ECG are unknown).  The time
    axis is marked in \emph{hours:minutes}.  Notice the increased
    heart rate just after 0:58 and just before 0:59.}\label{fig:a03erA}
\end{figure}

\begin{figure}
  \centering{\plotsize%
    \def\SpO{$SpO_2$}%
    \def\ONR{\emph{ONR}}%
    \def\ECG{\emph{ECG}}%
    \IncludeApneaFig{a03erN}}
  \caption[\comment{fig:a03erN }A segment of record a03]%
  {A segment of record a03 taken during a period of normal
    respiration.  Signals the same as in Fig.~\ref{fig:a03erA}.}\label{fig:a03erN}
\end{figure}

In plots like Fig.~\ref{fig:a03erA}, the heart rate visibly increases
at the end of the gasping phase and then decreases during the phase of
interrupted respiration.  That heart rate oscillation is the key I
used in my initial attempts to classify periods of apnea.  In
Fig.~\ref{fig:a03erHR}, I've plotted both a heart rate derived from
the ECG \nomenclature[rECG]{ECG}{Electrocardiogram} and the $SpO_2$
signal.  The oscillations in the signals track each other, and the
expert classifies only the region of large heart rate oscillation as
apnea.
\begin{figure}
  \centering{\plotsize%
    \def\SpO{$SpO_2$}%
    \def\HR{\emph{HR}}%
    \IncludeApneaFig{a03HR}}
  \caption[\comment{fig:a03HR }A segment of record 03 at the end of an episode of apnea]%
  {A segment of record 03 at the end of an episode of apnea with
    indications in both the $SpO_2$ signal and the heart rate
    \emph{(HR)} signal.  The expert marked the time before 1:00 as
    apnea and the time afterwards as normal.}\label{fig:a03erHR}
\end{figure}

\section{First Classification Algorithms}\label{sec:NVG}

\newcommand{\tmo}{i} % \tmo is t minus one
\newcommand{\tex}{j} % \tex is t exactly
\newcommand{\tpo}{k} % \tpo is t plus one

\subsection{Using Information from Experts to Train}

I first carefully considered the CINC2000 challenge when Andreas
Rechtsteiner told me that he was going to use it as a final project
for a class that James was teaching.  I suggested that he try a two
state HMM with autoregressive observation models with scalar observations.  The performance of Andreas' two state model was not
memorable.

To use the expert classification information in training, Andreas and
I found that we need only modify the observation model.  The technique
is not limited to HMMs with only two states or two classes; it applies
to an arbitrary number of classes and to arbitrary numbers of states
associated with each class.  At each time $t$, let $\ti{c}{t}$ denote
classification information from an expert about which states are
possible.  Specifically $\ti{c}{t}$ is a vector that indicates that
some states are possible and that the others are impossible.  We
simply replace $P_{\ti{Y}{t}|\ti{S}{t},\ts{Y}{1}{t-1}}$ with
$P_{\ti{Y}{t},\ti{C}{t}|\ti{S}{t},\ts{Y}{1}{t-1}}$ wherever it occurs
in the Baum Welch algorithm.\marginpar{The Baum Welch algorithm
  searches for maximum likelihood model parameters given some training
  data.  Running the forward algorithm and backward algorithm are the
  most computationally expensive part of each iteration.} Roughly, the
modification forces the system into states associated with the right
class during training.

\subsection{Nonlinear Dynamics}\label{sec:NLD}

After Andreas finished his class, I looked more carefully at heart
rate time series and the classification errors of a two state model.
I saw evidence of \emph{nonlinear dynamics} such as the period two
waveform and the sawtooth in Fig.~\ref{fig:ApneaNLD}.  Superpositions
of sinusoids can describe such patterns with the right amplitudes and
relative phases of the harmonics.  Although a linear model can favor
the correct frequencies and amplitudes of the component sinusoids,
linear models cannot detect or enforce phase relationships.  The
ability to distinguish phase relationships makes it possible to build
nonlinear models that are more discriminating than any linear model.

\begin{figure}
  \centering{\plotsize%
    \def\aT{\emph{a12} HR}%
    \def\aZ{\emph{a01} HR}%
    \IncludeApneaFig{ApneaNLD}}
  \caption[\comment{fig:ApneaNLD }Nonlinear effects]%
  {Nonlinear effects: The upper plot seems to be a period two
    oscillation.  The lower plot is approximately sawtooth.}\label{fig:ApneaNLD}
\end{figure}

Excited by these observations, I built an HMM with many chains of
states.  Each chain modeled a different form of heart rate
oscillation.  I trained the model on the expertly classified records,
and then used the model to classify those same records.  For each
record, I used the Viterbi algorithm to find the most likely state
sequence given the observations.  Then I derived a classification
sequence from the decoded state sequence by selecting class $C$ at
time $t$ if the decoded state satisfied $\ti{s}{t}\in C$.  The
technique performed terribly.  The sequences of classifications said
every minute was \emph{normal} even though (actually \emph{because}) I had
modeled the different kinds of \emph{apnea} oscillations so carefully.

An analysis of the values of the conditional probabilities of states given
the entire sequence of observations, $P_{\ti{S}{t}|\ts{Y}{1}{T}}
\left(s_i|\ts{y}{1}{T} \right) = \alpha(s_i,t) \beta(s_i,t)$,
revealed the problem and suggested a solution.  Because the model had
many more apnea states than normal states, the state probability was
rarely concentrated enough in a single apnea state for that state to
be decoded.  To address the problem, I solved for the sequence of most
likely classifications, \ie,
\begin{equation}
  \label{eq:smlc}
  \ti{\tilde C}{t} \equiv \argmax_C \sum_{i:s_i\in C}
  P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s_i|\ts{y}{1}{T} \right).
\end{equation}
instead of solving for the most likely sequence of states.  Using
Eqn.~\eqref{eq:smlc} and the HMM with many chains of states, I
classified the test data to prepare a contest entry.  When James
submitted the entry % on April 24, 2000
we found that it classified 78.91\% of the minutes correctly.

In Section~2.3.3 of the book I presented a sequence of MAP
(\emph{Maximum A posteriori Probability}) states that not only failed
to be a MAP sequence of states but that was actually an impossible
sequence.  Since the analogous distinction holds for sequences of
classifications, I developed the flawed algorithm described in
Section~\ref{sec:broken_decode} that seeks
\begin{equation}
  \label{eq:mlsc}
  {\ts{\hat C}{1}{T}} \equiv \argmax_{\ts{C}{1}{T} }
  \sum_{\ts{s}{1}{T}:\ti{s}{t}\in \ti{C}{t}, 1 \leq t \leq T} P\left(
    \ts{s}{1}{T} | \ts{y}{1}{T} \right),
\end{equation}
\ie, the MAP sequence of classifications rather than the sequence of
MAP classifications.

\section{Classes}\label{sec:classes}

In the introduction (Sect.~\ref{sec:introduction}), I said ``I'm
writing this document to clarify my own thoughts and to ask for
help.''.  Now that I've written two dozen pages\footnote{In writing
  the the previous pages, I've rewritten and restructured the software
  and the structure for integrating results of calculations into a
  document.  It's been a good way to start work on revising the book
  and the supporting software.} I'll begin addressing the problem with
Sect.~\ref{sec:broken_decode} which I copied without modification from
the book.  Here, I will discuss points and errors in that section:
\begin{description}
\item[Equation~\eqref{eq:maskedLikelihood}:] I think the normalization
  of the likelihood modified by class is OK.\@
\item[Equation~\eqref{eq:cbest}:] The premise of the definition is
  false.  If the best history ending with $\ti{c}{t+1}=d$ at time
  $t+1$ is the particular sequence $\ts{c}{1}{t+1}$, and that sequence
  ends with $\ti{c}{t-1}=a$, $\ti{c}{t}=b$, $\ti{c}{t+1}=d$, \ie,
  $\ts{c}{1}{t+1} = (\ts{c}{1}{t-1}, a, b, d)$, it is not necessarily
  true that the best sequence leading to $a$ at $t-1$ is
  $\ts{c}{1}{t-1}$ because the random process of classifications is
  not Markov.  Viterbi decoding for states works because the sequence
  of states \emph{is} Markov.  In particular, given the state at time
  $t$ the future is conditionally independent of the past.  That is
  not true for the classifications.  For a given classification
  $\ti{c}{t} = b$ at time $t$, the probability distribution of states
  in the class may contain relevant information about the past.
\item[Equation~\eqref{eq:Cat}:] Because of the flaw in
  Eqn.~\eqref{eq:cbest}, Eqn.~\eqref{eq:Cat} is simply not true.  To
  find the best sequence of classifications leading up to $d$ at time
  $t+1$, one must consider all possible predecessor sequences of
  length $t$.  The cardinality of that set is $\left|C\right|^t$,
  where $\left|C\right|$ is the number of classes.  The corresponding
  equation,~\eqref{eq:cat}, for Viterbi decoding lets you discard all
  but one path leading to a state.  That discarding makes Viterbi
  decoding linear in sequence length.
\end{description}

\subsection{Broken Decode}\label{sec:broken_decode}

In this section, I present a modified Viterbi
algorithm that finds the most likely sequence of classifications given
a model and a sequence of observations.  Before a brief discussion,
let me introduce the following notation and equations:
\subsubsection*{Notation:}
\begin{description}
\item[$g:S^*\times C^* \mapsto \{0,1\}$:] A masking function,
  $g(\ts{s}{1}{t},\ts{c}{1}{t}) = 1$ is equivalent to ``$\ts{s}{1}{t}$ is
  consistent with $\ts{c}{1}{t}$''.  The principal application is
  \begin{equation}\label{eq:maskedLikelihood}
    P_{} \left(\ti{y}{t},\ti{c}{t}|\ti{s}{t} \right) =  P_{}
    \left(\ti{y}{t}|\ti{s}{t} \right) g(\ti{s}{t},\ti{c}{t})
  \end{equation}
\item[$ \ts{\hat c}{1}{t} (c)$:] The best classification sequence ending
  in $c$
  \begin{equation*}
     \ts{\hat c}{1}{t} (c) \equiv \argmax_{\ts{c}{1}{t}:\ti{c}{t}=c}
     P\left(\ts{c}{1}{t}\ts{y}{1}{t}\right)
  \end{equation*}
\item[$\nu(t,c)$:] The \emph{utility} of the best sequence ending in $c$
  \begin{equation*}
    \nu(t,c) \equiv \log\left(P_{} \left(\ts{y}{1}{t},\ts{\hat c}{1}{t}(c)
      \right) \right)
  \end{equation*}
\item[$f(t+1,s,c')$:] The probability of the state $s$ at time $t+1$,
  and output $y(t+1)$ given class $c'$ at time $t$, the best
  classification sequence leading to $c'$, and all previous outputs
  \begin{equation*}
    f(t+1,s,c') \equiv  P\left(\ti{s}{t+1}\is s,\ti{y}{t+1} | y_1^{t}, \ts{\hat c}{1}{t}(c')\right)
  \end{equation*}
\item[$\phi(t,s,c)$:] The probability of state $s$ at time $t$ given
  the best classification sequence ending in $c$ at time $t$ and
  $\ts{y}{1}{t}$.
  \begin{equation*}
    \phi(t,s,c) \equiv P_{} \left(s|\ts{y}{1}{t},\ts{\hat c}{1}{t}(c) \right)
  \end{equation*}
\item[$\cbest\left(c,t+1\right)$:] The best $\ti{c}{t}$ given $\ti{c}{t+1}=c$
  \begin{equation}\label{eq:cbest}
    \cbest\left(c,t+1\right) \equiv \argmax_{\bar c} P_{}
    \left(\ts{y}{1}{t+1},\ts{\hat c}{1}{t}(\bar c),c \right)
  \end{equation}
\end{description}
%
\nomenclature[gf]{$\phi(t,s,c)$}{Used in discussing the Viterbi
  algorithm for class sequences.  The probability of state $s$ at time
  $t$ given the best classification sequence ending in $c$ at time $t$
  and $\ts{y}{1}{t}$.} % end nomenclature

\subsubsection*{Equations:}
\begin{align}
  \ts{\hat c}{1}{t}(c) &= \argmax_{\ts{c}{1}{t}:\ti{c}{t}=c}
  \sum_{\ts{s}{1}{t}} g(\ts{s}{1}{t},\ts{c}{1}{t})
  P\left(\ts{s}{1}{t},\ts{y}{1}{t}\right) \\
  \label{eq:Cat}
  \ts{\hat c}{1}{t+1}(c) &= \left( \left[ \ts{\hat c}{1}{t} (\cbest(c,t+1))\right],c
  \right) \\
  \label{eq:f}
  f(t+1,s,c') &= \sum_{s'}\phi(t,s',c') P(s|s')P(\ti{y}{t+1}|s)\\
  \nu(t+1,c) &= \nu(t,\cbest(c,t+1)) +
  \log\left(\sum_{s} g(s,c) f(t+1,s,\cbest(c,t+1)) \right) \\
  \label{eq:phi}
  \phi(t+1,s,c) & = \frac{f(t+1,s,\cbest(c,t+1))}
  {\sum_{\bar s} g(\bar s,c) f(t+1,\bar s, \cbest(c,t+1))}
\end{align}

Equation \eqref{eq:Cat} says that the best classification sequence
ending in $c$ at time $t+1$ consists of $c$ concatenated with the best
sequence ending in $\cbest$ at time $t$, where $\cbest$ is the best
predecessor of $c$.

Equation \eqref{eq:f} follows from the model assumptions
\begin{equation*}
  P(s|s',\ts{y}{1}{t},\ts{\hat c}{1}{t}(c')) =
  P(s|s')
\end{equation*} and
\begin{equation*}
  P(\ti{y}{t+1}|s,s',\ts{y}{1}{t},\ts{\hat c}{1}{t}(c')) = P(\ti{y}{t+1}|s)
\end{equation*}
and Bayes rule.

To derive Eqn~\eqref{eq:phi} use the following\footnote{I use the
  following abbreviations in this derivation:
  \begin{align*}
    \cbest(c,t+1) & \Rightarrow \cbest \\
    \ts{\hat c}{1}{t}(c') & \Rightarrow \ts{c}{1}{t} \\
    \ts{\hat c}{1}{t+1}(c) & \Rightarrow \ts{c}{1}{t+1}.
  \end{align*}
}
\begin{align}
  f(t+1,s,c') &= \frac{P(s,y_1^{t+1},\ts{c}{1}{t})}{P(\ts{y}{1}{t},\ts{c}{1}{t})}\\
  \sum_{\bar s} g(\bar s,c) f(t+1,\bar s, \cbest(c,t+1)) &= \frac{
    P(y_1^{t+1},\ts{c}{1}{t+1})}{P(\ts{y}{1}{t},\ts{c}{1}{t})}\\
  P(c|s,y_1^{t+1},\ts{c}{1}{t}) &= g(s,c) \\
  &= \frac{ P(s,y_1^{t+1},\ts{c}{1}{t+1})}{P(s,y_1^{t+1},\ts{c}{1}{t})}
\end{align}
and note
\begin{align*}
  \frac{f(t+1,s,c')}{\sum_{\bar s} g(\bar s,c) f(t+1,\bar s, c')}
  P(c|s,y_1^{t+1},\ts{c}{1}{t}) &= \frac{P(s,y_1^{t+1},\ts{c}{1}{t})~ P(\ts{y}{1}{t},\ts{c}{1}{t})
    ~ P(s,y_1^{t+1},\ts{c}{1}{t+1})} {P(\ts{y}{1}{t},\ts{c}{1}{t}) ~ P(y_1^{t+1},\ts{c}{1}{t+1})
    ~ P(s,y_1^{t+1},\ts{c}{1}{t})}\\
  &= P(s|y_1^{t+1},\ts{c}{1}{t+1}) \equiv \phi(t+1,s,c).
\end{align*}

\subsubsection*{Algorithm:}

The algorithm makes a single pass through the sequence of observations
going forward in time.  To move from time $t$ to time $t+1$, consider
each possible classification $c_\text{next}$, and find the best
predecessor classification $c_\text{best}$ at time $t$.  Then collect
and store the best classification sequence ending in that
classification, its log likelihood, and the conditional probabilities
of the hidden states given that classification sequence.  At the last
time step $T$, each possible final classification $\ti{C}{T}$ will be
associated with the best sequence ending in that classification and
the log likelihood of that sequence.  The algorithm simply selects the
sequence with the highest log likelihood.  Figure~\ref{fig:viterbiC}
provides pseudo-code for the algorithm.
%
%%% FixMe: \addcontentsline{loa}{section}{Pseudocode for the Viterbi Algorithm for class sequences}
%%% FixMe: is this a "figure" or an "algorithm"?
\begin{figure}[htbp]
  \begin{center}
    \newcommand{\tnext}{_{\text{next}}}
    \newcommand{\told}{_{\text{old}}}
    \newcommand{\tbest}{_{\text{best}}}
    \newcommand{\ick}[1]{\log \left(\sum_{s} g(s,#1) f(t+1,s,#1) \right)}
    \fbox{
      \begin{minipage}{\columnwidth}
        \begin{tabbing}
          XX\=XX\=XX\=XX\=XX\=XX\=XX\=XX\= \kill
          Initialize: \> \+ \\
          for each $c$\\ \> \+
          $\nu\tnext (c) = \log \left( \sum_{s} g(s,c) P_{\ti{Y}{1},\ti{S}{1}}
            \left(\ti{y}{1},s \right)\right)$ \\ \\ \< \- \< \-
          Iterate: \> \+ \\
          for $t$ from 1 to $T$\\ \> \+
          Swap $\nu\tnext \leftrightarrow \nu\told$\\
          for each $c\tnext$\\ \> \+
          \\ \# Find best predecessor\\
          $c\tbest = \argmax_{c\told}\left( \nu\told(c\told) + \ick{c\told} \right)$ \\
          \\ \# Update $\nu$\\
          $\nu\tnext(c\tnext) =\,$ \= $\nu\told(c\tbest) + \ick{c\tbest}$ \\ \> \-
          \\ \# Update predecessor array\\
          Predecessor[$c\tnext,t$] = $c\tbest$\\
          \\ \# Update $\phi$\\
          for $s$ in $c\tnext$\\ \> \+
          Assign $\phi\tnext(s,c\tnext)$ using Eqn.~\eqref{eq:phi}\\ \\
          \< \- \< \- \< \- %This stuff is for tabs \< \-
          Backtrack: \> \+ \\
          $\ts{c}{1}{t} = \ts{\hat c}{1}{t}(\bar c)$, where $\bar c =
          \argmax_c \nu\tnext(c)$ at $t=T$
        \end{tabbing}
      \end{minipage}
    }
    \caption[\comment{fig:viterbi }Pseudocode for the Viterbi
    Algorithm for class sequences.]%
    {Pseudocode for the Viterbi Algorithm for class sequences}
    \label{fig:viterbiC}
  \end{center}
\end{figure}

\subsection{Looking for a Good Classification Sequence}\label{good}

Since the computational complexity of finding the best sequence of
classifications is exponential in the length of the sequence, I've
written code that looks for a \emph{pretty good} sequence.  As I worked on
it, it seemed that my problem is similar to the traveling salesman
problem.  Is that good or bad?

Let's start by stating the goal.  I seek the maximum a posteriori
probability sequence of classifications for a given sequence of
observations $\ts{y}{1}{T}$, \ie:
\begin{equation}
  \label{eq:MAPclass}
  \ts{\hat{c}}{1}{T} = \argmax_{\ts{c}{1}{T}}P\left(\ts{c}{1}{T}|\ts{y}{1}{T}\right).
\end{equation}
Since $\log$ is monotonic, this is equivalent to
\begin{equation*}
  \ts{\hat{c}}{1}{T} =
  \argmax_{\ts{c}{1}{T}}\text{ score}(\ts{c}{1}{T}),
\end{equation*}
where the score of a classification sequences is
\begin{equation}
  \label{eq:score}
  \text{score}(\ts{c}{1}{t}) \equiv \log\left(
                               P\left(\ts{c}{1}{t}|\ts{y}{1}{t}\right)
                               \right).
\end{equation}

My code grows partial sequences that have high scores.  It manages the
following data structures that represent and grow partial
classification sequences $\ts{c}{1}{t}$.
\begin{description}
\item[Tree:] Each node of the tree is associated with a partial
  sequence, $\ts{c}{1}{t}$.  Each node has a link to its parent,
  namely $\ts{c}{1}{t-1}$.  Each internal node has links to the
  children $\ts{c}{1}{t+1}$, and each leaf has links to the two sorted
  lists described below.  Each leaf node has the following data:
  \begin{description}
  \item[$\mathtt{score}\left(\ts{c}{1}{t} \right)$:] Defined
    in~\eqref{eq:score} as
    $\log\left( P\left(\ts{c}{1}{t}|\ts{y}{1}{t}\right) \right)$
  \item[$P\left(\ti{s}{t}|\ts{c}{1}{t}, \ts{y}{1}{t}\right)$:]  The
    conditional distribution of states given the sequences of classes
    and observations up to the time $t$.
  \end{description}
Initialize the
  tree with $\ti{c}{0} = \mathtt{None}$ where $\mathtt{None}$ is not
  any class.  Assign this initial leaf a score of $0$.
\item[List by scores:] A list of leaves $\ts{c}{1}{t}$ sorted by
  score.  Initialize the list with the leaf
  $\ti{c}{0} = \mathtt{None}$.  Note that the score will decrease
  monotonically with length because at each time step the conditional
  probability of the class is between zero and one.
\item[List by priority:] A list of leaves $\ts{c}{1}{t}$ sorted by the
  function:
  \begin{equation}
    \label{eq:priority}
    \mathtt{priority}\left(\ts{c}{1}{t} \right) \equiv
    \mathtt{score}\left(\ts{c}{1}{t} \right) + \lambda_1 t^{\lambda_2}.
  \end{equation}
  The term $\lambda_1 t^{\lambda_2}$ will give more priority to longer
  sequences, and that will enable the code to find complete plausible
  sequences before resources are exhausted.  I think a better priority
  function is the key to improving performance of the code.
  Initialize the list with the leaf $\ti{c}{0} = \mathtt{None}$.
\item[Best complete sequence.] Initialize as $\mathtt{None}$
\end{description}

\subsubsection{Iteration}\label{iteration}

My code iteratively executes the following sequences of steps:
\begin{description}
\item[Select the leaf with highest priority:] Call its associated sequence
  $\ts{c}{1}{t}$ with $\ti{c}{t} = b$
\item[Remove $\ts{c}{1}{t}$ from the lists of leaves:]
\item[Create new leaves $\left( \ts{c}{1}{t}, \ti{c}{t+1} = d \right)
  \forall d \in C$:] For each new leaf characterized by $\ti{c}{t+1} =
  d$, do the following calculations:
  \begin{align*}
    \psi_0(s) &= P\left(\ti{s}{t}\is s|\ts{c}{1}{t}, \ts{y}{1}{t}\right)
    && \text{From node }\ts{c}{1}{t} \\
    \psi_1(q) &= P\left(\ti{s}{t+1}\is q|\ts{c}{1}{t},
                \ts{y}{1}{t}\right) &&= \sum_s P(q|s) \psi_0(s) \\
    \psi_2(q) &=  P\left(\ti{y}{t+1}, \ti{s}{t+1}\is q|\ts{c}{1}{t},
                \ts{y}{1}{t}\right) &&= P(\ti{y}{t+1}|q) \psi_1(q) \\
    \psi_3 &= P\left(\ti{y}{t+1}|\ts{c}{1}{t},
             \ts{y}{1}{t}\right) &&= \sum_q \psi_2(q) \\
    \psi_4(q) &= P\left(\ti{s}{t+1}\is q|\ts{c}{1}{t},
                \ts{y}{1}{t+1}\right) &&= \frac{\psi_2(q)}{\psi_3} \\
    \psi_5(q,d) &= P\left(\ti{c}{t+1}\is d, \ti{s}{t+1}\is q|\ts{c}{1}{t},
                  \ts{y}{1}{t+1}\right) &&= g(d,q) \psi_4(q) \\
    \psi_6(d) &= P\left(\ti{c}{t+1}\is d|\ts{c}{1}{t},
                \ts{y}{1}{t+1}\right) &&= \sum_q \psi_5(q,d) \\
    \psi_7(q) &= P\left(\ti{s}{t+1}\is d|\ts{c}{1}{t+1},
                \ts{y}{1}{t+1}\right) &&= \frac{\psi_5(q,d)}{\psi_6(d)}
  \end{align*}
  Then use $\psi_7$ for the conditional distribution of states for the
  leaf and assign
  $\mathbf{score}\left(\ts{c}{1}{t+1}\right) = \log(\psi_6) +
  \mathbf{score}\left( \ts{c}{1}{t} \right)$.
\item[If $t+1 < T$:] The sequences in the newly created leaves are not
  complete.  Discard leaves that are impossible ($\psi_6 = 0$), and
  insert links to the remaining leaves in the sorted lists and
  continue with the next iteration cycle.
\item[If $t+1 = T$:] Compare the score of each new leaf $\ts{c}{1}{T}$
  to \textbf{Best complete sequence}.  If the new score is better,
  replace \textbf{Best complete sequence} and remove from lists all
  leaves with lower scores.  Discard the new leaf if its score is not
  better.
\item[If the lists are empty:] The code has found
  $\ts{\hat{c}}{1}{T}$.  Terminate and report the result.
\item[If some resource is exhausted:] EG, runtime or length of lists;
  terminate and report \textbf{Best complete sequence}.  If no
  \textbf{Best complete sequence} has been found, report failure.
\end{description}

\subsection{Questions About Classes}
\label{sec:questions}

\begin{description}
\item[Q:] Why bother with classes?
\item[A:] The apnea classification problem needs classes for training,
  and it illustrates the weakness of using Viterbi decoding to
  estimate class.  Namely: Decoding will not find a class that is
  richly modeled with many plausible states.
\item[Q:] Why not use the sequence of most probable (MAP) states, ie,
  \begin{equation}
    \label{eq:mapStates}
    \ts{\hat{c}}{1}{T}, \text{ with } \ti{\hat{c}}{t} = \argmax_{\tilde{c}}
    P \left(\ti{\tilde{c}}{t}|\ts{y}{1}{T} \right)?
  \end{equation}
\item[A:] Well that might be the best thing to do for the apnea
  problem where the objective function is the \% of minutes classified
  correctly, but that procedure can in general yield an impossible
  estimate, \ie, $P(\ts{\hat{c}}{1}{T}|\ts{y}{1}{T}) = 0$.  So, if
  your objective function is the expected value of the probability of
  the entire sequence being correct,~\eqref{eq:mapStates} is
  inappropriate.
\item[Q:] Why not just let this whole classes thing go?  Use the
  sequence of MAP states for the apnea problem and move on.
\item[A:] I feel hierarchies of something like classes is the way to
  model multi-scale phenomena, and that it will be interesting and
  valuable.  The notion of approximate invariance might be related.
\item[Q:] What is an example or application?
\item[A:] Well for spoken language, you have the following levels:
  \begin{enumerate}
  \item Vibration and movement of air
  \item Position and movement of articulators (tongue, lips, etc.)
  \item Structure of the articulators (influenced by gender)
  \item Accent (many models of phonemes)
  \item Words
  \item Sentences
  \item Topic
  \end{enumerate}
\item[Q:] Hasn't Google solved this with deep learning?
\item[A:] Probably.  I need a simpler application, and I need better
  theory and algorithms.
\end{description}
\end{document}


%%% Local Variables:
%%% eval: (load-file "hmmkeys.el")
%%% End:
