% \documentclass[twocolumn]{article}
\RequirePackage{rotating}
\documentclass[]{article}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{xspace}
%\usepackage[pdftex]{graphicx,color} % For including pdfs

\usepackage{graphicx}
\usepackage[most]{tcolorbox}
\usepackage{figlatex}

% Commands from Hmmdsbook/hmmdsbook.cls
\usepackage{afterpage}
\usepackage[norefeq,refpage,nocfg,intoc,noprefix]{nomencl}
\newcommand{\parameters}{\theta}
\newcommand{\ts}[3]{#1_{#2}^{#3}}                    % Time Sequence
\newcommand{\argmin}{\operatorname*{argmin}}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\ti}[2]{{#1}{(#2)}}                  % Time Index
\newcommand{\states}{{\cal S}}
\newcommand{\ie}{i.e.\xspace}
\newcommand{\eg}{e.g.\xspace}
\newcommand{\etal}{et al.\xspace}
\newcommand{\iid}{i.~i.~d.\xspace}
\newcommand{\plotsize}{%
  \fontsize{9}{9}%
  \selectfont}
\newenvironment{symbdescription}{%
  \list{}{%
    \labelwidth\nomlabelwidth
    \leftmargin\labelwidth
    \advance\leftmargin\labelsep
    \itemsep\nomitemsep
    \let\makelabel\nomlabel}}%
{\endlist}
\renewcommand{\comment}[1]{}

% Commands for figures

\newcommand*{\inputfig}[2]{\input{#1/#2.pdf_t}}
\newcommand*{\InputIntroductionFig}[1]{\inputfig{../figs/introduction}{#1}}
\newcommand*{\InputBasicAlgorithmsFig}[1]{\inputfig{../figs/basic_algorithms}{#1}}

\newcommand{\IncludeApneaFig}[1]{\includegraphics[scale=0.7]{../figs/apnea/#1.pdf}}

\title{Estimating Membership in Bundles of HMM States: Notes for
  Friends\footnote{Diane Vaughan}}

\author{Andrew Fraser}

\begin{document}

\maketitle

\section{Introduction}
\label{sec:introduction}

In 2008, SIAM published my book \emph{Hidden Markov Models and
  Dynamical Systems.}  In the final chapter, I used HMMs to classify
each minute of EKG records as either normal or as apnea.  The key to
that effort was building HMMs with many states \eg 14 in which the
states were partitioned into \emph{bundles}.  Half of the states could
belong to the apnea bundle with the other half belonging to the normal
bundle.  A few years after SIAM published the book, I began rewriting
the software with the intention of illustrating exemplary software
practices.  One such practice is \emph{unit testing}.  Unit testing
revealed a conceptual error in my treatment of bundles.  Since then
I've made a few starts at fixing the code and the book.  I've learned
more about good software practices, but I haven't set aside enough
time to finish the project.

I am returning to the project now that I have retired from LANL.
After rewriting the basic HMM code, I turned to the problem of
bundles.  I have at least 3 different ways of handling them.  I'm
writing this document to clarify my own thoughts and to ask for help.

Since even in this brief introduction I've used some jargon that I
should explain before asking for help, I will review Hidden Markov
Models, \emph{HMMs}, before describing how I treat bundles.  I've
drawn some of the following text and figures from the book.

\section{Hidden Markov Models with States and Observations Drawn from
  Discrete Sets}
\label{sec:hmms}

In this section I describe the simplest HMMs: those that are
discrete in time, state, and observation.  I begin with a couple of
definitions.  Three random variables $\ti{X}{1}$, $\ti{X}{2}$, and
$\ti{X}{3}$ constitute a \emph{\index*{Markov chain}} if their
probability distributions obey
\begin{equation}
  \label{eq:MarkovChain}
  P_{\ti{X}{3}|\ti{X}{1},\ti{X}{2}} = P_{\ti{X}{3}|\ti{X}{2}},
\end{equation}
which is equivalent to $\ti{X}{1}$ and $\ti{X}{3}$ being conditionally
independent given $\ti{X}{2}$, \ie,
\begin{equation*}
  P_{\ti{X}{3},\ti{X}{1}|\ti{X}{2}} = P_{\ti{X}{3}|\ti{X}{2}}   P_{\ti{X}{1}|\ti{X}{2}}.
\end{equation*}
An indexed sequence of random variables $\ts{X}{1}{T}$ is a
\emph{Markov process} \index{Markov process} if
for any $t: 1 < t < T$ the variables before and after $t$ are
conditionally independent given $\ti{X}{t}$, \ie,
\begin{equation}
  \label{eq:MarkovProcess}
  P_{\ts{X}{1}{t-1},\ts{X}{t+1}{T}|\ti{X}{t}} =
  P_{\ts{X}{1}{t-1}|\ti{X}{t}} P_{\ts{X}{t+1}{T}|\ti{X}{t}}.
\end{equation}
I will restrict my attention to time invariant models, \ie, those
for which the transition probabilities are constant over time.
Begin by considering the ordinary (\emph{unhidden})
Markov model or process sketched in Fig.~\ref{fig:mm}.  The set of
states $\states = \left\{u,v,w\right\}$, the probability distribution
for the initial state
\begin{equation}
  \label{eq:InitialProbabilites}
P_{\ti{S}{1}} =
\begin{bmatrix}
  \frac{1}{3}, & \frac{1}{3}, & \frac{1}{3}
\end{bmatrix},
\end{equation}
and the \index*{transition matrix} %
\index{matrix!transition}%
\begin{equation}
  \label{eq:TransitionMatrix}
\begin{array}{rr|ccc}
  && \multicolumn{3}{c}{\ti{S}{t+1}} \\
  \multicolumn{2}{c|}{P(\ti{s}{t+1}|\ti{s}{t})} & u & v & w \\ \hline
  & u & 0 & 1 & 0 \\  && \vspace{-1 em} \\
  \ti{S}{t} & v & 0 & \frac{1}{2} & \frac{1}{2} \\  && \vspace{-0.98 em} \\
  & w & \frac{1}{2} & \frac{1}{2} & 0
\end{array}
\end{equation}
define the model, and the model determines the probability of any
sequence of states $\ts{s}{1}{T}$, which I write\footnote{I use
  upper case letters to denote random variables and $P$ to denote
  probability distribution functions.  A random variable used as
  subscript on $P$ specifies that I mean the distribution of that
  random variable.  I can give $P$ an argument to specify the value
  of the distribution function at that value, \eg $P_X(3)$ is the
  probability that the random variable $X$ has the value 3 and
  $P_X(x)$ is the probability that the random variable $X$ has the
  value $x$.  I usually drop subscripts on $P$ when the context or
  argument resolves ambiguity as to which probability function I
  mean.} as $P_{\ts{S}{1}{T}}\left( \ts{s}{1}{T} \right)$.  For
example I calculate the probability that a sequence of 4 states has
the values $\ts{s}{1}{4} = (u,v,w,v)$, (\ie, $\ti{s}{1} = u$,
$\ti{s}{2} = v$, $\ti{s}{3} = w$, and $\ti{s}{4} = v$) as follows:


\begin{align}
  \label{eq:intro_hmm1}
  P(\ts{s}{1}{4}) &= P(\ti{s}{1}) \prod_{\tau=2}^4 %
                     P(\ti{s}{\tau}|\ts{s}{1}{\tau-1})\\
  \label{eq:intro_hmm2}
                  &= P(\ti{s}{1}) \prod_{\tau=2}^4 %
                     P(\ti{s}{\tau}|\ti{s}{\tau-1}) \\
  \label{eq:intro_hmm3}
  P(u,v,w,v)      &= P(v|u,v,w) \cdot P(w|u,v) \cdot  P(v|u) \cdot P(u)\\
  \label{eq:intro_hmm4}
        &= P(v|w) \cdot P(w|v) \cdot  P(v|u) \cdot P(u)\\
  \label{eq:intro_hmm5}
        &= \frac{1}{2} \cdot \frac{1}{2} \cdot 1 %
                     \cdot \frac{1}{3} = \frac{1}{12}.
\end{align}

Applying \index*{Bayes rule} $\left( P_{A|B} P_B = P_{A,B} \right)$
recursively, yields Eqn.~\eqref{eq:intro_hmm1} and the special case,
Eqn.~\eqref{eq:intro_hmm3}.  Equations \eqref{eq:intro_hmm2} and
\eqref{eq:intro_hmm4} follow from Eqns.~\eqref{eq:intro_hmm1} and
\eqref{eq:intro_hmm3} respectively by the %
\emph{\index*{Markov assumption}}, Eqn.~\eqref{eq:MarkovProcess}.
which says that in determining the probability of the $t^\text{th}$
state given any sequence of previous states only the $(t-1)^\text{th}$
state is relevant. %
%%%


A common exercise is to find a \emph{\index*{stationary}} probability
distribution, \ie, given a transition matrix $T$ find the probability
vector $V$ (non-negative entries that sum to one) that satisfies
\begin{equation}
  \label{eq:statCond}
  VT = V.
\end{equation}
If \eqref{eq:statCond} holds, then
\begin{equation*}
  P_{\ti{S}{2}}  = P_{\ti{S}{1}}T = P_{\ti{S}{1}} = P_{\ti{S}{t}}
  \forall t,
\end{equation*}
and in fact all probabilities are independent of shifts in time, \ie,
\begin{equation*}
  P_{\ts{S}{1}{t}} = P_{\ts{S}{1+\tau}{t+\tau}} \forall (t,\tau),
\end{equation*}
which is the definition of a stationary process.  Quick calculations
verify that the initial probability and transition matrix in
\eqref{eq:InitialProbabilites} and \eqref{eq:TransitionMatrix} do not
satisfy \eqref{eq:statCond} but that the distribution $V =
\begin{bmatrix} \frac{1}{7}, & \frac{4}{7}, & \frac{2}{7}
\end{bmatrix}$ does.  Although the example is not a stationary
stochastic process, it relaxes towards such a process in the sense
that
\begin{equation*}
  \lim_{t \rightarrow \infty} P_{\ti{S}{t}} =  \lim_{t \rightarrow
    \infty} P_{\ti{S}{1}} T^t = \begin{bmatrix} \frac{1}{7}, & \frac{4}{7}, & \frac{2}{7}
\end{bmatrix}.
\end{equation*}

\begin{figure}[htbp]
  \centering{\plotsize%
    \InputIntroductionFig{Markov_mm}
  }
  \caption[\comment{fig:Markov }A Markov model.]{A Markov model}
  \label{fig:mm}
\end{figure}

The important points about a Markov model also apply to hidden
Markov models, namely that:
\begin{itemize}
\item The model determines the probability of arbitrary sequences of
  observations,
\item and the assumptions about independence and time invariance
  permit specification of the model by a small number of parameters.
\end{itemize}

% karlheg does not like the "," after the display-math array.  The
% punctuation here is not in any style manual, but karlheg thinks it
% seems right:
%
Now suppose, as sketched in Fig.~\ref{fig:dhmm}, that when the system
arrives in a state that rather than observing the state directly, one
observes a random variable that depends on the state.  The matrix that
specifies the random map from states to observations, \ie%
:
\begin{equation*}
  \begin{array}{cr|ccc}
      &      &\multicolumn{3}{c}{Y} \\
      \multicolumn{2}{r|}{P(y|s)} & d & e           & f \\ %
      \hline%
      & u      & 1 & 0           & 0 \\
      &        & \vspace{-1 em} \\
    S & v      & 0 & \frac{1}{3} & \frac{2}{3} \\
      &        & \vspace{-1 em} \\
      & w      & 0 & \frac{2}{3} & \frac{1}{3}
  \end{array}%,
\end{equation*}
combined with the distribution of initial states
\eqref{eq:InitialProbabilites} and transition matrix
\eqref{eq:TransitionMatrix} specifies this \emph{hidden} Markov model.
The notion is that the underlying Markov process chugs along unaware
of the observations, and that when the process arrives at each
successive state $\ti{s}{t}$, an observation $\ti{y}{t}$ is produced
in a fashion that depends only on the state $\ti{s}{t}$.

\begin{figure}[htbp]
  \centering{\plotsize%
    \InputIntroductionFig{Markov_dhmm}
  }
  \caption[\comment{fig:Markov_dhmm }A hidden Markov model.]{A hidden Markov model}
  \label{fig:dhmm}
\end{figure}

Let me calculate the probability that a sequence of four observations
from this process would have the values $\ts{y}{1}{4} = (d,e,f,e)$.
As an intermediate step I calculate $P(\ts{y}{1}{4},\ts{s}{1}{4})$
for the given observation sequence and all possible state sequences.
Then I add to obtain
\begin{equation}
  \label{eq:dhmm_sum}
  \sum_{\ts{s}{1}{4}} P(\ts{y}{1}{4},\ts{s}{1}{4}) = P(\ts{y}{1}{4}).
\end{equation}
It is convenient that the only state sequences that could have
produced the observation sequence are $(u,v,v,v)$, $(u,v,v,w)$, and
$(u,v,w,v)$.  For any other state sequence
$P(\ts{y}{1}{4},\ts{s}{1}{4}) = 0$.

\begin{subequations}
\label{eq:pcalc}
 \begin{align}
  \ts{s}{1}{4} & & P(\ts{s}{1}{4}) %
                & & P(\ts{y}{1}{4}|\ts{s}{1}{4}) %
                 & & P(\ts{y}{1}{4},\ts{s}{1}{4})\nonumber\\[1ex]
  \hline\nonumber\\[-2ex]
  uvvv         & & \frac{1}{3} \cdot 1 \cdot \frac{1}{2} \cdot \frac{1}{2} %
                & & 1 \cdot \frac{1}{3} \cdot \frac{2}{3} \cdot \frac{1}{3} %
                 & & \frac{2}{324}\\[1ex]
%%%
  uvvw         & & \frac{1}{3} \cdot 1 \cdot \frac{1}{2} \cdot \frac{1}{2} %
                & & 1 \cdot \frac{1}{3} \cdot \frac{2}{3} \cdot \frac{2}{3} %
                 & & \frac{4}{324}\\[1ex]
%%%
  uvwv         & & \frac{1}{3} \cdot 1 \cdot \frac{1}{2} \cdot \frac{1}{2} %
                & & 1 \cdot \frac{1}{3} \cdot \frac{1}{3} \cdot \frac{1}{3} %
                 & & \frac{1}{324}
 \end{align}
\end{subequations}

Adding the fractions in the right hand column yields %
\begin{equation*}
  P(d,e,f,e) = \frac{7}{324}.
\end{equation*}

Now examine this calculation more carefully beginning with a statement
of the model assumptions.
\begin{description}
\item[The state process is Markov:] Given the current state, the
  probability of the next state is independent of earlier states and
  observations, \ie,
  \begin{equation}
    \label{eq:assume_markov}
    P_{\ti{S}{t+1}|\ts{S}{1}{t},\ts{Y}{1}{t}} = %
        P_{\ti{S}{t+1}|\ti{S}{t}}.
  \end{equation}
\item[The observations are conditionally independent given the states:]
  Given the current state, the probability of the current observation is
  independent of states and observations at all earlier times, \ie,
  \begin{equation}
    \label{eq:assume_output}
    P_{\ti{Y}{t}|\ts{S}{1}{t},\ts{Y}{1}{t-1}} = %
        P_{\ti{Y}{t}|\ti{S}{t}}.
  \end{equation}
\end{description}
Though the assumptions appear asymmetric in time, they are
not\footnote{I often use the following facts about independence
  relations:
  \begin{align}
    P(A|B,C) = P(A|B)   &\iff     P(A,C|B) = P(A|B) \cdot P(C|B)\nonumber\\
    \label{eq:markov-symmetry}%
                        &\iff     P(C|A,B) = P(C|B)\\
    P(A|B,C,D) = P(A|B) &\iff     P(A,C,D|B) = P(A|B) \cdot P(C,D|B)\nonumber\\
                        &\implies P(A,C|B) = P(A|B) \cdot P(C|B)\nonumber\\
    \label{eq:independence-groups}%
                        &\iff     P(A|B,C) = P(A|B).
  \end{align}
  The first chain of implications, \eqref{eq:markov-symmetry}, says
  that if a process is Markov with time going forward, then it is also
  Markov with time going backwards.  The second chain,
  \eqref{eq:independence-groups}, says that if $A$ is conditionally
  independent of $C$ and $D$ given $B$, then $A$ is conditionally
  independent of $C$ alone given $B$.  By symmetry, $A$ is also
  conditionally independent of $D$ given $B$.}.  From the assumptions,
one can derive that
\begin{description}
\item[The joint process is Markov:]
  \begin{equation*}
    P_{\ts{Y}{t+1}{T},\ts{S}{t+1}{T}|\ts{Y}{1}{t},\ts{S}{1}{t}}
      = P_{\ts{Y}{t+1}{T},\ts{S}{t+1}{T}|\ti{Y}{t},\ti{S}{t}}
  \end{equation*}
\item[Given $\bm{\ti{S}{t}}$, $\bm{\ti{Y}{t}}$ is conditionally independent of everything else:]
  \begin{equation*}
    P_{\ti{Y}{t} |\ts{Y}{1}{t-1},\ts{Y}{t+1}{T}, \ts{S}{1}{T}} = P_{\ti{Y}{t} |\ti{S}{t}}
  \end{equation*}
\end{description}
Equations \eqref{eq:assume_markov} and \eqref{eq:assume_output} are
assumptions about \emph{conditional independence} relations.  Figure
\ref{fig:dhmm_net} represents these relations as a %
\emph{\index*{Bayes net}}.

\begin{figure}[htbp]
  \centering{\plotsize%
    \InputIntroductionFig{Markov_dhmm_net}
  }
  \caption[\comment{fig:dhmm-net }Bayes net schematic for a hidden Markov model.]%
  {Bayes net schematic for a hidden Markov model.  The drawn edges
    indicate the dependence and independence relations: Given
    $\ti{S}{t}$, $\ti{Y}{t}$ is conditionally independent of
    everything else.  Also, given $\ti{S}{t}$ all earlier values of
    state and observation are conditionally independent of all later
    values of state and observation.}
  \label{fig:dhmm_net}
\end{figure}

Bayes rule and the assumptions justify
\begin{align}
  P(\ts{Y}{1}{T},\ts{S}{1}{T}) &= P(\ts{S}{1}{T}) \, %
                                   P(\ts{Y}{1}{T}|\ts{S}{1}{T}),\notag\\
  \label{eq:sseqprob}%
  P(\ts{S}{1}{T})              &= P(\ti{S}{1}) %
                                   \prod_{t=2}^T P(\ti{S}{t}|\ti{S}{t-1})\\
  \label{eq:condyseqprob}%
  P(\ts{Y}{1}{T}|\ts{S}{1}{T}) &= \prod_{t=1}^T P(\ti{Y}{t}|\ti{S}{t})\\
  \intertext{and I conclude}
  P(\ts{Y}{1}{T},\ts{S}{1}{T}) &= P(\ti{S}{1}) %
                                   \prod_{t=2}^T P(\ti{S}{t}|\ti{S}{t-1})\, %
                                   \prod_{t=1}^T P(\ti{Y}{t}|\ti{S}{t}).\notag
\end{align}

Since the state $u$ produces the observation $d$ exclusively and no
other state can produce $d$, the observation sequence $(d,f,e,f)$ is
only possible if the state sequence begins with $u$ and does not
return to $u$.  That constraint reduces the number of possible state
sequences to eight.  The impossibility of state $w$ following itself,
further constrains the possible state sequences to the three listed in
the calculations of Eqn.~\eqref{eq:pcalc}.  One can verify the values
for $P(\ts{s}{1}{T})$ and $P(\ts{y}{1}{T}|\ts{s}{1}{T})$ in those
calculations by applying Eqns.~\eqref{eq:sseqprob} and
\eqref{eq:condyseqprob}.

The calculation of $P(\ts{y}{1}{4})$ in Eqn.~\eqref{eq:pcalc} is easy
because, of the $3^4 = 81$ conceivable state sequences, only three are
consistent with the observations and model structure.  In general
however, if there are $N_S$ states and an observation sequence with
length $T$, then implementing
\begin{equation*}
  P(\ts{y}{1}{T}) = \sum_{\ts{s}{1}{T}} P\left(\ts{s}{1}{T}
    ,\ts{y}{1}{T} \right)
\end{equation*}
naively requires order $\left(N_S\right)^T$ calculations.  If $N_S$
and $T$ are as large as one hundred, $\left(N_S\right)^T$ is too many
calculations for any conceivable computer.

There is a family of algorithms whose complexities are linear in the
length $T$ that make it possible to use HMMs with interestingly long
time series.  I will provide details of three of those algorithms in
subsequent sections.  Here I only list their names and objectives.  In
these descriptions, I denote by $\parameters$ the vector of
parameters that define an HMM, namely the state transition
probabilities, the initial state probabilities, and the conditional
observation probabilities,
\begin{equation*}
   \parameters \equiv \left\{
     \begin{aligned}
       &\left\{\; P_{\ti{S}{t+1}|\ti{S}{t}} \left(s'|s
       \right)~\forall s,s' \;\right\},\\
       & \left\{\; P_{\ti{S}{1}} \left(s \right)~\forall s
       \;\right\},\\
       &  \left\{\; P_{\ti{Y}{t}|\ti{S}{t}} \left(y_i|s' \right)
       ~ \forall y_i,s' \;\right\}
     \end{aligned}
   \right\}.
\end{equation*}
\begin{description}
\item[The Viterbi Algorithm:] \index{Viterbi algorithm} Given a model
  $\parameters$ and a sequence of observations $\ts{y}{1}{T}$, the
  Viterbi algorithm finds the most probable state sequence $\ts{\hat
    s}{1}{T}$, \ie,
  \begin{equation}
    \label{eq:intro-viterbi}
    \ts{\hat s}{1}{T} = \argmax_{\ts{s}{1}{T}} P
    \left(\ts{s}{1}{T}|\ts{y}{1}{T},\parameters\right).
  \end{equation}
  %
\item[The Forward Algorithm:] For each time step $t$ and each state
  $s$, the \index*{forward algorithm} calculates the conditional
  probability of being in state $s$ at time $t$ given all of the
  observations up to that time, \ie,
  $P_{\ti{S}{t}|\ts{Y}{1}{t},\parameters} \left(s|\ts{y}{1}{t},
    \parameters \right)$. It also calculates
  $P\left(\ti{y}{t}|\ts{y}{1}{t-1}, \parameters \right)$, the
  conditional probability of each observation given previous
  observations.  Using these terms it calculates the probability of
  the entire data sequence given the model,
  \begin{equation*}
    P \left(\ts{y}{1}{T}|\parameters \right) =  P \left(\ti{y}{1}
      |\parameters \right) \cdot  \prod_{t=2}^T P
    \left(\ti{y}{t}|\ts{y}{1}{t-1}, \parameters \right).
  \end{equation*}
  %
\item[The Backward Algorithm] The \index{backward algorithm} backward
  algorithm calculates the influence of later observations on the
  conditional distribution of states at each time.  After running both
  the forward algorithm and the backward algorithm, one can calculate
  $P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)$, the
  conditional probability of being in any state $s \in \states$ at any
  time $t: 1\leq t \leq T$ given the entire sequence of observations.
\end{description}

\subsection{The Model Parameters}
\label{sec:parameters}

Before describing the algorithms, I review the notation for the model
parameters.  \setlength{\nomlabelwidth}{2.7cm}%
\begin{symbdescription}
\item[$\bm{P_{\ti{S}{t+1}|\ti{S}{t}}(s|{\tilde s})}$] The probability that
  at time $t+1$ the system will be in state $s$ given that at time
  $t$ it was in state ${\tilde s}$.  Notice that the parameter is independent
  of time $t$.
\item[$\bm{P_{\ti{S}{1}}(s)}$] The probability that the system will
  start in state $s$ at time 1.
\item[$\bm{P_{\ti{Y}{t}|\ti{S}{t}}(y_k|{\tilde s})}$] The probability that
  the observation value is $y_k$ given that the system is in state ${\tilde s}$.
\item[$\bm{\parameters}$] The entire collection of parameters.
\end{symbdescription}

\subsection{The Forward Algorithm}
\label{sec:forward}
\index{forward algorithm|textbf}

Given $\parameters$, the forward algorithm calculates
$P(\ts{y}{1}{T}|\parameters)$, and several useful intermediate terms.
Figure~\ref{fig:forward} sketches the structure of the recursion.
Since I are considering only one set of parameters, I will drop the
dependence of probabilities on $\parameters$ from the notation for the
remainder of this section.  In the example of Eqn.~\eqref{eq:pcalc} I
found that I could calculate the right hand terms of
\begin{equation*}
   P\left( \ts{y}{1}{T} \right) = \sum_{\ts{s}{1}{T}}
   P\left( \ts{y}{1}{T},\ts{s}{1}{T} \right)
\end{equation*}
easily from the model assumptions.  Unfortunately, the number of
possible sequences $\ts{s}{1}{T}$ is exponential in $T$, and it is
impossible to do the sum for even modest lengths $T$.

\begin{sidewaysfigure}[htbp]
  %% 0.75\textheight is approx 5.7 in.  The .eps is exactly that size.
  %% The widths for the minipages below are taken by measuring the
  %% ovals inside of XFig.
  \centering{\plotsize%
    %% Column a
    \def\colaa{$\alpha(s_1,t-1)$}%
    \def\colab{$\alpha(s_2,t-1)$}%
    \def\colac{$\alpha(s_3,t-1)$}%
    %% Column b
    \def\colba{$P \left(s_1|\ts{y}{1}{t-1} \right)$}%
    \def\colbb{$P \left(s_2|\ts{y}{1}{t-1} \right)$}%
    \def\colbc{$P \left(s_3|\ts{y}{1}{t-1} \right)$}%
    \def\sumeqforwardAthree{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        Weighted\\%
        sum of prior\\%
        $\alpha$'s\\%
        Eqn.~\eqref{eq:forwardA3}
      \end{minipage}}%
    %% Column c
    \def\colca{$P \left(s_1,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\colcb{$P \left(s_2,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\colcc{$P \left(s_3,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\prdeqforwardBtwo{%
      \begin{minipage}[t]{2.3in}
        \raggedright%
        Multiply\\%
        observation\\%
        probability\\%
        Eqn.~\eqref{eq:forwardB2}
      \end{minipage}}%
    %% Column d
    \def\coldb{$P(\ti{y}{t}|\ts{y}{1}{t-1})$}%
    \def\prdeqforwardC{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        Add, to get $\gamma(t)$\\%
        $\equiv P \left(\ti{y}{t}|\ts{y}{1}{t-1} \right)$\\%
        Eqn.~\eqref{eq:forwardC}
      \end{minipage}}%
    %% Column e
    \def\colea{$\alpha(s_1,t)$}%
    \def\coleb{$\alpha(s_2,t)$}%
    \def\colec{$\alpha(s_3,t)$}%
    \def\quoteqforwardD{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        Normalize\\%
        new $\alpha$'s\\%
        Eqn.~\eqref{eq:forwardD}
      \end{minipage}}%
    \InputBasicAlgorithmsFig{forward}
  }
  \vspace{5 em}
  \caption[\comment{fig:forward }Dependency relations in the forward algorithm.]%
  {Dependency relations in the forward algorithm (See
    Eqns.~\eqref{eq:forwardA}-\eqref{eq:forwardD} in the text).}
  \label{fig:forward}
\end{sidewaysfigure}
\afterpage{\clearpage}%% Print this right here please.


The forward algorithm regroups the terms and produces the desired
result using order $T$ calculations.  For each time $t:\, 1 < t \leq
T$ I calculate $P(\ti{y}{t}|\ts{y}{1}{t-1})$, and in principle I can
write
\begin{equation*}
  P(\ts{y}{1}{T}) = P(\ti{y}{1}) \prod_{t=2}^T P(\ti{y}{t}|\ts{y}{1}{t-1}).
\end{equation*}
However the values of $P(\ti{y}{t}|\ts{y}{1}{t-1})$ are typically
small compared to 1, and the product of many such terms is too small
to be represented even in double precision.  Working with logarithms
avoids underflow:

\begin{equation}
  \label{eq:logP}
  \log\left( P(\ts{y}{1}{T}) \right) = \log\left( P(\ti{y}{1})
 \right) + \sum_{t=2}^T \log\left( P(\ti{y}{t}|\ts{y}{1}{t-1})\right).
\end{equation}

% Perhaps use \usepackage[most]{tcolorbox} for these boxes
\definecolor{MyGreen}{rgb}{0,.5,0}%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% #1 = time #2 = state
\newcommand{\alphax}[2]{%
  \tcboxmath[colback=white,colframe=cyan]{%  Todo double box
    P_{S(#1)|\ts{Y}{1}{#1}}\left(#2 |\ts{y}{1}{#1} \right)%
  }%
}%
%%%
%%%
\newcommand{\prealpha}{%
  \tcboxmath[colback=white,colframe=MyGreen]{%
    P_{\ti{S}{t}|\ts{Y}{1}{t-1}} \left(s | \ts{y}{1}{t-1} \right)%
  }%
}%
%%%
\newcommand{\gammax}{%
  \tcboxmath[colback=white,colframe=blue]{%
    P(\ti{y}{t}|\ts{y}{1}{t-1})%
  }%
}%
%%%
%%%
\newcommand{\pregamma}{%
  \tcboxmath[colback=white,colframe=red]{%
    P_{\ti{S}{t},\ti{Y}{t}|\ts{Y}{1}{t-1}} \left(s,\ti{y}{t}|\ts{y}{1}{t-1}\right)%
  }%
}%
%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For each time step I do the four calculations specified in
equations \ref{eq:forwardA}-\ref{eq:forwardD} below.  In these
equations I use boxes to emphasize repeated instances of the same
quantity.  The algorithm saves the intermediate results
%
\nomenclature[ga]{$\alpha(s,t)$}{The conditional probability that at time
  $t$ the system is in state $s$ given the observations up to the
  present,
  \begin{equation*}
    \alpha(s,t) \equiv  P_{S(t)"|\ts{Y}{1}{t}}\left(s "|\ts{y}{1}{t}
    \right).
  \end{equation*}
  Also called the forward updated distribution in the Kalman filter
  literature.}
%
\nomenclature[gc]{$\gamma(t)$}{The probability of the present observation
  given the history.}%, $P(y(t)|y_1^{t-1}$.}
\begin{align}
  \label{eq:alpha}
  \alpha(s,t) &\equiv \alphax{t}{s}\\
  \label{eq:gamma}
  \ti{\gamma}{t} &\equiv \gammax .
\end{align}
In words, $\alpha(s,t)$ is the
conditional probability of being in state $s$ at time $t$ given all
of the observations up to time $t$, and $\ti{\gamma}{t}$ is the
conditional probability of the observation at time $t$ given all of
the previous observations.  To initialize the algorithm, one assigns
\begin{equation*}
\alpha(s,1) = P_{\ti{S}{1}|\ti{Y}{1}}(s|\ti{y}{1}) =
\frac{P_{\ti{S}{1}}(s)P_{\ti{Y}{t}|\ti{S}{t}}(\ti{y}{1}|s)}
{\sum_{{\tilde s}}P_{\ti{S}{1}}({\tilde s})P_{\ti{Y}{t}|\ti{S}{t}}(\ti{y}{1}|{\tilde s})}
~\forall s \in \states
\end{equation*}
where the distributions $P_{\ti{S}{1}}$ and $P_{\ti{Y}{t}|\ti{S}{t}}$
are model parameters.
\begin{description}
\item[\underline{Forecast} the Distribution of States] Find for time $t$ and each
  possible state $s$, the conditional probability, given the
  previous observations, of the state being $s$ at time $t$:
  \begin{subequations}
    \label{eq:forwardA}
    \begin{align}
      \label{eq:forwardA1}
      &\prealpha = \sum_{{\tilde s}\in\states}
      P_{\ti{S}{t},\ti{S}{t-1}|\ts{Y}{1}{t-1}} \left( s, {\tilde s}
      |\ts{y}{1}{t-1} \right)\\
      \label{eq:forwardA2}
      & = \sum_{{\tilde s}\in\states}
        P_{\ti{S}{t}|\ti{S}{t-1},\ts{Y}{1}{t-1}}
        \left( s|{\tilde s},\ts{y}{1}{t-1} \right) \times
       \alphax{t-1}{{\tilde s}} \\
      \label{eq:forwardA3}
      & = \sum_{{\tilde s}\in\states} P_{\ti{S}{t}|\ti{S}{t-1}} \left( s|{\tilde s} \right)
      \cdot \alpha({\tilde s},t-1) .
    \end{align}
  \end{subequations}
  I justify the operations as follows:
  \begin{description}
  \item[\eqref{eq:forwardA1}] $P(a) = \sum_b P(a,b)$
  \item[\eqref{eq:forwardA2}] $P(a|b)\cdot P(b) = P(a,b)$
  \item[\eqref{eq:forwardA3}] Assumption of
    Eqn.~\eqref{eq:assume_markov}: The state process is Markov
  \end{description}
\item[\underline{Update} the Joint Probability of States and the Current
  Observation] Find for time $t$ and each possible state $s$, the
  conditional probability, given the previous observations, of the
  state being $s$ and the observation being $\ti{y}{t}$ (the observation
  actually observed):
  \begin{subequations}
    \label{eq:forwardB}
    \begin{align}
      \label{eq:forwardB1}
      \pregamma &= P_{\ti{Y}{t} |
        \ti{S}{t},\ts{Y}{1}{t-1}}\left(\ti{y}{t} |s, \ts{y}{1}{t-1}
      \right) \nonumber \\& \times \prealpha\\
      \label{eq:forwardB2}
      &= P_{\ti{Y}{t} | \ti{S}{t}}\left(\ti{y}{t} |s \right) \cdot
      \prealpha .
    \end{align}
  \end{subequations}
I justify the equations as follows:
\begin{description}
\item[\eqref{eq:forwardB1}]  $P(a|b)\cdot P(b) = P(a,b)$
\item[\eqref{eq:forwardB2}] Assumption of
  Eqn.~\eqref{eq:assume_output}: The observations are conditionally
  independent given the states
\end{description}
\item[\underline{Sum} to Get the Conditional Probability of the Current Observation]
  Find for time $t$ the conditional probability, given the previous
  observations, of the observation being $\ti{y}{t}$ (the observation actually
  observed):
  \begin{align}
    \label{eq:forwardC}
    \gammax &= \sum_{s \in \states} \pregamma .
  \end{align}
Equation~\eqref{eq:forwardC} is an application of $P(a) = \sum_b P(a,b)$.
\item[\underline{Normalize} the Updated Distribution of States] For each possible
  state $s$, find the conditional probability of being in that state
  at time $t$ given all of the observations up to time $t$.  Note that
  this differs from the first calculation in that the
  conditioning event includes $\ti{y}{t}$:%
  \begin{subequations}
    \label{eq:forwardD}
    \begin{align}
      \label{eq:forwardD1}
      \alpha(s,t) &\equiv
      \alphax{t}{s} \\
      \label{eq:forwardD2}
      &= \pregamma \div \gammax
    \end{align}
  \end{subequations}
  Equation \eqref{eq:forwardD2} is an application of Bayes rule, \ie,
  $P(a|b)\cdot P(b) = P(a,b)$.
\end{description}

\subsection{The Viterbi Algorithm}
\label{sec:viterbi}

For some applications, one must estimate the sequence of states based
on a sequence of observations.  The Viterbi algorithm %
\index{Viterbi algorithm|textbf}%
finds the \emph{best} sequence $\ts{\hat s}{1}{T}$ in the sense of
maximizing the probability $P\left( \ts{s}{1}{T}|\ts{y}{1}{T}
\right)$.  That is equivalent to maximizing $\log \left( P\left(
    \ts{y}{1}{T},\ts{s}{1}{T} \right) \right)$ because $P \left(
  \ts{y}{1}{T} \right)$ is simply a constant, and the $\log$ is
monotonic, ie,
\begin{align*}
  \ts{\hat s}{1}{T} &\equiv \argmax_{\ts{s}{1}{T}}
  P(\ts{s}{1}{T}|\ts{y}{1}{T})\\
  &= \argmax_{\ts{s}{1}{T}} \left( P(\ts{s}{1}{T}|\ts{y}{1}{T}) \cdot
    P(\ts{y}{1}{T}) \right)\\
  &= \argmax_{\ts{s}{1}{T}} \log \left( P(\ts{y}{1}{T},\ts{s}{1}{T})
  \right).
\end{align*}
As in the implementation of the forward algorithm, I use logs to
avoid numerical underflow.  If I define $\log \left( P\left(
    \ts{y}{1}{t}, \ts{s}{1}{t} \right) \right)$ as the
\emph{utility} (negative cost) of the state sequence $\ts{s}{1}{t}$
given the observation sequence $\ts{y}{1}{t}$, then the Viterbi
algorithm finds the maximum utility state sequence.

Initially one calculates $\log\left(P_{\ti{Y}{1},\ti{S}{1}}
  \left(\ti{y}{1}, s \right) \right)$ for each state $s \in
\states$.  Then for each successive time step $t: 1 < t \leq T$ one
considers each state and determines the best predecessor for that
state and the utility of the best state sequence ending in that state.
The Viterbi algorithm and the forward algorithm have similar
structures (see Fig.~\ref{fig:forward} and Fig.~\ref{fig:viterbiB}).
Roughly, the forward algorithm does a sum over predecessor states,
while the Viterbi algorithm finds a maximum. I use the following
notation and equations to describe and justify the algorithm.

\subsubsection*{Notation:}
\begin{description}
\item[$\bm{{\hat s}_1^t(s)}$ The best sequence ending in $\bm{s}$]
  Of all length $t$ state sequences ending in $s$, I define
  $\ts{\hat s}{1}{t}(s)$ to be the sequence with the highest joint
  probability with the data, \ie,
  \begin{equation*}
    \ts{\hat s}{1}{t}(s) = \argmax_{ \ts{s}{1}{t}:\ti{s}{t}=s}
    P\left(\ts{y}{1}{t}, \ts{s}{1}{t} \right).
  \end{equation*}
\item[$\bm{\nu(t,s)}$ The \emph{utility} of the best sequence ending
  in $\bm{s}$] %
  This is simply the log of the joint
  probability of the data with the best state sequence defined above,
  \ie
  \begin{equation*}
    \nu(t,s) = \log\left( P\left(\ts{y}{1}{t}, \ts{\hat s}{1}{t}(s)
      \right) \right)
  \end{equation*}
\item[$\bm{s'(s,t)}$ The best predecessor of state $\bm{s}$] This is
  the state at time $t-1$ in the best sequence that ends at state $s$
  at time $t$, \ie
  \begin{equation*}
    s'(s,t) = \argmax_{\tilde s} \left( \nu(t-1,\tilde s) + \log(
      P(s|\tilde s)) \right).
  \end{equation*}
\end{description}
\subsubsection*{Equations:}
Equations~\eqref{eq:cat} and \eqref{eq:nuprop} summarize the Viterbi
algorithm.  When finally deciphered, one finds Eqn.~\eqref{eq:cat} is
the obvious statement that the best state sequence ending in $s$ at
time $t+1$ consists of $s$ concatenated with the best sequence ending
in $s'$ at time $t$, where $s'$ is the best predecessor of $s$.
\begin{equation}
  \label{eq:cat}
  \ts{\hat s}{1}{t+1} (s) = \left( \left[\ts{\hat s}{1}{t}
      (s'(s,t+1))\right],s \right)
\end{equation}
Equation~\eqref{eq:nuprop} says that the total utility of the best
path to state $s$ at time $t+1$ is the utility of the best
predecessor plus two terms, one that accounts for the transition from
the predecessor to $s$ and one that accounts for the probability of
state $s$ producing the observation $\ti{y}{t+1}$.  The equation
follows from taking logs of
\begin{multline*}
  P_{\ti{Y}{t+1},\ts{Y}{1}{t},\ti{S}{t+1},\ts{S}{1}{t}}
  \left(\ti{y}{t+1},\ts{y}{1}{t},s,\ts{s}{1}{t} \right) =\\
  P\left(\ts{y}{1}{t}, \ts{s}{1}{t} \right) \cdot
  P_{\ti{S}{t+1}|\ti{S}{t}} \left(s|\ti{s}{t} \right) \cdot
  P_{\ti{Y}{t+1}|\ti{S}{t+1}} \left(\ti{y}{t+1}|s \right)
\end{multline*}
which in turn follows from the model assumptions
(Eqn.~\eqref{eq:assume_markov} and Eqn.~\eqref{eq:assume_output}).
\begin{equation}
  \label{eq:nuprop}
  \begin{split}
    \nu (t+1,s) = \nu(t,s'(s,t+1)) +
    \log\left(P_{\ti{S}{t+1}|\ti{S}{t}} \left(s|s'(s,t+1) \right)\right)\\
    \quad + \log \left( P_{\ti{Y}{t+1}|\ti{S}{t+1}}
      \left(\ti{y}{t+1}|s\right)\right)
  \end{split}
\end{equation}

\subsubsection*{Algorithm:}
Following the steps in Fig.~\ref{fig:viterbi}, note that the algorithm
starts by assigning a utility for each state using the first
observation and then iterates forward through time.  For each time
step $t$ and each possible next state $s_\text{next}$ at time $t+1$,
the algorithm finds and records the best predecessor state $s_\text{best}$
at time $t$.  Then the algorithm calculates the utility of
$s_\text{next}$ at time $t+1$ on the basis of the utility of the best
predecessor, the conditional transition probability, and the
conditional observation probability.  At the final time $T$ the
algorithm selects the highest utility endpoint, \ie,
\begin{equation*}
  \hat {\ti{s}{T}} = \argmax_s \nu(T,s),
\end{equation*}
and then backtracks through the optimal predecessor links to produce
the entire highest utility path.
%%%
%%% fig:viterbi
%%%
%%% FixMe: \addcontentsline{loa}{section}{Pseudocode for the Viterbi Algorithm}
%%% FixMe: Is this a "figure" or an "algorithm"?
\begin{figure}[htbp]
  \begin{center}
    \def\tnext{_{\text{next}}}%
    \def\told{_{\text{old}}}%
    \def\tbest{_{\text{best}}}%
    \fbox{
      \begin{minipage}{0.90\textwidth}
        \begin{tabbing}
          XX\=XX\=XX\=XX\=XX\=XX\=XX\=XX\= \kill
          Initialize: \> \+ \\
          for each $s$\\ \> \+
          $\nu\tnext (s) = \log \left( P_{\ti{Y}{1},\ti{S}{1}}
            \left(\ti{y}{1},s \right)\right)$ \\ \\ \< \- \< \-
          Iterate: \> \+ \\
          for $t$ from 1 to $T$\\ \> \+
          Swap $\nu\tnext \leftrightarrow \nu\told$\\
          for each $s\tnext$\\ \> \+
          \\ \# Find best predecessor\\
          $s\tbest = \argmax_{s\told}\left( \nu\told(s\told) + \log\left(
              P_{\ti{S}{t}|\ti{S}{t-1}} \left(s\tnext|s\told \right) \right)\right)$ \\
          \\ \# Update $\nu$\\
          $\nu\tnext(s\tnext) =\,$ \= $\nu\told(s\tbest)$ \\ \> \+
          $+ \log\left( P_{\ti{S}{t}|\ti{S}{t-1}} \left(s\tnext|s\tbest
            \right) \right)$ \\
          $ + \log\left( P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s\tnext \right)
          \right)  $ \\ \> \-
          \\ \# Update predecessor array\\
          Predecessor[$s\tnext,t$] = $s\tbest$\\ \\
          \< \- \< \- \< \- %This stuff is for tabs \< \-
          Backtrack: \> \+ \\
          $s_1^T = \hat s_1^T(\bar s)$ , where $\bar s =
          \argmax_s \nu\tnext(s)$ at $t=T$
        \end{tabbing}
      \end{minipage}
    }
    \caption[Pseudocode for the Viterbi Algorithm.]%
    {Pseudocode for the Viterbi Algorithm}
    \label{fig:viterbi}
  \end{center}
\end{figure}
%%%
%%% fig:viterbiB
%%%
\begin{sidewaysfigure}[htbp]
  %% 0.75\textheight is approx 5.7 in.  The .eps is exactly that size.
  %% The widths for the minipages below are taken by measuring the
  %% ovals inside of XFig.
  \centering{\plotsize%
    %% Column a
    \def\colaa{$\nu(s_1,t-1)$}%
    \def\colab{$\nu(s_2,t-1)$}%
    \def\colac{$\nu(s_3,t-1)$}%
    %% Column b
    \def\colba{$ \begin{matrix} s'(s_1,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_1|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\colbb{$ \begin{matrix} s'(s_2,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_2|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\colbc{$ \begin{matrix} s'(s_3,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_3|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\bestpred{%
      \begin{minipage}[t]{3.9in}
        \raggedright%
        For each state $s$ find the best\\%
        predecessor $s'(s,t)$, \ie, the\\%
        one that maximizes\\%
        $\log\left(P(s|s'(s,t)) \right) + \nu(s'(s,t),t-1)$.\\%
        The bolder lines indicate best\\%
        predecessors.
      \end{minipage}}%
    %% Column c
    \def\colca{$\nu(s_1,t)$}%
    \def\colcb{$\nu(s_2,t)$}%
    \def\colcc{$\nu(s_3,t)$}%
    \def\newnu{%
      \begin{minipage}[t]{2.7in}
        \raggedright%
        For each state $s$\\%
        calculate $\nu(s,t)$\\%
        by including the\\%
        conditional probability\\%
        of the observation $\ti{y}{t}$,\\%
        \ie, $ \nu(s,t) = \log\left(P(\ti{y}{t}|s) \right) $\\
        \qquad$+ \log\left(P(s|s'(s,t)) \right)$\\
        \qquad$+ \nu(s'(s,t),t-1)$.
      \end{minipage}}
    %%
    \InputBasicAlgorithmsFig{viterbiB}
  }
  \vspace{7em}
  \caption[Dependency relations in the Viterbi algorithm.]%
  {Dependency relations in the Viterbi algorithm.}
  \label{fig:viterbiB}
\end{sidewaysfigure}

\subsection{The Backward Algorithm}
\label{sec:backward}

The \index{backward algorithm} backward algorithm is similar to the
forward algorithm in structure and complexity, but the terms are not
as easy to interpret.  The principal goal of the algorithm is to
calculate terms that can be combined with results from the forward
algorithm to calculate
$P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)$, the
conditional probability of being in any state $s \in \states$ at any
time $t: 1\leq t \leq T$ given the entire sequence of observations.
The forward algorithm provides the terms
$\alpha(s,t) \equiv P_{\ti{S}{t}|\ts{Y}{1}{t}} \left(s|\ts{y}{1}{t}
\right)\, \forall (s,t)$.  Thus the backward algorithm must provide
terms, call them $\beta(s,t)$, with the values
\begin{equation}
  \label{eq:bw1} \beta(s,t) =
  \frac{P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)}
  {\alpha(s,t)} = \frac{P_{\ti{S}{t}|\ts{Y}{1}{T}}
    \left(s|\ts{y}{1}{T} \right)}
  {P_{\ti{S}{t}|\ts{Y}{1}{t}} \left(s|\ts{y}{1}{t} \right)}.
\end{equation}
\nomenclature[gb]{$\beta(s,t)$}{An intermediate quantity calculated in the
  backwards algorithm which is used somewhat like $\alpha$ in the
  forward algorithm.  One may use either of the following two
  equations to define $\beta$
  \begin{align*}
    \beta(s,t) &= \frac{P_{\ts{Y}{t+1}{T}"|\ti{S}{t}}
      \left(\ts{y}{t+1}{T}"|s
      \right)} {P \left(\ts{y}{t+1}{T}"|\ts{y}{1}{t} \right)}\\
    &= \frac{P_{\ti{S}{t}"|\ts{Y}{1}{T}} \left(s"|\ts{y}{1}{T} \right)}
    {\alpha(s,t)} = \frac{P_{\ti{S}{t}"|\ts{Y}{1}{T}}
      \left(s"|\ts{y}{1}{T} \right)} {P_{\ti{S}{t}"|\ts{Y}{1}{t}}
      \left(s"|\ts{y}{1}{t} \right)}.
  \end{align*}
  The interpretation of $\beta$ is less intuitive than the
  interpretation of $\alpha$.  It is also called the backward forecast
  distribution in the Kalman filter literature.}% end nomenclature
Invoking Bayes rule and the model assumptions I find
\begin{align}
  \label{eq:bw2} \beta(s,t) &= \frac{P_{\ts{Y}{1}{T},\ti{S}{t}}
    \left(\ts{y}{1}{T},s \right)\cdot P \left(\ts{y}{1}{t} \right)}
  {P_{\ts{Y}{1}{t},\ti{S}{t}}
    \left(\ts{y}{1}{t},s \right)\cdot P \left(\ts{y}{1}{T} \right)}\\
  \label{eq:bw3} &= \frac{P_{\ts{Y}{t+1}{T}|\ts{Y}{1}{t},\ti{S}{t}}
    \left(\ts{y}{t+1}{T}|\ts{y}{1}{t},s \right)} {P
    \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)}\\
  \label{eq:bw4}
  & = \frac{P_{\ts{Y}{t+1}{T}|\ti{S}{t}} \left(\ts{y}{t+1}{T}|s
    \right)} {P \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)}.
\end{align}
(Note that if $\alpha(s,t)=0$, Eqn.~\eqref{eq:bw1} is undefined, but
I can nonetheless implement Eqn.~\eqref{eq:bw4}.)

The algorithm starts at the final time $T$ with $\beta$ set to
one\footnote{From the premises that $\alpha(s,t) \beta(s,t) =
  P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s|\ts{y}{1}{T} \right)$ and
  $\alpha(s,T) \equiv P_{S(T)|\ts{Y}{1}{T}}\left(s |\ts{y}{1}{T}
  \right)$, I conclude that $\beta(s,T) = 1 ~\forall s$.} %
for each state, $\beta(s,T) = 1,~\forall s \in \states$, and solves
for $\beta$ at earlier times with the following recursion that goes
\emph{backwards} through time:
\begin{equation}
  \label{eq:backformula}
  \beta({\tilde s},t-1) = \sum_{s\in\states} \beta(s,t)
  \frac{ P_{\ti{Y}{t}|\ti{S}{t}}
    \left(\ti{y}{t}|s \right) \cdot P_{\ti{S}{t}|\ti{S}{t-1}}
    \left(s|{\tilde s} \right)} {\ti{\gamma}{t}}
\end{equation}
Note that ${\ti{\gamma}{t} \equiv P \left( \ti{y}{t} |
    \ts{y}{1}{t-1}\right)}$ is calculated by the forward algorithm and
that the terms in the numerator are model parameters.  I justify
Eqn.~\eqref{eq:backformula} by using Eqn.~\eqref{eq:bw4}
\begin{align}
  \beta({\tilde s},t-1) & \equiv \frac{P_{\ts{Y}{t}{T}|\ti{S}{t-1}}
    \left(\ts{y}{t}{T}|{\tilde s} \right)}
  {P \left(\ts{y}{t}{T}|\ts{y}{1}{t-1} \right)} \\
  \label{eq:back2}
  &= \frac{\sum_{s\in\states} P_{\ts{Y}{t}{T},\ti{S}{t}|\ti{S}{t-1}}
    \left(\ts{y}{t}{T},s|{\tilde s} \right)} {P
    \left(\ts{y}{t}{T}|\ts{y}{1}{t-1} \right)}.
\end{align}
Next, factor each term in the numerator of Eqn.~\eqref{eq:back2} using
Bayes rule twice then apply the model assumptions and the expression
for $\beta(s,t)$ from Eqn.~\eqref{eq:bw4}:
\begin{align*}
  & P_{\ts{Y}{t}{T},\ti{S}{t}|\ti{S}{t-1}}\left( \ts{y}{t}{T},s|{\tilde s} \right)\\
  \begin{split}
    &\quad= P_{\ts{Y}{t+1}{T}|\ti{Y}{t},\ti{S}{t},\ti{S}{t-1}}
       \left(\ts{y}{t+1}{T}|\ti{y}{t},s,{\tilde s} \right)\\
    &\quad\qquad \cdot P_{\ti{Y}{t}|\ti{S}{t},\ti{S}{t-1}} \left(\ti{y}{t}|s,{\tilde s}
       \right)\cdot P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)
  \end{split}\\
  &\quad= P_{\ts{Y}{t+1}{T}|\ti{S}{t}} \left(\ts{y}{t+1}{T}|s\right)
           \cdot P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
            P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right) \\
  &\quad= \beta(s,t) \cdot P \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)
           \cdot P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
            P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)
\end{align*}
Similarly, simplify the denominator of Eqn.~\eqref{eq:back2} using
Bayes rule:
\begin{equation*}
  P \left(\ts{y}{t}{T}|\ts{y}{1}{t-1} \right) = P
  \left(\ts{y}{t+1}{T}|\ts{y}{1}{t}  \right) \cdot {P \left(
  \ti{y}{t}|\ts{y}{1}{t-1}\right)}
\end{equation*}
Finally by substituting these values into the fraction of
\eqref{eq:back2}, I verify the recursion \eqref{eq:backformula}
\begin{align}
  \label{eq:back3} \beta({\tilde s},t-1) &= \frac{\sum_{s\in\states}
    \beta(s,t) \cdot P \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right)
    \cdot P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
    P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)} {P
    \left(\ts{y}{t+1}{T}|\ts{y}{1}{t} \right) \cdot {P \left(
        \ti{y}{t}|\ts{y}{1}{t-1}\right)}} \\
  \label{eq:back4} &= \sum_{s\in\states} \beta(s,t) \frac{
    P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s \right) \cdot
    P_{\ti{S}{t}|\ti{S}{t-1}} \left(s|{\tilde s} \right)} {\ti{\gamma}{t}}.
\end{align}

\section{Apnea}
\label{sec:Apnea}

In my book \emph{Hidden Markov Models and Dynamical Systems} the only
conceivably useful application was the analysis of EKG data in Chapter
6, \emph{Obstructive Sleep Apnea}.  I wrote code to estimate sequences
of classifications or bundles for that application.  As I said in the
introduction to this document, the ideas behind that code are flawed,
and I am writing this document as part of my effort to address those
errors.  Rather than immediately discussing the flawed ideas, in this
section I will pull some of the text about the application from the
book to give a concrete example.

The challenge for the \emph{Computers in Cardiology} %
\index{Computers in Cardiology 2000 (CINC2000)}%
meeting in 2000 (CINC2000) %
\index{CINC2000 (Computers in Cardiology 2000)}%
was to identify \emph{obstructive sleep apnea} on the basis of
electrocardiograms alone.  With my colleague James \index*{McNames} at
Portland State University, I won the prize for the best minute by
minute analysis of data.  I prepared our first entry using HMMs, and
James prepared the subsequent (and winning) entries by hand using
spectrograms\footnote{This chapter is available as tech report
  \#LA-UR-07-1969 from Los Alamos National Laboratory.}\footnote{A
  spectrogram is display of power in Fourier spectral bands as a
  function of time.  The x-axis is time, the y-axis is frequency, and
  the image intensity at point $(t,f)$ is the power in that frequency
  estimated in a window centered at that time.} to visualize the data.
\index{spectrogram} In preparing the first entry, I discovered that
using a sequence of states from the Viterbi algorithm to deduce a
sequence of classifications produced obvious errors.  After some
thought, I realized that a variant of the Viterbi algorithm that
directly decoded sequences of \emph{classifications} rather than
sequences of \emph{states} would yield better classification results.
Although I did not implement such an algorithm in 2000, I have in
preparing this book.

While the more appropriate algorithm does not perform as well as
James' eye, it does perform well enough to place among the top scores
that appear on the \index*{PhysioNet}
website.  Here, I will describe the algorithm for decoding
sequences of classification and narrate in a less formal style of
presentation my attempt at using it to \emph{re-win} the contest.

\subsection{The  Challenge and the Data}
\label{sec:challenge}

The PhysioNet website announced the challenge and described the data
as follows:

{\it % italic to signify quote
  {\rm \textbf{Introduction:}}
  %
  Obstructive sleep apnea (intermittent cessation of breathing) is a
  common problem with major health implications, ranging from
  excessive daytime drowsiness to serious cardiac arrhythmias.
  Obstructive sleep apnea is associated with increased risks of high
  blood pressure, myocardial infarction, and stroke, and with
  increased mortality rates. Standard methods for detecting and
  quantifying sleep apnea are based on respiration monitoring, which
  often disturbs or interferes with sleep and is generally expensive.
  A number of studies during the past 15 years have hinted at the
  possibility of detecting sleep apnea using features of the
  electrocardiogram. Such approaches are minimally intrusive,
  inexpensive, and may be particularly well-suited for screening. The
  major obstacle to use of such methods is that careful quantitative
  comparisons of their accuracy against that of conventional
  techniques for apnea detection have not been published.

  We therefore offer a challenge to the biomedical research community:
  demonstrate the efficacy of ECG-based methods for apnea detection
  using a large, well-characterized, and representative set of data.
  The goal of the contest is to stimulate effort and advance the state
  of the art in this clinically significant problem, and to foster
  both friendly competition and wide-ranging collaborations. We will
  award prizes of US\$500 to the most successful entrant in each of two
  events.

  {\rm \textbf{Data for development and evaluation:}}
  %
  Data for this contest have kindly been provided by Dr. Thomas
  Penzel \index{Penzel, Dr.\ Thomas}  of Philipps-University, Marburg,
  Germany [available on the website].

  The data to be used in the contest are divided into a learning set
  and a test set of equal size. Each set consists of 35 recordings,
  containing a single ECG signal digitized at 100 Hz with 12-bit
  resolution, continuously for approximately 8 hours (individual
  recordings vary in length from slightly less than 7 hours to nearly
  10 hours). Each recording includes a set of reference annotations,
  one for each minute of the recording, that indicate the presence or
  absence of apnea during that minute. These reference annotations
  were made by human experts on the basis of simultaneously recorded
  respiration signals. Note that the reference annotations for the
  test set will not be made available until the conclusion of the
  contest. Eight of the recordings in the learning set include three
  respiration signals (oronasal airflow measured using nasal
  thermistors, and chest and abdominal respiratory effort measured
  using inductive plethysmography) each digitized at 20 Hz, and an
  oxygen saturation signal digitized at 1 Hz. These additional signals
  can be used as reference material to understand how the apnea
  annotations were made, and to study the relationships between the
  respiration and ECG signals. [...]

  {\rm \textbf{Data classes:}}
  %
  For the purposes of this challenge, based on these varied criteria,
  we have defined three classes of recordings:
  \begin{description}
  \item[Class A (Apnea):] These meet all criteria. Recordings in class
    A contain at least one hour with an apnea index of 10 or more, and
    at least 100 minutes with apnea during the recording. The learning
    and test sets each contain 20 class A recordings.
  \item[Class B (Borderline):] These meet some but not all of the
    criteria. Recordings in class B contain at least one hour with an
    apnea index of 5 or more, and between 5 and 99 minutes with apnea
    during the recording. The learning and test sets each contain 5
    class B recordings.
  \item[Class C (Control):] These meet none of the criteria, and may
    be considered normal. Recordings in class C contain fewer than 5
    minutes with apnea during the recording. The learning and test
    sets each contain 10 class C recordings.
  \end{description}

  {\rm \textbf{Events and scoring:}}
  %
  Each entrant may compete in one or both of the following events:
  \begin{description}
  \item[1. Apnea screening:] In this event, your task is to design
    software that can classify the 35 test set recordings into class A
    (apnea) and class C (control or normal) groups, using the ECG
    signal to determine if significant sleep apnea is present.  [...]
  \item[2. Quantitative assessment of apnea:] In this event, your
    software must generate a minute-by-minute annotation file for each
    recording, in the same format as those provided with the learning
    set, using the ECG signal to determine when sleep apnea occurs.
    Your annotations will be compared with a set of reference
    annotations to determine your score. Each annotation that matches
    a reference annotation earns one point; thus the highest possible
    score for this event will be approximately 16800 (480 annotations
    in each of 35 records). It is important to understand that scores
    approaching the maximum are very unlikely, since apnea assessment
    can be very difficult even for human experts. Nevertheless, the
    scores can be expected to provide a reasonable ranking of the
    ability of the respective algorithms to mimic the decisions made
    by human experts.
  \end{description}
}%% end \it for quote

\subsection{The Data}
\label{sec:data}
%%% FixMe: In runs using CM fonts, I see too much space under
%%% FixMe: fig:a03erA.  It and fig:a03erN get put on facing pages.
%%% FixMe: The following text breaks right after "45 seconds and",
%%% FixMe: and there is several inches of empty vertical whitespace
%%% FixMe:  between the figure and the text.

Briefly, one can fetch the following records from PhysioNet:
\begin{description}
\item[a01-a20:] The \emph{a records} from individuals that display
  \emph{apnea}
\item[b01-b05:] The \emph{b records}\footnote{The amplitude of the
    \emph{b05} record varies dramatically over different segments of
    time.  I found it unusable and discarded it entirely.} from
  individuals diagnosed as \emph{borderline}
\item[c01-c10:] The \emph{c records} from \emph{control} or normal
  individuals
\item[a01er-a04er and b01er and c01er:] Identical to \emph{a01-a04}
  and \emph{b01} and \emph{c01} except augmented with respiration and
  $SpO_2$ (percent of arterial hemoglobin saturated with oxygen)
  \nomenclature[rSpO]{$SpO_2$}{Percent of arterial hemoglobin
    saturated with oxygen.} signals
\item[summary\_of\_training:] Expert classifications of each minute in
  the $a$, $b$, and $c$ records
\item[x01-x35:] The test set\footnote{The records \emph{x33} and
    \emph{x34} are so similar that I suspect they are simultaneous
    recordings from different ECG leads.  I did not explicitly exploit
  the similarity in my analysis.}; records without classification
\end{description}

In 2000, using both the data and software to view it from PhysioNet, I
saw striking oscillations in the apnea time series.  The patients stop
breathing for tens of seconds, gasp a few breaths, and stop again.
Each cycle takes about 45 seconds and can go on for most of the night.
I've plotted two periods of such an oscillation from record \emph{a03}
in Fig.~\ref{fig:a03erA}.  The reference or \emph{expert}
classifications provided with the data indicate these are the last
oscillations in the first apnea episode of the night.  Over the entire
night's record of 8 hours and 39 minutes, the patient had apnea for a
total of 4 hours and five minutes in 11 separate episodes.  In that
time, more than once a minute, he was waking up enough to start
breathing.  Ten and a half minutes after the end of the first apnea
episode, the record, as plotted in Fig.~\ref{fig:a03erN}, looks
normal.

\begin{figure}
  \centering{\plotsize%
    \def\SpO{$SpO_2$}%
    \def\ONR{\emph{ONR}}%
    \def\ECG{\emph{ECG}}%
    \IncludeApneaFig{a03erA}}
  \caption[\comment{fig:a03erA }A segment of record a03]%
  {A segment of record a03.  Two cycles of a large apnea
    induced oscillation in $SpO_2$ are drawn in the lower plot.  The
    middle plot is the oronasal airflow signal, and the upper plot is
    the ECG (units of both ONR and ECG are unknown).  The time
    axis is marked in \emph{hours:minutes}.  Notice the increased
    heart rate just after 0:58 and just before 0:59.}
  \label{fig:a03erA}
\end{figure}

\begin{figure}
  \centering{\plotsize%
    \def\SpO{$SpO_2$}%
    \def\ONR{\emph{ONR}}%
    \def\ECG{\emph{ECG}}%
    \IncludeApneaFig{a03erN}}
  \caption[\comment{fig:a03erN }A segment of record a03]%
  {A segment of record a03 taken during a period of normal
    respiration.  Signals the same as in Fig.~\ref{fig:a03erA}.}
  \label{fig:a03erN}
\end{figure}

In plots like Fig.~\ref{fig:a03erA}, the heart rate visibly increases
at the end of the gasping phase and then decreases during the phase of
interrupted respiration.  That heart rate oscillation is the key I
used in my initial attempts to classify periods of apnea.  In
Fig.~\ref{fig:a03erHR}, I've plotted both a heart rate derived from
the ECG \nomenclature[rECG]{ECG}{Electrocardiogram} and the $SpO_2$
signal.  The oscillations in the signals track each other, and the
expert classifies only the region of large heart rate oscillation as
apnea.
\begin{figure}
  \centering{\plotsize%
    \def\SpO{$SpO_2$}%
    \def\HR{\emph{HR}}%
    \IncludeApneaFig{a03HR}}
  \caption[\comment{fig:a03HR }A segment of record 03 at the end of an episode of apnea]%
  {A segment of record 03 at the end of an episode of apnea with
    indications in both the $SpO_2$ signal and the heart rate
    \emph{(HR)} signal.  The expert marked the time before 1:00 as
    apnea and the time afterwards as normal.}
  \label{fig:a03erHR}
\end{figure}

\section{First Classification Algorithms and Two Useful Features}
\label{sec:NVG}

\newcommand{\tmo}{i} % \tmo is t minus one
\newcommand{\tex}{j} % \tex is t exactly
\newcommand{\tpo}{k} % \tpo is t plus one

\subsection{Using Information from Experts to Train}

I first carefully considered the CINC2000 challenge when Andreas
Rechtsteiner told me that he was going to use it as a final project
for a class that James was teaching.  I suggested that he try a two
state HMM with autoregressive observation models with scalar observations.  The performance of Andreas' two state model was not
memorable.

To use the expert classification information in training, Andreas and
I found that we need only modify the observation model.  The technique
is not limited to HMMs with only two states or two classes; it applies
to an arbitrary number of classes and to arbitrary numbers of states
associated with each class.  At each time $t$, let $\ti{c}{t}$ denote
classification information from an expert about which states are
possible.  Specifically $\ti{c}{t}$ is a vector that indicates that
some states are possible and that the others are impossible.  We
simply replace $P_{\ti{Y}{t}|\ti{S}{t},\ts{Y}{1}{t-1}}$ with
$P_{\ti{Y}{t},\ti{C}{t}|\ti{S}{t},\ts{Y}{1}{t-1}}$ wherever it occurs
in the Baum Welch algorithm.  Roughly, the modification forces the
system into states associated with the right class during training.

\subsection{Nonlinear Dynamics}
\label{sec:NLD}

After Andreas finished his class, I looked more carefully at heart
rate time series and the classification errors of a two state model.
I saw evidence of \emph{nonlinear dynamics} such as the period two
waveform and the sawtooth in Fig.~\ref{fig:ApneaNLD}.  Superpositions
of sinusoids can describe such patterns with the right amplitudes and
relative phases of the harmonics.  Although a linear model can favor
the correct frequencies and amplitudes of the component sinusoids,
linear models cannot detect or enforce phase relationships.  The
ability to distinguish phase relationships makes it possible to build
nonlinear models that are more discriminating than any linear model.

\begin{figure}
  \centering{\plotsize%
    \def\aT{\emph{a12} HR}%
    \def\aZ{\emph{a01} HR}%
    \IncludeApneaFig{ApneaNLD}}
  \caption[\comment{fig:ApneaNLD }Nonlinear effects]%
  {Nonlinear effects: The upper plot seems to be a period two
    oscillation.  The lower plot is approximately sawtooth.}
  \label{fig:ApneaNLD}
\end{figure}

Excited by these observations, I built an HMM with many chains of
states.  Each chain modeled a different form of heart rate
oscillation.  I trained the model on the expertly classified records,
and then used the model to classify those same records.  For each
record, I used the Viterbi algorithm to find the most likely state
sequence given the observations.  Then I derived a classification
sequence from the decoded state sequence by selecting class $C$ at
time $t$ if the decoded state satisfied $\ti{s}{t}\in C$.  The
technique performed terribly.  The sequences of classifications said
every minute was \emph{normal} even though (actually \emph{because}) I had
modeled the different kinds of \emph{apnea} oscillations so carefully.

An analysis of the values of the conditional probabilities of states given
the entire sequence of observations, $P_{\ti{S}{t}|\ts{Y}{1}{T}}
\left(s_i|\ts{y}{1}{T} \right) = \alpha(s_i,t) \beta(s_i,t)$,
revealed the problem and suggested a solution.  Because the model had
many more apnea states than normal states, the state probability was
rarely concentrated enough in a single apnea state for that state to
be decoded.  To address the problem, I solved for the sequence of most
likely classifications, \ie,
\begin{equation}
  \label{eq:smlc}
  \ti{\tilde C}{t} \equiv \argmax_C \sum_{i:s_i\in C}
  P_{\ti{S}{t}|\ts{Y}{1}{T}} \left(s_i|\ts{y}{1}{T} \right).
\end{equation}
instead of solving for the most likely sequence of states.  Using
Eqn.~\eqref{eq:smlc} and the HMM with many chains of states, I
classified the test data to prepare a contest entry.  When James
submitted the entry % on April 24, 2000
we found that it classified 78.91\% of the minutes correctly.

In Section~2.3.3 of the book I presented a sequence of MAP states that
not only failed to be a MAP sequence of states but that was actually
an impossible sequence.  Since the analogous distinction holds for
sequences of classifications, I developed the algorithm described in
Section~\ref{sec:broken_decode} that finds
\begin{equation}
  \label{eq:mlsc}
  {\ts{\hat C}{1}{T}} \equiv \argmax_{\ts{C}{1}{T} }
  \sum_{\ts{s}{1}{T}:\ti{s}{t}\in \ti{C}{t}, 1 \leq t \leq T} P\left(
    \ts{s}{1}{T} | \ts{y}{1}{T} \right),
\end{equation}
\ie, the MAP sequence of classifications rather than the sequence of
MAP classifications.

\section{Bundles}
\label{sec:bundles}

\subsection{Broken Decode}
\label{sec:broken_decode}


\end{document}

Look at how you made ~/projects/hmmds3/figs/a03erHR.pdf
~/projects/hmmds3/code/plotscripts/SConscript

%%% Local Variables:
%%% eval: (load-file "hmmkeys.el")
%%% End:
