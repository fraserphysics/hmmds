% \documentclass[twocolumn]{article}
\RequirePackage{rotating}
\documentclass[]{article}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{xspace}
%\usepackage[pdftex]{graphicx,color} % For including pdfs

\usepackage{graphicx}
\usepackage[most]{tcolorbox}
\usepackage{figlatex}

% Commands from Hmmdsbook/hmmdsbook.cls
\usepackage{afterpage}
\usepackage[norefeq,refpage,nocfg,intoc,noprefix]{nomencl}
\newcommand{\parameters}{\theta}
\newcommand{\ts}[3]{#1_{#2}^{#3}}                    % Time Sequence
\newcommand{\argmin}{\operatorname*{argmin}}
\newcommand{\argmax}{\operatorname*{argmax}}
\newcommand{\ti}[2]{{#1}{(#2)}}                  % Time Index
\newcommand{\states}{{\cal S}}
\newcommand{\ie}{i.e.\xspace}
\newcommand{\eg}{e.g.\xspace}
\newcommand{\etal}{et al.\xspace}
\newcommand{\iid}{i.~i.~d.\xspace}
\newcommand{\plotsize}{%
  \fontsize{9}{9}%
  \selectfont}
\newenvironment{symbdescription}{%
  \list{}{%
    \labelwidth\nomlabelwidth
    \leftmargin\labelwidth
    \advance\leftmargin\labelsep
    \itemsep\nomitemsep
    \let\makelabel\nomlabel}}%
{\endlist}
\renewcommand{\comment}[1]{}

\title{Estimating Membership in Bundles of HMM States}

\author{Andrew Fraser}

\begin{document}

\maketitle

Let us begin by establishing our notation for the model parameters.
\setlength{\nomlabelwidth}{2.7cm}%
\begin{symbdescription}
\item[$\bm{P_{\ti{S}{t+1}|\ti{S}{t}}(s|{\tilde s})}$] The probability that
  at time $t+1$ the system will be in state $s$ given that at time
  $t$ it was in state ${\tilde s}$.  Notice that the parameter is independent
  of time $t$.  Ferguson called these parameters \emph{the $A$ matrix}
  with $a_{i,j} = P_{\ti{S}{t+1}|\ti{S}{t}}(s|{\tilde s})$.
\item[$\bm{P_{\ti{S}{1}}(s)}$] The probability that the system will
  start in state $s$ at time 1.  Ferguson used $a$ to represent this
  vector of probabilities with $a_i = P_{\ti{S}{1}} \left(s \right)$.
\item[$\bm{P_{\ti{Y}{t}|\ti{S}{t}}(y_k|{\tilde s})}$] The probability that
  the observation value is $y_k$ given that the system is in state ${\tilde s}$.
  Ferguson used $b$ to represent this with $b_j(k) =
  P_{\ti{Y}{t}|\ti{S}{t}} \left(y_k|{\tilde s} \right)$.
\item[$\bm{\parameters}$] The entire collection of parameters.  For
  example, iteration of the Baum Welch algorithm produces a sequence
  of parameter vectors $\ts{\parameters}{1}{N}$ with
  $P\left(\ts{y}{1}{T}|\ti{\parameters}{n+1}\right) \geq
  P\left(\ts{y}{1}{T}|\ti{\parameters}{n}\right)\, : 1 < n < N$.
  Instead of $\parameters$, Ferguson used $\lambda$ to denote the
  entire collection of parameters.
  \nomenclature[gh]{$\bm{\theta}$}{The entire collection of
    parameters that defines a model.}
\end{symbdescription}

\section{The Forward Algorithm}
\label{sec:forward}
\index{forward algorithm|textbf}

Given $\parameters$, the forward algorithm calculates
$P(\ts{y}{1}{T}|\parameters)$, and several useful intermediate terms.
Figure~\ref{fig:forward} sketches the basic recursion's structure.
Since we are considering only one set of parameters, we will drop the
dependence of probabilities on $\parameters$ from the notation for the
remainder of this section.  In the example of Eqn.~\eqref{eq:pcalc} we
found that we could calculate the right hand terms of
\begin{equation*}
   P\left( \ts{y}{1}{T} \right) = \sum_{\ts{s}{1}{T}}
   P\left( \ts{y}{1}{T},\ts{s}{1}{T} \right)
\end{equation*}
easily from the model assumptions.  Unfortunately, the number of
possible sequences $\ts{s}{1}{T}$ is exponential in $T$, and it is
impossible to do the sum for even modest lengths $T$.

\begin{sidewaysfigure}[htbp]
  %% 0.75\textheight is approx 5.7 in.  The .eps is exactly that size.
  %% The widths for the minipages below are taken by measuring the
  %% ovals inside of XFig.
  \centering{\plotsize%
    %% Column a
    \def\colaa{$\alpha(s_1,t-1)$}%
    \def\colab{$\alpha(s_2,t-1)$}%
    \def\colac{$\alpha(s_3,t-1)$}%
    %% Column b
    \def\colba{$P \left(s_1|\ts{y}{1}{t-1} \right)$}%
    \def\colbb{$P \left(s_2|\ts{y}{1}{t-1} \right)$}%
    \def\colbc{$P \left(s_3|\ts{y}{1}{t-1} \right)$}%
    \def\sumeqforwardAthree{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        Weighted\\%
        sum of prior\\%
        $\alpha$'s\\%
        Eqn.~\eqref{eq:forwardA3}
      \end{minipage}}%
    %% Column c
    \def\colca{$P \left(s_1,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\colcb{$P \left(s_2,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\colcc{$P \left(s_3,\ti{y}{t}|\ts{y}{1}{t-1} \right)$}%
    \def\prdeqforwardBtwo{%
      \begin{minipage}[t]{2.3in}
        \raggedright%
        Multiply\\%
        observation\\%
        probability\\%
        Eqn.~\eqref{eq:forwardB2}
      \end{minipage}}%
    %% Column d
    \def\coldb{$P(\ti{y}{t}|\ts{y}{1}{t-1})$}%
    \def\prdeqforwardC{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        Add, to get\\%
        $\gamma(t)$, $P \left(\ti{y}{t}|\ts{y}{1}{t-1} \right)$\\%
        Eqn.~\eqref{eq:forwardC}
      \end{minipage}}%
    %% Column e
    \def\colea{$\alpha(s_1,t)$}%
    \def\coleb{$\alpha(s_2,t)$}%
    \def\colec{$\alpha(s_3,t)$}%
    \def\quoteqforwardD{%
      \begin{minipage}[t]{1.8in}
        \raggedright%
        Normalize\\%
        new $\alpha$'s\\%
        Eqn.~\eqref{eq:forwardD}
      \end{minipage}}%
    \input{forward.pdf_t}
  }
  \vspace{5 em}
  \caption[\comment{fig:forward }Dependency relations in the forward algorithm.]%
  {Dependency relations in the forward algorithm (See
    Eqns.~\eqref{eq:forwardA}-\eqref{eq:forwardD} in the text).}
  \label{fig:forward}
\end{sidewaysfigure}
\afterpage{\clearpage}%% Print this right here please.


The forward algorithm regroups the terms and produces the desired
result using order $T$ calculations.  For each time $t:\, 1 < t \leq
T$ we calculate $P(\ti{y}{t}|\ts{y}{1}{t-1})$, and in principle we can
write
\begin{equation*}
  P(\ts{y}{1}{T}) = P(\ti{y}{1}) \prod_{t=2}^T P(\ti{y}{t}|\ts{y}{1}{t-1}).
\end{equation*}
However the values of $P(\ti{y}{t}|\ts{y}{1}{t-1})$ are typically
small compared to 1, and the product of many such terms is too small
to be represented even in double precision.  Working with logarithms
avoids underflow:

\begin{equation}
  \label{eq:logP}
  \log\left( P(\ts{y}{1}{T}) \right) = \log\left( P(\ti{y}{1})
 \right) + \sum_{t=2}^T \log\left( P(\ti{y}{t}|\ts{y}{1}{t-1})\right).
\end{equation}

% Perhaps use \usepackage[most]{tcolorbox} for these boxes
\definecolor{MyGreen}{rgb}{0,.5,0}%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% #1 = time #2 = state
\newcommand{\alphax}[2]{%
  \tcboxmath[colback=white,colframe=cyan]{%  Todo double box
    P_{S(#1)|\ts{Y}{1}{#1}}\left(#2 |\ts{y}{1}{#1} \right)%
  }%
}%
%%%
%%%
\newcommand{\prealpha}{%
  \tcboxmath[colback=white,colframe=MyGreen]{%
    P_{\ti{S}{t}|\ts{Y}{1}{t-1}} \left(s | \ts{y}{1}{t-1} \right)%
  }%
}%
%%%
\newcommand{\gammax}{%
  \tcboxmath[colback=white,colframe=blue]{%
    P(\ti{y}{t}|\ts{y}{1}{t-1})%
  }%
}%
%%%
%%%
\newcommand{\pregamma}{%
  \tcboxmath[colback=white,colframe=red]{%
    P_{\ti{S}{t},\ti{Y}{t}|\ts{Y}{1}{t-1}} \left(s,\ti{y}{t}|\ts{y}{1}{t-1}\right)%
  }%
}%
%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For each time step we do the four calculations specified in the
equations below\footnote{In Section~\ref{sec:Clarity} we present four
  lines of python code that implement these four calculations.}.  In
these equations we use boxes to emphasize repeated instances of the
same quantity.  The algorithm saves the intermediate results
%
\nomenclature[ga]{$\alpha(s,t)$}{The conditional probability that at time
  $t$ the system is in state $s$ given the observations up to the
  present,
  \begin{equation*}
    \alpha(s,t) \equiv  P_{S(t)"|\ts{Y}{1}{t}}\left(s "|\ts{y}{1}{t}
    \right).
  \end{equation*}
  Also called the forward updated distribution in the Kalman filter
  literature.}
%
\nomenclature[gc]{$\gamma(t)$}{The probability of the present observation
  given the history.}%, $P(y(t)|y_1^{t-1}$.}
\begin{align}
  \label{eq:alpha}
  \alpha(s,t) &\equiv \alphax{t}{s}\\
  \label{eq:gamma}
  \ti{\gamma}{t} &\equiv \gammax .
\end{align}
In words\footnote{In Ferguson's notation $\alpha(s,t) \equiv
  P_{\ti{S}{t},\ts{Y}{1}{t}} \left(s,\ts{y}{1}{t} \right)$.  Our
  notation differs from that by a factor of $P(\ts{y}{1}{t})$.
  Ferguson did not have notation for the term
  $P(\ti{y}{t}|\ts{y}{1}{t-1})$ which we call $\gamma$, but he did use
  $\gamma$ for quantities that we will denote by $w$ in
  Eqns.~\eqref{eq:wit} and \eqref{eq:wijt}.}, $\alpha(s,t)$ is the
conditional probability of being in state $s$ at time $t$ given all
of the observations up to time $t$ and $\ti{\gamma}{t}$ is the
conditional probability of the observation at time $t$ given all of
the previous observations.  To initialize the algorithm, one assigns
\begin{equation*}
\alpha(s,1) = P_{\ti{S}{1}|\ti{Y}{1}}(s|\ti{y}{1}) =
\frac{P_{\ti{S}{1}}(s)P_{\ti{Y}{t}|\ti{S}{t}}(\ti{y}{1}|s)}
{\sum_{{\tilde s}}P_{\ti{S}{1}}({\tilde s})P_{\ti{Y}{t}|\ti{S}{t}}(\ti{y}{1}|{\tilde s})}
~\forall s \in \states
\end{equation*}
where the distributions $P_{\ti{S}{1}}$ and $P_{\ti{Y}{t}|\ti{S}{t}}$
are model parameters.
\begin{description}
\item[Forecast the Distribution of States] Find for time $t$ and each
  possible state $s$, the conditional probability, given the
  previous observations, of the state being $s$ at time $t$:
  \begin{subequations}
    \label{eq:forwardA}
    \begin{align}
      \label{eq:forwardA1}
      \prealpha & = \sum_{{\tilde s}\in\states}
      P_{\ti{S}{t},\ti{S}{t-1}|\ts{Y}{1}{t-1}} \left( s, {\tilde s}
      |\ts{y}{1}{t-1} \right)\\
      \label{eq:forwardA2}
      & = \sum_{{\tilde s}\in\states} \left(
        P_{\ti{S}{t}|\ti{S}{t-1},\ts{Y}{1}{t-1}}
        \left( s|{\tilde s},\ts{y}{1}{t-1} \right) \right. \nonumber \\ &
      \left. \times \alphax{t-1}{{\tilde s}} \right) \\
      \label{eq:forwardA3}
      & = \sum_{{\tilde s}\in\states} P_{\ti{S}{t}|\ti{S}{t-1}} \left( s|{\tilde s} \right)
      \cdot \alpha({\tilde s},t-1) .
    \end{align}
  \end{subequations}
  We justify the operations as follows:
  \begin{description}
  \item[\eqref{eq:forwardA1}] $P(a) = \sum_b P(a,b)$
  \item[\eqref{eq:forwardA2}] $P(a|b)\cdot P(b) = P(a,b)$
  \item[\eqref{eq:forwardA3}] Assumption of
    Eqn.~\eqref{eq:assume_markov}: The state process is Markov
  \end{description}
\item[Update the Joint Probability of States and the Current
  Observation] Find for time $t$ and each possible state $s$, the
  conditional probability, given the previous observations, of the
  state being $s$ and the observation being $\ti{y}{t}$ (the observation
  actually observed):
  \begin{subequations}
    \label{eq:forwardB}
    \begin{align}
      \label{eq:forwardB1}
      \pregamma &= P_{\ti{Y}{t} |
        \ti{S}{t},\ts{Y}{1}{t-1}}\left(\ti{y}{t} |s, \ts{y}{1}{t-1}
      \right) \nonumber \\& \times \prealpha\\
      \label{eq:forwardB2}
      &= P_{\ti{Y}{t} | \ti{S}{t}}\left(\ti{y}{t} |s \right) \cdot
      \prealpha .
    \end{align}
  \end{subequations}
We justify the equations as follows:
\begin{description}
\item[\eqref{eq:forwardB1}]  $P(a|b)\cdot P(b) = P(a,b)$
\item[\eqref{eq:forwardB2}] Assumption of
  Eqn.~\eqref{eq:assume_output}: The observations are conditionally
  independent given the states
\end{description}
\item[Calculate the Conditional Probability of the Current Observation]
  Find for time $t$, the conditional probability, given the previous
  observations, of the observation being $\ti{y}{t}$ (the observation actually
  observed):
  \begin{align}
    \label{eq:forwardC}
    \gammax &= \sum_{s \in \states} \pregamma .
  \end{align}
Equation~\eqref{eq:forwardC} is an application of $P(a) = \sum_b P(a,b)$.
\item[Normalize the Updated Distribution of States] For each possible
  state $s$, find the conditional probability of being in that state
  at time $t$ given all of the observations up to time $t$.  Note that
  this differs from the first calculation in that the
  conditioning event includes $\ti{y}{t}$:%
  \begin{subequations}
    \label{eq:forwardD}
    \begin{align}
      \label{eq:forwardD1}
      \alpha(s,t) &\equiv
      \alphax{t}{s} \\
      \label{eq:forwardD2}
      &= \pregamma \div \gammax
    \end{align}
  \end{subequations}
  Equation \eqref{eq:forwardD2} is an application of Bayes rule, \ie,
  $P(a|b)\cdot P(b) = P(a,b)$.
\end{description}

\section{The Viterbi Algorithm}
\label{sec:viterbi}

For some applications, one must estimate the sequence of states based
on a sequence of observations.  The Viterbi algorithm %
\index{Viterbi algorithm|textbf}%
finds the \emph{best} sequence $\ts{\hat s}{1}{T}$ in the sense of
maximizing the probability $P\left( \ts{s}{1}{T}|\ts{y}{1}{T}
\right)$.  That is equivalent to maximizing $\log \left( P\left(
    \ts{y}{1}{T},\ts{s}{1}{T} \right) \right)$ because $P \left(
  \ts{y}{1}{T} \right)$ is simply a constant, and the $\log$ is
monotonic, ie,
\begin{align*}
  \ts{\hat s}{1}{T} &\equiv \argmax_{\ts{s}{1}{T}}
  P(\ts{s}{1}{T}|\ts{y}{1}{T})\\
  &= \argmax_{\ts{s}{1}{T}} \left( P(\ts{s}{1}{T}|\ts{y}{1}{T}) \cdot
    P(\ts{y}{1}{T}) \right)\\
  &= \argmax_{\ts{s}{1}{T}} \log \left( P(\ts{y}{1}{T}),\ts{s}{1}{T}
  \right).
\end{align*}
As in the implementation of the forward algorithm, we use logs to
avoid numerical underflow.  If we define $\log \left( P\left(
    \ts{y}{1}{t}, \ts{s}{1}{t} \right) \right)$ as the
\emph{utility} (negative cost) of the state sequence $\ts{s}{1}{t}$
given the observation sequence $\ts{y}{1}{t}$, then the Viterbi
algorithm finds the maximum utility state sequence.

Initially one calculates $\log\left(P_{\ti{Y}{1},\ti{S}{1}}
  \left(\ti{y}{1}, s \right) \right)$ for each state $s \in
\states$.  Then for each successive time step $t: 1 < t \leq T$ one
considers each state and determines the best predecessor for that
state and the utility of the best state sequence ending in that state.
The Viterbi algorithm and the forward algorithm have similar
structures (see Fig.~\ref{fig:forward} and Fig.~\ref{fig:viterbiB}).
Roughly, the forward algorithm does a sum over predecessor states,
while the Viterbi algorithm finds a maximum. We use the following
notation and equations to describe and justify the algorithm.

\subsubsection*{Notation:}
\begin{description}
\item[$\bm{{\hat s}_1^t(s)}$ The best sequence ending in $\bm{s}$]
  Of all length $t$ state sequences ending in $s$, we define
  $\ts{\hat s}{1}{t}(s)$ to be the sequence with the highest joint
  probability with the data, \ie,
  \begin{equation*}
    \ts{\hat s}{1}{t}(s) = \argmax_{ \ts{s}{1}{t}:\ti{s}{t}=s}
    P\left(\ts{y}{1}{t}, \ts{s}{1}{t} \right).
  \end{equation*}
\item[$\bm{\nu(t,s)}$ The \emph{utility} of the best sequence ending
  in $\bm{s}$] %
  This is simply the log of the joint
  probability of the data with the best state sequence defined above,
  \ie
  \begin{equation*}
    \nu(t,s) = \log\left( P\left(\ts{y}{1}{t}, \ts{\hat s}{1}{t}(s)
      \right) \right)
  \end{equation*}
\end{description}
\subsubsection*{Equations:}
Equations~\eqref{eq:cat} and \eqref{eq:nuprop} summarize the Viterbi
algorithm.  When finally deciphered, one finds Eqn.~\eqref{eq:cat} is
the vacuous statement that the best state sequence ending in $s$ at
time $t+1$ consists of $s$ concatenated with the best sequence ending
in $s'$ at time $t$, where $s'$ is the best predecessor of $s$.
\begin{equation}
  \label{eq:cat}
  \ts{\hat s}{1}{t+1} (s) = \left( \left[\ts{\hat s}{1}{t}
      (s'(s,t+1))\right],s \right)
\end{equation}
Equation~\eqref{eq:nuprop} says that the total utility of the best
path to state $s$ at time $t+1$ is the utility of the best
predecessor plus two terms, one that accounts for the transition from
the predecessor to $s$ and one that accounts for the probability of
state $s$ producing the observation $\ti{y}{t+1}$.  The equation
follows from taking logs of
\begin{multline*}
  P_{\ti{Y}{t+1},\ts{Y}{1}{t},\ti{S}{t+1},\ts{S}{1}{t}}
  \left(\ti{y}{t+1},\ts{y}{1}{t},s,\ts{s}{1}{t} \right) =\\
  P\left(\ts{y}{1}{t}, \ts{s}{1}{t} \right) \cdot
  P_{\ti{S}{t+1}|\ti{S}{t}} \left(s|\ti{s}{t} \right) \cdot
  P_{\ti{Y}{t+1}|\ti{S}{t+1}} \left(\ti{y}{t+1}|s \right)
\end{multline*}
which in turn follows from the model assumptions
(Eqn.~\eqref{eq:assume_markov} and Eqn.~\eqref{eq:assume_output}).
\begin{equation}
  \label{eq:nuprop}
  \begin{split}
    \nu (t+1,s) = \nu(t,s'(s,t+1)) +
    \log\left(P_{\ti{S}{t+1}|\ti{S}{t}} \left(s|s'(s,t+1) \right)\right)\\
    \quad + \log \left( P_{\ti{Y}{t+1}|\ti{S}{t+1}}
      \left(\ti{y}{t+1}|s\right)\right)
  \end{split}
\end{equation}

\subsubsection*{Algorithm:}
Following the steps in Fig.~\ref{fig:viterbi}, note that the algorithm
starts by assigning a utility for each state using the first
observation and then iterates forward through time.  For each time
step $t$ and each possible next state $s_\text{next}$ at time $t+1$,
the algorithm finds and records the best predecessor state $s_\text{best}$
at time $t$.  Then the algorithm calculates the utility of
$s_\text{next}$ at time $t+1$ on the basis of the utility of the best
predecessor, the conditional transition probability, and the
conditional observation probability.  At the final time $T$ the
algorithm selects the highest utility endpoint, \ie,
\begin{equation*}
  \hat {\ti{s}{T}} = \argmax_s \nu(T,s),
\end{equation*}
and then backtracks through the optimal predecessor links to produce
the entire highest utility path.
%%%
%%% fig:viterbi
%%%
%%% FixMe: \addcontentsline{loa}{section}{Pseudocode for the Viterbi Algorithm}
%%% FixMe: Is this a "figure" or an "algorithm"?
\begin{figure}[htbp]
  \begin{center}
    \def\tnext{_{\text{next}}}%
    \def\told{_{\text{old}}}%
    \def\tbest{_{\text{best}}}%
    \fbox{
      \begin{minipage}{0.90\textwidth}
        \begin{tabbing}
          XX\=XX\=XX\=XX\=XX\=XX\=XX\=XX\= \kill
          Initialize: \> \+ \\
          for each $s$\\ \> \+
          $\nu\tnext (s) = \log \left( P_{\ti{Y}{1},\ti{S}{1}}
            \left(\ti{y}{1},s \right)\right)$ \\ \\ \< \- \< \-
          Iterate: \> \+ \\
          for $t$ from 1 to $T$\\ \> \+
          Swap $\nu\tnext \leftrightarrow \nu\told$\\
          for each $s\tnext$\\ \> \+
          \\ \# Find best predecessor\\
          $s\tbest = \argmax_{s\told}\left( \nu\told(s\told) + \log\left(
              P_{\ti{S}{t}|\ti{S}{t-1}} \left(s\tnext|s\told \right) \right)\right)$ \\
          \\ \# Update $\nu$\\
          $\nu\tnext(s\tnext) =\,$ \= $\nu\told(s\tbest)$ \\ \> \+
          $+ \log\left( P_{\ti{S}{t}|\ti{S}{t-1}} \left(s\tnext|s\tbest
            \right) \right)$ \\
          $ + \log\left( P_{\ti{Y}{t}|\ti{S}{t}} \left(\ti{y}{t}|s\tnext \right)
          \right)  $ \\ \> \-
          \\ \# Update predecessor array\\
          Predecessor[$s\tnext,t$] = $s\tbest$\\ \\
          \< \- \< \- \< \- %This stuff is for tabs \< \-
          Backtrack: \> \+ \\
          $s_1^T = \hat s_1^T(\bar s)$ , where $\bar s =
          \argmax_s \nu\tnext(s)$ at $t=T$
        \end{tabbing}
      \end{minipage}
    }
    \caption[Pseudocode for the Viterbi Algorithm.]%
    {Pseudocode for the Viterbi Algorithm}
    \label{fig:viterbi}
  \end{center}
\end{figure}
%%%
%%% fig:viterbiB
%%%
\begin{sidewaysfigure}[htbp]
  %% 0.75\textheight is approx 5.7 in.  The .eps is exactly that size.
  %% The widths for the minipages below are taken by measuring the
  %% ovals inside of XFig.
  \centering{\plotsize%
    %% Column a
    \def\colaa{$\nu(s_1,t-1)$}%
    \def\colab{$\nu(s_2,t-1)$}%
    \def\colac{$\nu(s_3,t-1)$}%
    %% Column b
    \def\colba{$ \begin{matrix} s'(s_1,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_1|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\colbb{$ \begin{matrix} s'(s_2,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_2|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\colbc{$ \begin{matrix} s'(s_3,t) = \argmax_{{\tilde s}}\\%
        \log\left(P(s_3|{\tilde s}) \right)\\+ \nu({\tilde s},t-1)
      \end{matrix}$}%
    \def\bestpred{%
      \begin{minipage}[t]{3.9in}
        \raggedright%
        For each state $s$ find the best\\%
        predecessor $s'(s,t)$, \ie, the\\%
        one that maximizes\\%
        $\log\left(P(s|s'(s,t)) \right) + \nu(s'(s,t),t-1)$.\\%
        The bolder lines indicate best\\%
        predecessors.
      \end{minipage}}%
    %% Column c
    \def\colca{$\nu(s_1,t)$}%
    \def\colcb{$\nu(s_2,t)$}%
    \def\colcc{$\nu(s_3,t)$}%
    \def\newnu{%
      \begin{minipage}[t]{2.7in}
        \raggedright%
        For each state $s$\\%
        calculate $\nu(s,t)$\\%
        by including the\\%
        conditional probability\\%
        of the observation $\ti{y}{t}$,\\%
        \ie, $ \nu(s,t) = \log\left(P(\ti{y}{t}|s) \right) $\\
        \qquad$+ \log\left(P(s|s'(s,t)) \right)$\\
        \qquad$+ \nu(s'(s,t),t-1)$.
      \end{minipage}}
    %%
    \input{viterbiB.pdf_t}
  }
  \vspace{7em}
  \caption[Dependency relations in the Viterbi algorithm.]%
  {Dependency relations in the Viterbi algorithm.}
  \label{fig:viterbiB}
\end{sidewaysfigure}

\end{document}

%%% Local Variables:
%%% TeX-master: "main"
%%% eval: (load-file "hmmkeys.el")
%%% End:
